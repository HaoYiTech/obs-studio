
=========================================================================
注意 => 版本更新日志   => E:\GitHub\build\rpm_bin\version.txt
注意 => 最新浩一云日志 => 《浩一云日志.txt》
注意 => 最新Smart日志  => 《Smart日志.txt》
=========================================================================

2019.09.26 - 2019.10.26 - Flutter的学习记录：
===============================================================================================
00.（已完成）github.com/flutter | flutter.cn | sifou.com/flutter => 有关 Flutter 的开发社区资源；
   （已完成）F:\Flutter => 放置与Flutter开发相关的资源，相关学习记录等等内容；
   （未完成）https://www.jianshu.com/p/cda416e2fc0d => Flutter安装文档
   （已完成）https://developer.android.google.cn/
   （已完成）https://blog.csdn.net/xcg8818/article/details/100120840 => AS3.5的安装文档
   （已完成）https://blog.csdn.net/qijingwang/article/details/100113503 => AS3.5新功能说明
   （已完成）https://blog.csdn.net/u014720022/article/details/93321418 => 创建第一个应用
   （已完成）https://blog.csdn.net/liqz666/article/details/80243836 => AS简单入门教程
             三个主要的文件 => 主配置文件：AndroidManifest.xml，人机交互的MainActivity，还有布局LayLout:activity_main.xml
             Activity => 是一个人机交互的程序，相当于人和机器操作的桥梁，类似于shell，在里面写Java代码，从而达到想要

实现的业务处理。
             

activity_main.xml => 是Android界面显示的视图，所有的配置控件，各种控件可以通过这里进行设计。

             
AndroidManifest.xml => 主配置文件，用于配置各个组件的访问权限。


             R.java => 简单说就是android_main.xml里的控件的id号，方便在MainActivity里找到id来确定这个控件，从而做出业务处理。
             

app => 通常Android的各个组成部分放在此目录里，其中res存放一些资源文件，如图片、layout、values 等资源。
   （已完成）https://blog.csdn.net/herr_kun/article/details/84146462 => AS入门例子教程
   （已完成）https://www.liaoxuefeng.com/ => 各种教程入门文档
01.（已完成）https://ephtracy.github.io/ => 体素软件下载
02.（已完成）https://blog.csdn.net/sinat_33224091/article/details/100980160 => 快速后台管理开源工程
03.（已完成）C:\Windows\System32\Tasks => 这个目录专门配置Windows的Task规范，有大量的任务，通过xml配置，中间会有各种触发条件来启动其它应用程序；
             C:\Windows\System32\Tasks\Microsoft\Windows\TabletPC\InputPersonalization => 这是手写板的任务配置
             计算机管理 => 系统工具 => 任务计划程序 => 任务计划程序库 => 里面可以找到对应任务计划目录下的任务列表

2019.09.21 - 2019.09.26 - TensorFlow+Python的学习记录：
===============================================================================================
00.（不处理）讲师端，输入终端，目前还不支持手写输入，需要找到当初可汗学院里面的手写输入直接到电脑的方法；
   （不处理）讲师端，输入终端，YouTube上有一个妈咪说也用到了手写输入，还能与图片叠加，应该是手写笔的应用，不可能是鼠标输入，鼠标输入没有那么方便；
   （已完成）https://zhuanlan.zhihu.com/p/32494499 => Wacom+ArtRage，没有彻底搞明白，具体的应用；
   （已完成）https://item.jd.com/6029598.html => CTL-472/K1-F，需要购买一个手写板，可以直接与电脑软件交互；
   （已完成）https://www.wacom.com/zh-cn => Wacom的官网，已经申请了SDK，有两种SDK；但是好像并没有提供SDK下载；
   （已完成）https://www.bearrental.com => 小熊U租，咨询有关展会用电脑租赁相关问题：
             租赁1周的费用是多少？ => i7/8代/8G内存/27寸，3天~5天，展会包安装费用是500元左右，需要公司营业执照，法人身份证，先付款，无押金；
             租赁电脑的安装系统？押金？ => 可以根据需求事先安装好，只租给公司，免押金；网上的月租金是要租满1年的价格；
             租赁电脑是直接邮寄到展会地点？ => 北上广深都可以派人直接安装调试，撤展；
             租赁电脑的整个租赁流程是怎样的？怎么归还？ => 费用包含安装调试，撤展一条龙服务；
             租赁电脑主要用来跑软件，是否可以提前远程安装测试？ => 可以提前远程安装测试软件；
   （很重要）如果参加展会，就要做到一鸣惊人，做到有趣的操作，可以考虑加入体感控制投屏，让老师上课的效果更好，更加虚拟化；
   （很重要）让老师站在屏幕中间，老师用手势来操作屏幕，控制屏幕的声音，缩放，让教学产生未来感，这样的效果更加震撼，技术不一定先进，但效果能吸引眼球；
   （很重要）https://item.taobao.com/item.htm?id=536306606991 => LeapMotion，三代+支架，共818元；
             https://www.leapmotion.com/setup/desktop/ => 下载相关软件进行安装 => 需要64位系统才能运行；
   （很重要）要想实现这个手势操作效果，需要在Smart里面调用LeapMotion的SDK获取手势识别的状态，从而实现屏幕操作，同时，为了达到视觉冲击效果，还应该加入一些移动的动画效果；
   （很重要）https://www.leapmotion.com/ => LeapMotion的官网上也有提供SDK，CSDN上也有有关LeapMotion开发教程，可以实现直接的嵌入自己的应用程序当中；
   （很重要）E:\GitHub\HaoYiYun\Document\云教室\LeapVR\Leap_Motion_Developer_Kit_4.0.0+52173\LeapSDK => LeapMotion的SDK位置，支持x86，但不清楚是否还需要安装额外伺服软件或驱动；
   （很重要）另外，还需要增加一个人脸跟踪云台，相当于稳定器之类的辅助摄像头定位，方便老师在移动时自动跟踪；
   （很重要）https://item.taobao.com/item.htm?id=588805572205 => iDS-2PT7T40MX-D4/T3，可以自动跟踪任意人脸，价格在2800左右；
   （很重要）可以考虑使用普通海康云台摄像头配合OpenCV完成人脸识别自动云台跟踪的目的；在老师端使用普通海康摄像头完成；
   （很重要）E:\GitHub\HaoYiYun\Document\云教室\OpenCV => OpenCV本地开发目录；
   （很重要）在老师端，利用LeapMotion的手势识别功能，可以对学生端的海康摄像头进行拉近和拉远的手势操作；
   （很重要）https://mp.weixin.qq.com/s?__biz=MzI2NDk5NzA0Mw==&mid=2247553686&idx=1&sn=0ee923d8ff20675d5322c6331c8c7536
   （很重要）利用谷歌提供的TensorFlow.js+ARCore+小程序，可以替代LeapMotion，简化AR的操作，让讲师端自动适配手势操作；
   （很重要）2019.09.21，跟老张聊完之后，需要使用TensorFlow的机器学习代替LeapMotion，实现人体运动识别，从而达到控制三维世界的目标，用这种方式来降低AR成本，提高科普教学体验；
   （很重要）要充分利用小程序做为移动交互终端的体验，直接跟课堂上的讲师端进行资源互动、资源控制，让手机成为遥控器；这里面刚好可以使用到独有专利技术；
   （很重要）所有资源都挂载到用户身上，所有小程序上传的资源，也会自动挂载到上传者用户身上，方便用户管理资源，打通移动端+PC端+网页端；
   （已完成）https://csic.taobao.com/ => 这是一个专门做硬件板卡，无线通信板卡的淘宝店主，可以考虑板卡集成的事情；
   （已完成）EC20 => 4G模组，FC20 => WIF模组；

01.（不处理）2019.09.25 - 经过几天的思考，思路整理如下：
             A：必须通过本地School.exe获取IPC摄像头的RTSP数据，直接通过自定义的UDP协议，实时高速传递给云端服务器；
             B：云端Linux服务器接收网络数据之后，解码，生成JPG或BMP投递给Linux端运行的TensorFLow进行计算分析，得到人体骨骼的运动数据；
             C：云端Linux服务器将实时计算出来的人体骨骼数据回传给本地简单主机，School.exe收到反馈数据之后，控制unity3d对象进行响应；
             D：这样的方式，最大限度的降低本地机器的依赖，特别是本地机器运行复杂TensorFlow的环境依赖，让远端服务器利用强大云端算力来提高性能；

02.（已完成）https://github.com/geektime-geekbang/tensorflow-101/blob/master/README.md#1-windows-%E4%B8%8A%E5%AE%89%E8%A3%85-tensorflow-%E6%B5%81%E7%A8%8B
   （已完成）开始在 192.168.1.123 | Win7-x64 | CPM:111 | 主机上安装CPM，首先安装 Python => F:\Python\Anaconda3-5.3.1-Windows-x86_64.exe
   （已完成）https://blog.csdn.net/wyx100/article/details/79453941 => Anaconda与Python版本对应关系
   （已完成）https://python.org => 能正常访问了，直接下载最新版本，pip安装时，可以更换源，清华大学下载超快，每隔5分钟就会自动同步一次；
   （已完成）https://www.cnblogs.com/DjangoBlog/p/9145694.html => pip源的更换方法，在windows下实测有效，速度超快；
   （已完成）192.168.1.123 | Win7-x64上安装了 pip install tensorflow-gpu ，但是由于显卡不是nvidia的，无法运行CPM；
   （已完成）在淘宝上购买了2条4G内存，1个GTX1050Ti的显卡，用来测试 tensorflow-gpu，一定要把CPM运行起来，看看到底效果如何；
   （已完成）https://service.mail.qq.com/cgi-bin/help?subtype=1&&id=28&&no=1001256%27 => smtp.qq.com 第三方发送邮件，需要生成授权码；
   （已完成）F:\Python\work\mail.py => 使用qqmail需要新增starttls()，端口可以是25也可以是587；授权码需要通过绑定手机发送短信才能生成；

03.（已完成）https://github.com/timctho/convolutional-pose-machines-tensorflow => 针对 cpm 的tensorflow版本改造；
   （已完成）https://github.com/timctho/VNect-tensorflow => 实时摄像头捕获处理；
   （已完成）开始针对TensorFlow的机器学习研究，主要目标是让TensorFlow对人体的动作识别能够到达很快的精准匹配；
   （已完成）https://mp.weixin.qq.com/s?__biz=MzI2NDk5NzA0Mw==&mid=2247553686&idx=1&sn=0ee923d8ff20675d5322c6331c8c7536
   （已完成）http://baijiahao.baidu.com/s?id=1645273012927138624 => 有关谷歌开发者大会
   （已完成）需要研究 TensorFlow.js 和 TensorFlow Lite，还有 ARCore；还有 Flutter，快速开发三端应用；
   （已完成）github.com/flutter | flutter.cn | sifou.com/flutter => 有关 Flutter 的开发社区资源；
   （已完成）https://haokan.baidu.com/v?vid=5033386093680624195&pd=bjh&fr=bjhauthor&type=video
   （已完成）https://www.jianshu.com/p/dfd47294656b => 手势识别Demo（效果一般）
   （已完成）https://www.imooc.com/article/34036 => AAA => 基于tensorflow的手势检测和手势识别分类 => 研究这个很重要；
   （已完成）https://blog.csdn.net/zhangboshen/article/details/82430481 => AAA => Convolutional-Pose-Machines-tensorflow => 研究这个很重要；
   （已完成）https://blog.csdn.net/cherry_yu08/article/details/80846146 => Convolutional Pose Machine总结
   （已完成）https://blog.csdn.net/shenxiaolu1984/article/details/51094959 => Convolutional Pose Machine
   （已完成）https://blog.csdn.net/yeahDeDiQiZhang/article/details/78131566 => Convolutional Pose Machine => 文后有更多参考链接
   （已完成）https://java.ctolib.com/timctho-convolutional-pose-machines-tensorflow.html => 2D身体和手部姿势估计的最先进模型之一
   （已完成）https://blog.csdn.net/mogoweb/article/details/80274063 => TensorFlow.js结合PoseNet应用
   （已完成）https://blog.csdn.net/qq_42793029/article/details/93631267 => TensorFlow.js的例子
   （已完成）https://blog.csdn.net/bobxx/article/details/88354697 => 使用unity3d和tensorflow实现基于姿态估计的体感游戏(效果差)
   （已完成）tensorflow.org/js => 轻量级应用 => 必须翻墙才能访问；
   （不处理）新工程的代号是 School，具体实现参考 Screen 的实现；
   （已完成）https://www.cnblogs.com/wumac/p/8195025.html => python在Windows下的环境安装
   （已完成）https://www.cnblogs.com/--wwwww/p/10024448.html => 适合初学者的python安装
             https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ => 清华镜像资源 => https://www.python.org/downloads/
             I:\工具软件\IDM\腾讯视频下载工具.exe =>  只有这个版本能用 
             I:\工具软件\IDM\xdown => 百度网盘快速下载工具，需要开启 暴力猴 chrome插件才行，IDM需要注册非常麻烦；
             https://blog.csdn.net/qq_39521554/article/details/80855086 => 有关python2和python3的思考；
             https://github.com/Microsoft/PTVS/ => Python tools for Visual Studio => 总是在后台运行，占用CPU；
             https://www.runoob.com/w3cnote/pycharm-windows-install.html => PyCharm 安装教程
             http://www.jetbrains.com/pycharm/download/other.html => 选择2018.3.7，支持win32版本；比PTVS干净利索，不会莫名其妙在后台运行python；
   （已完成）https://www.liaoxuefeng.com/wiki/1016959663602400 => python学习基础知识
   （已完成）https://docs.python.org/zh-cn/2.7/ => python帮助文档 => 居然能访问；
   （已完成）F:\Python => python资料 => F:\Python\work => python学习过程代码

2019.08.24 - 2019.09.20 - 封装obs最新版本：
===============================================================================================
00.（已完成）http://www.ceiea.com/ => 中国最大的教育装备展，每年举办2次，在不同的省市举办，一次在5月，一次在10月；
   （已完成）77届青岛展会，参展商最低9平米参展，分为会员价3800/9平米，非会员价5200/9平米，2019年的普通会员费是2000元/年
   （已完成）76届重庆展会，参展商最低9平米参展，分为会员价3800/9平米，非会员价5200/9平米，特展是4个普通展位，每个展位会员价8000，非会员价9000；
   （已完成）10.11日，D335，22:42-06:37，北京站-青岛北，青岛北站 3号线到 青岛站 5/6/7隧道 新城吾悦广场(积米崖) 13号线 世博城国际展览中心
             10.12日，D336，21:20-06:03，青岛北-北京站，13号线 新城吾悦广场(积米崖) 5/6/7隧道 青岛站 3号线 青岛北站

01.（未完成）服务器，暂停改造，将已改造的代码转移到 => C:\Users\Jackey\Desktop\obs-code\udpserver-2019.04.28
   （未完成）学生端，暂停改造，将已改造的代码转移到 => C:\Users\Jackey\Desktop\obs-code\student-2019.04.28
   （未完成）学生端，需要增加多路网络数据流的回放功能，在右侧进行分屏显示，并能对每个显示画面进行投影展示；
   （已完成）学生端，通过新增 -m 参数自动进入右侧多窗口展示模式，默认显示4分屏窗口，第一个是讲师推流窗口；
   （已完成）学生端，只通过学生端来改造，达到多地联合比赛的目的；完全无需讲师端的参与；
   （未完成）学生端，需要改造视频显示方式，采用libobs的显示内核，而不是SDL显示内核；
   （未完成）学生端，所有参与比赛的学生端都进入相同的房间教室；通过DBCameraID区分讲师播放(0)还是学生播放(>0)；
   （未完成）学生端，CViewStudent，新增关闭按钮，新增静音按钮，图标都需要做特定的修改，https://www.iconfont.cn/
   （未完成）学生端，初步完成右侧窗口重排，现在需要加入右侧窗口的右键菜单，新增菜单 => 学生端列表 => 创建CViewStudent，并直接预览播放出来；
   （未完成）服务器，讲师与学生交互时的扩展音频数据源来自讲师观看者对应的学生推流者，因此，讲师只拉取一路摄像头；
   （未完成）服务器，一个房间里面只有一个讲师推流者，可以接入多个学生观看者；
   （未完成）服务器，一个房间里面只有一个讲师观看者，对应观看一个学生推流者；
   （未完成）服务器，一个房间里面可以多个学生推流者，每个学生推流者可以有多个学生观看者；
   （未完成）服务器，基本架构调整完毕，现在需要在细节上进行调整，通道的丢包|补包验证，推流自动关闭验证，推流切换自动关闭验证；
   （已完成）服务器，学生端拉流的音频播放有问题，完全没有消耗音频数据；丢包的补包也有问题，有一些数据包永远不会补上；由于探测包填充的问题；
   （已完成）服务器，改进探测包处理反馈过程，学生观看者的探测包填充有问题，需要改进 => 有两种观看者 => 观看老师的学生|观看学生的学生
   （已完成）服务器，当学生观看者接入时，通过服务器中转启动命令到学生推流端，目前的机制有问题，需要改造成可以支持同时多路上传，而不是现在的只能一路上传；
   （未完成）服务器，当学生观看者退出时，通过服务器只是删除观看者对象，当观看者减少到0时，让服务器停止发送探测包，迫使学生端自己缓存溢出而自动停止；
   （未完成）服务器，而不是靠直接的命令转换，快速退出，这种方式不适合多路上传，而且来回的精确退出，也会在讲师端频繁切换时造成问题；
   （未完成）服务器，TCP线程资源 访问 CApp线程资源 需要采用消息队列的方式进行tcpthread与CApp线程之间的资源访问管理，这样，还能避免使用互斥带来的麻烦；
   （未完成）服务器，CApp线程资源 访问 TCP线程资源 由于本身就在CRoom当中操作，已经做了互斥处理，能够保证CTCPClient的有效性；

02.（已完成）服务器，需要重构，整理各个线程之间的关系，整理各个对象之间的关系，将TCP房间和UDP房间整合到一起；
   （已完成）服务器，三个线程对象 => main | CUDPThread | CTCPThread
   （已完成）服务器，三个线程对象，共同管理的是房间对象，互斥放在CApp当中，所有的资源都放到房间对象当中；
   （已完成）服务器，全局CApp对象管理的对象如下：
             A：UDP线程对象  => CUDPThread => 只有一个
             B：TCP线程对象  => CTCPThread => 只有一个
             C：房间集合对象 => DBRoomID => CRoom => Map集合
   （已完成）服务器，整合后的房间对象可能包含的对象列表 => DBRoomID => CRoom，具体思路详见 => 绘图-Viso.vsd => udpserver架构
             A：老师TCP => CTCPClient => 只有一个 => Teacher
             B：学生TCP => CTCPClient => Map集合  => Student
   （已完成）每一个TCP长链接对应一个UDP推流，多个UDP拉流 => 教学和会议进行统一管理
             C：老师推流UDP => CUDPClient => Teacher => Pusher => 只有一个 => 存放在CTCPClient
             D：老师拉流UDP => CUDPClient => Teacher => Looker => Map集合  => 存放在CTCPClient
             E：学生推流UDP => CUDPClient => Student => Pusher => 只有一个 => 存放在CTCPClient
             F：学生拉流UDP => CUDPClient => Student => Looker => Map集合  => 存放在CTCPClient
   （已完成）每个CRoom当中存放一个讲师CTCPClient，多个学生CTCPClient；
   （已完成）每个CTCPClient存放一个推流CUDPClient，多个拉流CUDPClient；
   （已完成）CTCPThread和CUDPThread都同CApp中转访问，对CRoom进行互斥保护，都通过CRoom统一访问资源，这样能保持互斥，让系统更确定更稳定；
   （已完成）三个线程优化原则 => 简化接口，不要乱窜，UDPThread最简单，阻塞接收网络数据，收到之后投递给CApp主线程，然后继续等待网络数据；
   （已完成）TCPThread主要管理CTCPClient对象，所有的CTCPClient的创建和删除，都在这个线程完成，并通过CTCPClient与CApp主线程关联，主要通过互斥CRoom完成；
   （已完成）最终演变成 CUDPClient::doProcessUdpEvent() 与 CTCPClient::ForRead() 之间的资源访问问题；CApp主线程 与 TCP线程 访问CRoom资源互斥；
   （已完成）具体思路详见 => 绘图-Viso.vsd => udpserver架构
   （已完成）改变CRoom的管理策略，之前的方案太保守，因为CRoom永远不会被删除，只会被创建，只要保证CRoom创建时做好互斥，不要重复创建就可以了；
   （已完成）新策略就可以完全参考之前的代码来改造，CTCPClient和CUDPClient都可以在自己对象内部保留CRoom对象，这样避免来回穿插调用的麻烦；
   （已完成）目前新的线程管理方式，一定要尽量避免CApp线程CUDPClient::doProcessUdpEvent() 与 CTCPThread线程CTCPClient::ForRead()，直接的来回穿插调用；
   （已完成）在访问CRoom内部资源时，也需要用进行互斥保护，m_lpTCPTeacher|m_MapTCPStudent，这两个长链接资源；
   （已完成）对CRoom接口进行封装，不要把m_lpTCPTeacher|m_MapTCPStudent直接对外暴露，而是通过接口封装，便于进行资源互斥和保护；
   （已完成）将UDPPusher放在了对应的TCP长链接对象当中，将UDPLooker的Map集合放在了对应的UDPPusher当中；
   （已完成）在thread.h当中新增CMutexLocker，可以利用构造和析构简化互斥的操作过程；
   （已完成）udpcenter当中，新增了退出机制（killall），调整了tcp线程超时时间，与udpserver保持一致；
   （已完成）2019.09.10，服务器的改造初步告一段落，下面需要让服务器配置Smart.exe讲师端进行联合调试，服务器|网站端|Smart终端
   （已完成）https://mp.weixin.qq.com/s?__biz=MzU1NTEzOTM5Mw==&mid=2247485966&idx=1&sn=113920ae7c4f908f4576fbcc1484781a => webrtc拥塞文档
   （已完成）https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547697&idx=1&sn=acc748b7fcf0058b58e244970e51eabc => 网络延时分析
   （已完成）https://www.cnblogs.com/jimodetiantang/p/8952141.html => 有关过期事件的处理问题；

03.（已完成）需要整理清楚 webserver|udpcenter|udpserver 三者之间在运营模式和产品模式下的关联和结构，具体思路详见 => 绘图-Viso.vsd => 服务器架构；
   （已完成）需要给 udpcenter|udpserver 加上版本控制信息，以便区分服务器的代码状态，增加 -v 参数即可，在启动日志当中也要做标记；
   （不处理）需要给 udpcenter|udpserver 增加配置文件，以便适应产品发布的需要，具体参考简单的 obs 配置脚本；basic.ini或global.ini
   （已完成）obs里面有关ini的读写非常复杂，udpcenter|udpserver端口很特殊，只针对udpserver进行中心服务器的地址配置，通过参数传递，支持域名形式；-c 参数
   （已完成）udpserver里面连接中心服务器的地址，都会自动强制转换成IP地址，进行连接；
   （已完成）udpserver开始搭建纯粹的TCP线程与UDP线程，它们是网络数据的获取渠道；
   （已完成）udpserver里面的TCP线程改造，去掉了互斥管理，因为所有有关对象操作都是在TCP线程内部完成的，针对外部资源访问都是通过CApp来完成，因此，CApp需要加入互斥，以便处理TCP线程与UDP线程的资源互斥；
   （已完成）udpcenter|udpserver都需要打印出当前正在监听的端口信息，以便排查错误，以及查看当前服务器状态的有效性；
   （已完成）https://blog.csdn.net/angellove156/article/details/51689745 => UDPThread在recvfrom的阻塞退出问题，shutdown关闭读写通道，close只关闭写通道；
   （已完成）之前版本的recvfrom是在CApp主线程，可以直接close唤醒，新版本放在UDPThread子线程，调用close只关闭写通道，需要追加shutdown(fd,SHUT_RDWR)，必须关闭读写通道时才会将recvfrom阻塞唤醒。
   （已完成）shutdown => 可以控制关闭的通道方向，可以同时关闭读写通道，但不会释放套接字资源；
   （已完成）close => 只关闭写通道，无法唤醒在子线程中阻塞的recvfrom函数，同时，close能够释放套接字资源；
   （已完成）改造 udpcenter 整理代码，将所有相关的变量相关管理都放到 TCPThread 当中，所有的交互都是通过 TCPClient 完成；
   （已完成）改造 udpcenter 整理代码，从最基础的部分开始，重新整理，重新梳理代码和结构；
   （已完成）F:\obs-studio\Server\common\rtp.h => Smart|udpcenter|udpserver 三者都需要用到的结构和常量；
   （已完成）F:\obs-studio\Server\common\server.h => udpcenter|udpserver 服务器都需要用到的结构和常量；
   （已完成）Smart，OBSApp::InitGlobalConfig()当中，可以针对ClientType进行默认值的读写配置；
   （已完成）Smart，需要在CLoginMini登录界面当中，三角形区域可以配置登录类型，默认是学生端，可以修改成讲师端，写入 global.ini 当中；
   （已完成）Smart，需要在CLoginMini当中的某个与网站端交互命令当中，传递参数，创建 wk_smart 信息表，就是之前的 wk_gather 表的简化版本；
   （已完成）Smart，开始进行CRemoteSession与udpserver的交互命令的完善过程；
   （已完成）udpserver，CTCPCenter::doSendCommonCmd()当中，之前使用assign重建模式，会造成极端情况下kCmd_UdpServer_OnLine命令会冲掉doRoomCommand命令...
             因为doRoomCommand先被tcp线程执行，然后tcp线程中发生doHandleTimeout，激发kCmd_UdpServer_OnLine，这时doRoomCommand还没有被执行真正的发送命令...
             因此需要改成append方式，这样，没有发送的命令，也可以一并被发送出去，服务器也专门处理了命令粘滞的问题；
   （已完成）udpcenter，CTCPClient::doSendCommonCmd()当中，也需要修改成append模式；

04.（未完成）网站端 => 配合新版Smart终端，浩一云对应的网站和数据库需要重新整理和改造；
   （未完成）网站端 => F:\obs-studio\Web => 本地目录，存放 mysql数据库|Nginx配置|php代码
   （已完成）网站端 => https://www.myhaoyi.com => 保留，修改下载页面，通过直接的访问目录列表的方式；
   （已完成）网站端 => https://edu.ihaoyi.cn => 改造，只留下下载地址，替换成双师系统的下载页面；
   （已完成）网站端 => F:\obs-studio\Web => /weike/smart => 远程服务器目录 => https://edu.ihaoyi.cn
   （已完成）Smart，从登陆界面入手，开始整理终端登陆流程，简化以前复杂混乱的过程，将学生端|讲师端登陆流程合并起来；
   （已完成）Smart，CLoginMini，开始搭建最初的版本，判断输入参数，连接中心服务器，获取小程序二维码，获取节点服务器地址和端口；
   （已完成）Smart，win-update，里面有Json的重定义，需要更名为OBSJson，与 json/json.h里面冲突，需要去掉，在Teacher当中已经处理过了；
   （不处理）Smart，开始正式确定参数方式启动Smart的细节，如果确定是参数访问，下面的参数缺一不可，少了一个都要提示失败；
             -m 10001    => 登录的房间号码，从10001开始，对应的数据库编号 x - 10000
             -u 张三     => 登录房间的用户名称，只要是名字就行，不一定跟数据库关联；
             -c edu.ihaoyi.cn => 指定连接中心服务器的域名或IP地址，通过这个地址获取节点服务器地址；
             -p => 参数模式，默认是小程序模式，连接外网的中心服务器，弹出二维码进行扫描打开房间信息；
   （不处理）Smart，参数启动模式，都是私有云模式，当输入的参数无效或连接指定服务器失败时，会在CLoginMini当中显示登陆参数，服务器|房间号|用户名，具体参考屏幕端的登录界面形式；
   （不处理）Smart，参数启动模式，在连接外网进行自动升级之后，也要注意将成功登录的参数传递给启动参数，这样便于保持启动的的参数模式，否则，会连接外网，走默认弹出二维码启动过程；
   （已完成）Smart，platform-windows.c:567有一个BUG，需要判断有没有错误才能继续执行；
   （已完成）Smart，需要将讲师端|学生端，单独的命令，现在需要合并简化成一个命令；
   （已完成）网站端，无论是经销商模式，还是私有云模式，还是小程序模式，都必须包含完整的体系，完整体系包含如下的形式：
             Smart       => 运行终端，既可以是老师端，又可以是学生端，可以根据参数设定，也可以根据绑定用户参数设定；
             udpcenter   => 中心服务器，管理多个节点服务器，也可以接受网站服务器的管理；
             udpserver   => 节点服务器，提供音视频数据流的中转处理工作；
             nginx+php+mysql => 网站服务器，同时，包含一个smart数据库；
             fastdfs     => 备用的分布式文件服务器，在有录像和回放需求时要用到；
             注意：php连接udpcenter|udpserver时，都要采用fastdfs插件模式，这样便于统一维护；
   （已完成）这样设计的目的，最大限度的保持各个版本的独立与一致，所有模式的升级维护都可以独立完成，而不是相互缠绕依赖，最大限度的降低复杂度；
   （已完成）这样的方式，对外就只需要暴露 中心网站地址 和 中心网站端口，需要注意的是 http 和 https 格式的提前判断；
   （已完成）通过中心网站的数据库获取到中心服务器地址，通过中心服务器地址，登录成功，之后，再通过中心网站获取到节点服务器地址；
   （已完成）不要把多个模式混在一起完成，否则，无法进行，非常麻烦和混乱，先做小程序模式，再做内网模式，最后完成参数模式；
   （已完成）即使是小程序版本的Smart，也是非常复杂的版本，因为讲师端和学生端进行了合并，统一成了Smart终端；
   （已完成）将目前的混合模式暂时保存起来 => C:\Users\Jackey\Desktop\obs-code\Smart-0913
   （已完成）浩一云 小程序 发布第一个版本，便于进行二维码的绑定操作；
   （已完成）浩一云 小程序 09.17审核通过，开始验证Smart扫码登录过程；
   （已完成）由于 pages/bind/bind 页面没有上传，造成无法获取二维码；
   （已完成）QT针对QPixmap的半透明方法 => 可以简化为两行 => https://blog.csdn.net/chduguxue/article/details/82902980
             painter.drawPixmap(nXPos, nYPos, m_QPixQRCode);
             //painter.setCompositionMode(QPainter::CompositionMode_Source); // 以QColor为透明对象...
             painter.setCompositionMode(QPainter::CompositionMode_DestinationIn); // 以m_QPixQRCode为透明对象...
             painter.fillRect(nXPos, nYPos, m_QPixQRCode.width(), m_QPixQRCode.height(), QColor(0, 0, 0, 100));
             注意：这种方法可以配合QPushButton的border-image透明背景的png的透明度，可以实现按钮的半透明；
   （已完成）完成了初步的smart-output相关的终端与服务器的交互通讯过程；
   （未完成）下面开始进行smart-source相关的终端与服务器的交互通讯过程；

05.（已完成）https://www.cnblogs.com/fsw-blog/p/4788036.html => tc 详细用法 (ln -s /usr/lib64/tc /usr/lib/tc)
      https://blog.csdn.net/duanbeibei/article/details/41250029/ => tc 详细用法
      tc qdisc add dev eth0 root netem delay 200ms 70ms 30% loss 10% corrupt 0.1% => 延时200ms，抖动70ms，丢包10%，0.1包损坏；
      tc qdisc del dev eth0 root netem delay 100ms 30ms 30% loss 1% corrupt 0.1%
      tc qdisc replace dev eth0 root netem delay 200ms 70ms 30% loss 10% corrupt 0.1%

2019.08.24 - 2019.09.24 - 封装obs最新版本：
===============================================================================================
01.（未完成）2019.08.22，来为想把双师系统改造成核心模块（服务器|推流|观看），去掉所有的外围模块，嵌入到他们的系统当中；
   （未完成）2019.08.22，这样适合将服务器建在私有云上面，服务器上创建license，终端（推流|观看）针对license进行授权验证判断；
   （未完成）2019.08.22，需要改造的东西还不少，终端合并（讲师端|学生端），变成SDK（动态库），服务器需要简化，只保留音视频部分，增加license判断部分；
   （已完成）存放php相关接口实现 => F:\obs-studio\Web => php|nginx|mysql
             存放服务器相关代码  => F:\obs-studio\Server => udpserver|udpcenter => /weike/udpserver => /weike/udpcenter
             存放终端库相关代码  => F:\obs-studio\Smart  => Smart.exe => %APPDATA%\obs-smart
             存放终端库发布组件  => F:\obs-studio\vsbuild\smart => bin|data|obs-plugins => 具体参考 screen 相关代码；
             经过尝试，无法将 QTGUI 封装成动态库，非常麻烦，且不太方便，最终采用 Smart.exe 方式，这样第三方直接启动外部进程，这样更简单；
             Smart.exe 可以接收一些特定的参数，比如：房间编号|用户姓名|服务器地址 等等其它信息，供Smart.exe启动时使用；
             -m 10001 -u 张三 -s 192.168.1.3 => 服务器端口 都是默认的，有好几个端口，udpcenter-tcp|udpserver-tcp|udpserver-udp
             默认情况下，无参数启动Smart.exe，会自动打开“浩一云”小程序二维码，访问 https://myhaoyi.com 基础服务器上的服务；
             Smart.exe 始终会自动升级，升级服务器的地址是 https://myhaoyi.com，升级之后，如果是其它私有服务器有可能Smart.exe无法运行，需要手动升级私有服务器；
             Smart.exe 的会议模式界面参考 钉钉 的视频会议界面，简化操作，老师端和学生端都简化成一个界面；

02.（未完成）Smart.exe最重要的核心改造1 => 讲师端|学生端合并，界面始终参考obs的界面，既能上课又能开会；
   （未完成）Smart.exe最重要的核心改造2 => 支持视频会议模式的多人双向交互模式；大量简化obs原来的复杂界面；
   （未完成）Smart.exe最重要的核心改造3 => 必须站在巨人的肩膀上快速前进，而不是重复造轮子；
   （未完成）Smart.exe在启动时，需要通过外部参数 或 小程序扫码来确认运行模式 => 讲师端 或 学生端 身份；
   （未完成）Smart.exe把 屏幕共享 单独拿出来，做成一个单独的按钮，参考钉钉视频会议，然后将Smart最小化，将屏幕进行整个共享；
   （未完成）Smart.exe里面的学生端，是完全独立的存在，走自己完全另一条通路，只是借助smart.exe这个壳而存在，学生端默认是软压缩模式，可以切换成硬压缩模式；
   （未完成）Smart.exe里面可以将screen模式也加进去，也是跟学生端思路一样，通过窗口来进行变换；
   （未完成）Smart.exe里面针对学生端编号不要存放在本地，而是通过tcp长连接，在有新的终端通道上线后，主动推送给房间里所有的终端；
   （未完成）Smart.exe里面学生端的硬件模式，可以有多个上传通道，软件模式，只有一个上传通道，走软压缩流程；
   （未完成）Smart.exe里面可以由老师端配置成 教学模式 或 会议模式，默认是 教学模式，就是目前的形式，会议模式 就是多人相互查看模式；
   （未完成）Smart.exe里面不要存放中心网站的域名地址，通过参数传递，如果没有参数，使用内嵌的默认地址 https://www.myhaoyi.com，通过网站接口获取中心服务器地址；
   （未完成）Smart.exe里面当没有传递参数时，使用内嵌的 https://www.myhaoyi.com，启动 小程序 界面，进行网站流程模式，中心服务器地址通过网站端获取；
   （未完成）Smart.exe里面当通过参数启动时，传递的服务器地址和端口是中心服务器地址和端口，认为网站服务器不存在，简化系统运行的方式和状态，但可以通过后期添加网站的方式升级；
   （未完成）Smart.exe是以参数方式启动时，跳过小程序界面，跳过网站登录过程，直接连接中心服务器；中心服务器是否连接成功，也要通过小程序界面来展示；
   （未完成）Smart.exe是以参数方式启动时，也需要显示小程序登录界面，通过这个界面来展示参数传递的有效与合法性，需要连接中心服务器，获取有效节点服务器地址和端口；
   （已完成）F:\obs-studio\vsbuild\CMakeCache.txt => STATIC_ZLIB_PATH:STRING=F:/obs-deps/win32/bin/zlib.lib => 才能创建update工程；
   （已完成）需要将新版本的obs-studio(23.2.2)转换成smart.exe，然后，讲师端|学生端，合并；
   （已完成）https://github.com/MoePlayer/DPlayer => 一个不错的H5播放器；
   （已完成）F:\obs-studio\vsbuild\config => 仅供 F:\obs-studio\UI 和 F:\obs-studio\Smart 同时使用；
   （已完成）默认zh-CN配置；去掉license检测，去掉向导配置；重排Docker(统一右边排列)
   （已完成）OBSApp::InitTheme() => 会利用System.qss重新定义菜单对应的图标，全部都修改成了.svg格式，OBSBasic.ui文件当中都是.png，是不正确的，会被自动修改；
   （已完成）需要解决无法自动添加Scene场景对象的问题，无法在场景对象列表当中显示自动创建的默认场景，必须手动添加一个？Load()调用位置调整，AddScene()自动调用
   （已完成）新版OBS界面层很容易出现卡死现象，估计是日志上传|自动更新线程的缘故，删除一些没用的线程；
   （已完成）开始进行预览窗口的数据源分行显示的更改过程；scene_save_item()|scene_load_item()|obs_scene_add_internal() => 读取更新floated标志；
   （已完成）需要解决数据源被删除时的事件通知，然后解决有关0点数据源的复位问题；然后解决有关翻页按钮的显示问题；
   （已完成）obs_source_remove => OBS里面是用来处理scene的移除，obs_sceneitem_remove => OBS里面用来处理sceneitem的移除；sceneitem是对source的进一步封装；
   （已完成）InitOBSCallbacks => 直接处理底层source数据源和scene的事件通知；AddScene => 处理信息更全的sceneitem事件通知；针对0点数据源应该在sceneitem事件中，针对PPT数据源应该在source事件当中；
   （已完成）由于新版OBS增加了sourceTree，因此SourceTree::Remove()当中直接调用RemoveSceneItem()，一起完成remove事件通知；
   （已完成）注意：source是一种数据类型，sceneitem是source的具体实例，多个sceneitem对应一个source类型；
   （已完成）开始添加PPT数据源对象，能够从外部添加PPT文件，自动生成PPT图片序列，需要PowerPoint的支持；
   （已完成）处理只能添加一个音频输入数据源的问题；
   （已完成）再次优化了首次启动加载过慢，造成加载等待白框的问题，进行了两次异步加载之后解决，详情见 OBSBasic::OBSInit() => OnFinishedLoad() => DeferredLoad() => OnFirstSystemTray()
   （已完成）系统设置，需要解决启动和退出时都比较缓慢的问题；ProfileScope()检测发现需要近3秒钟才加载完毕，需要去掉一些没有使用到的组件；
   （已完成）系统设置，去掉 推流|热键|高级，只留下 通用|音频|视频，x264的高级压缩选项配置放在通用里面；
   （已完成）系统设置，利用QTimer::singleShot，先显示白屏界面，再QTimer中ui->setupUi(this)，这样体验会好很多，不要让用户在弹框之前等待，而应该在弹框之后等待；
   （已完成）系统设置，同时，需要注意修改Q_PROPERTY(QICON)由于setupUi变化之后的图标处理问题；需要修改 UI/data/themes 下面的 .qss 文件，只能分开写样式...
   （已完成）系统设置，通用，新增 输出里面针对x264的常规参数配置，把它放到 通用 里面的 输出 栏当中；
   （不处理）系统设置，通用，SaveGeneralExtern() => main->ResetOutputs() 还没有验证，并需要改进；
   （已完成）系统设置，将默认的系统设置，改成简化版 OBSBasicSetting，高级配置 OBSBasicSettings 放到右键菜单当中；
   （已完成）优化并修改 AdvancedOutput::AdvancedOutput 里面针对推流和录像的配置信息；"bitrate": 1024,
 "profile": "baseline",
 "tune": "zerolatency"
   （已完成）开始验证本地录像是否正常，注意是录制轨道2的声音；
   （已完成）需要改进smart里面obs渲染核心，改进延时机制；由于渲染核心改动较大，延时是否有所降低还需要进一步根据实际网络传输进行验证；
   （未完成）首先需要对工程命名做一个详细的规范，将老师端|学生端合并，都是采用软压缩方式：
             rtp-services.dll => smart_source => 老师端|学生端输入数据源 => 老师观看者|学生观看者
             rtp-services.dll => smart_output => 老师端|学生端输出数据源 => 老师推流者|学生推流者
   （未完成）开始搭建讲师端CRemoteSession对象，与服务器进行交互，并开启推流模式；
   （未完成）将海康摄像头进行封装，这是硬压缩解决方案，然后命名规范如下：
             ipc-services.dll => ipc_teacher => source => 老师端输入数据源 => 拉取rtsp流，默认本地解码播放，老师端显示为一个数据源窗口；
             ipc-services.dll => ipc_student => source => 学生端输出数据源 => 拉取rtsp流，默认本地解码关闭(可手动打开)，根据老师端请求，直接推流；
             ipc-services.dll => ipc_student => source => 学生端输出数据源 => 本质上具备rtp推流特性的数据源，推流直接通过数据源完成，不通过obs过程；

03.（已完成）https://github.com/obsproject/obs-studio.git => clone时选择 递归 深度 1，才能把相关所有独立出去的模块都提取下来；
   （已完成）切换|检出 => 分支 => remotes/origin/master => 覆盖已存在的分支，就能提取服务器上的最新版本，并更新覆盖到本地版本；
   （已完成）https://github.com/jackeyxp/obs-studio => 18059104@qq.com => F:/obs-studio => 尽量保持与obs的版本一致，跟它同步；
   （已完成）https://github.com/HaoYiTech/obs-studio => 18059104@qq.com => E:/obs-studio => 之前启迪未来的版本位置，不再更新；
   （已完成）https://blog.csdn.net/gengxt2003/article/details/79070741 => obs在2015下的编译参考文档；
   （已完成）当前使用的是23.2.2版本，cmake-gui当中新增QTDIR|DepsPath|RELEASE_CANDIDATE(23.2.2-rc1)，否则Configure无法通过；
   （已完成）F:/obs-studio => 23.2.2 版本，去掉obs-vst|enc-amf|enc-amf-test，正常完整编译通过；
   （已完成）F:/obs-studio => 23.2.2 版本，尝试加入 obs-browser 编译过程；https://github.com/obsproject/obs-browser/
   （已完成）https://blog.csdn.net/liukang325/article/details/55254267/ => obs编译说明 => obs-browser（CEF内核浏览器插件）
             CEFWRAPPER_LIBRARY:FILEPATH=F:/CEF/cef_binary_76.0.3809.87_windows32/vsbuild/libcef_dll_wrapper/Release/libcef_dll_wrapper.lib
             CEFWRAPPER_LIBRARY_DEBUG:FILEPATH=F:/CEF/cef_binary_76.0.3809.87_windows32/vsbuild/libcef_dll_wrapper/Debug/libcef_dll_wrapper.lib
             CEF_LIBRARY:FILEPATH=F:/CEF/cef_binary_76.0.3809.87_windows32/Release/libcef.lib
             CEF_INCLUDE_DIR:PATH=F:/CEF/cef_binary_76.0.3809.87_windows32/include
             CEF_ROOT_DIR:PATH=F:/CEF/cef_binary_76.0.3809.87_windows32
   （已完成）虽然编译通过，但是感觉运转起来非常不友好，最终还是放弃了；
   （已完成）屏蔽coreaudio-encoder的支持，在windows下会有问题；

04.（已完成）正在尝试将“浩一云”小程序改名为“浩一测试” => 1840413417@qq.com => 贴上了直播标签，无法审核通过；
   （已完成）正在尝试将“启迪未来双师”小程序改名为“浩一云” => 2119644571@qq.com => 认证主体是“浩一科技” => 2019.09.03，完成改名工作；
   （不处理）如果“浩一云”仍然无法启用，注销“浩一云”的服务号 => 2338664674@qq.com => 在小程序改名时显示有这个重名问题 => 小程序名和服务号名字是相互独立的，不受影响；

2019.07.28 - 2019.08.23 - 爱多幼儿园实测过程中发现的问题：
===============================================================================================
00.（已完成）2019.08.23，发布新版本 1.2.13，只是编译好放在那里，等需要的时候再升级到服务器上去；
   （已完成）2019.08.23，在升级到服务器上的时候，需要注意将 udpserver 一并升级更新上去；

01.（不处理）讲师端，本地视频文件，需要在窗口中心位置，增加一个暂停按钮和进度条功能，鼠标移动上去之后可以暂停，也可以进行拖动进度；
   （不处理）学生端，需要在全屏画面中显示网络探测的结果信息，以便让用户查看到当前的网络状态；
   （已完成）讲师端，obs_sceneitem_t对应的坐标系始终没有变化，变化的是preview自身的投影，doSceneItemToFirst|doSceneItemExchangePos才会始终用的obs_get_video_info这个信息；
   （已完成）讲师端，因此，在对obs的显示做调整时，需要结合preview自身的尺寸进行，obs_sceneitem_t背景尺寸永远保持不变；
   （已完成）讲师端，这个发现是在针对互动学生端显示麦克风图片时发现并确认的，以前都是没有彻底搞清楚，为什么preview会有缩放，而obs_sceneitem_t却没有的原因；

02.（不处理）讲师端，需要开启本地捕获电脑输出的声音，这样便于直接输出电脑屏幕上的声音，特别是浏览器播放视频内容；
   （不处理）讲师端，目前采用的默认屏蔽电脑输出的模式，需要进行必要的调整，不适合灵活应用，很多网页视频都需要下载，但是很多网站都做了防下载的措施，造成很大麻烦；
   （已完成）腾讯视频下载工具：维棠，可以不用格式转换，直接就是MP4格式 => https://www.52pojie.cn/thread-729577-1-1.html

03.（已完成）2019.08.05，石景山当老师端，西三旗幼儿园当学生端，都是4G网络，声音采集是个大问题；
   （已完成）2019.08.05，先去石景山，对老师端进行调整，更换两个支架（自带灯光，78+32），一个正对老师(C930E)，一个俯拍手部(汇博士)
   （已完成）2019.08.05，发现C930E针对人像抠图非常到位，利用斜壁支架靠近人嘴巴，拾音效果好，罗技摄像头，声音和图像都做了优化；
   （已完成）2019.08.05，汇博士摄像头拍出来的画面偏红色，还没有找到合适的调试方法；
   （已完成）2019.08.06，爱多国际幼儿园，试听课，家长都想占便宜，内心对乐高机器人还是应该上，利用双师进幼儿园就是乐高的普及；
   （已完成）2019.08.06，双师乐高在幼儿园当中的应用，前景非常乐观，线上老师+线下老师=完整老师，线上老师相对轻松，线下老师更轻松，只需要维持纪律；
   （已完成）2019.08.06，双师课程因为有前期导入（动画片），PPT演示，远程老师互动，实际搭建，整个上课过程显得更丰满更立体；
   （已完成）2019.08.06，双师乐高进幼儿园，是对乐高机器人的普及，性价比高，不到2000的价格可以学一学期，还能拿回一箱玩具，以及一个正规机构证书；

04.（不处理）2019.08.07，每天到上午10点，4G物联网卡就会突然降速，讲师端|学生端需要根据网络探测情况，自动进行速度匹配；
   （不处理）2019.08.07，讲师端|学生端，默认设置一个最高码流上限，都是1024Kbps，当探测发现网络拥塞时，需要主动降速；
   （不处理）2019.08.07，tinyXml 可以直接利用 std::string << document 输出到字符串；
   （不处理）2019.08.07，学生推流者进行网络探测，探测的是 学生推流者 <=> 服务器 之间的网络延时；
             学生端的学生推流者探测到网络延迟rtt超过500毫秒，主动将当前获取到的IPC码流降低50%；
             学生端的学生推流者进行丢包重传时，发现丢包重传的次数超过3次，也会主动降低码流50%；
   （不处理）2019.08.07，学生端，先解决学生端通过ISAPI进行音视频码流的获取与修改的代码；
             GET ISAPI/Streaming/channels/101 => 只获取101通道的配置情况，没有可选参数返回；
             GET ISAPI/Streaming/channels/101/capabilities => 获取101通道的配置情况，同时返回可选参数；
                 <Video><constantBitRate min="32" max="16384">1024</constantBitRate> => 当前配置的视频码流数值
                        <vbrUpperCap min="32" max="16384">1024</vbrUpperCap>
                        <vbrLowerCap>32</vbrLowerCap>
                 </Video>
             GET ISAPI/System/TwoWayAudio/channels/1 => 获取摄像头统一的音频配置情况；
                 <audioCompressionType>AAC</audioCompressionType> => 音频压缩格式
                 <audioInputType>MicIn</audioInputType> => 硬件设备类型
                 <speakerVolume>50</speakerVolume> => 音频捕获音量
                 <noisereduce>false</noisereduce> => 环境噪音抑制
                 <audioBitRate>64</audioBitRate> => 音频码率
                 <audioSamplingRate>32</audioSamplingRate> => 音频采样率
            PUT ISAPI/Streaming/channels/101 => 保存视频配置信息
                <?xml version="1.0" encoding="UTF-8"?>
                <StreamingChannel xmlns="http://www.hikvision.com/ver20/XMLSchema" version="2.0">
                  <id>101</id>
                  <channelName>永丰小学 - 全景</channelName>
                  <enabled>true</enabled>
                  <Video xmlns="">
                    <constantBitRate>512</constantBitRate>
                  </Video>
                </StreamingChannel>
     注意：不能用局部的简单更新配置方式，必须使用全面的通道配置更新，因此，GET ISAPI/Streaming/channels/101 之后，需要保存xmldoc，用来动态更新视频码流，然后再PUT回到IPC摄像头；

05.（已完成）在修改动态码率调整过程中，发现 udpserver => student.cpp:642 处一个非常严重的BUG；
   （已完成）642行代码，如果环形队列为空，只有是第一个数据包的情况下才会成立，如果不是第一个数据包，不能直接当丢包处理；
   （已完成）642行代码，如果不是第一个数据包，环形队列为空的原因是被发包完毕造成的情况时，就会造成一个巨大的丢包区间 => [1, new_id-1]
   （已完成）同样的问题，teacher.cpp:528，也是相同的问题，需要对第一个数据包的标志进行判断和设定，如果环形队列是被发包清空的，会造成一个巨大的丢包区间；
   （已完成）同样的问题，讲师端|学生端，相关的 doTagAVPackProcess 代码，都做了严密的逻辑判断处理，就是要针对第一个数据包进行特殊的判断和处理；
   （已完成）doCalcAVJamStatus 现在的方案，会造成音频被动被视频清空，造成音频缓存为0，从而触发大量的补包命令，引发混乱；
   （已完成）doCalcAVJamStatus 进行调整，不要音视频联动删除，而是单独删除，始终保留5秒钟的缓存数据；
   （已完成）这样修改之后就不会发生环形队列为空的情况，因为始终保留5秒缓存供补包使用；
   （已完成）追根溯源，发现这个问题的发生，是由于学生端拿到IPC音频之后，进行解码 => 回音消除 => 重新压缩，时间戳的计算上产生误差，丢弃了IPC原始音频时间戳，自己构造时间戳；
   （已完成）造成新音频时间戳与IPC原始音频时间戳存在偏差，从而进一步造成与IPC原始视频时间戳偏差，本身同步的音视频，被人为的造成不同步（时间戳偏差）；
   （已完成）解决方法 => 想办法在回音消除时，不要构造新的时间戳，而是使用IPC原有时间戳，这样让IPC的音视频始终保持一致，不要出现偏差；
   （已完成）解决方法 => 在对IPC音频进行回音消除时，始终以IPC音频为主轴，因为，它的时间戳是准确的，来自硬件没有偏差；
   （已完成）讲师端，由于多路音频混合输出之后，没有进行音视频同步操作，造成音视频同步问题，现在都是将音频混合成一路之后挂载到Scene上面；
   （已完成）讲师端，每个source的音视频同步点在audio_monitor当中；需要修改每个source的音视频同步点，放到混音之前才行；
   （已完成）学生端，读取IPC压缩AAC音频，解码 => 转换 => 回音消除 => 降噪 => 转换 => AAC压缩 => 推流，整个过程的延迟是可以接受的；
   （已完成）学生端，但是，利用ffmpeg的AAC压缩器，只能每次输入1024个采样64毫秒，但是回音消除的对齐数据是10毫秒，造成过大的落差，处理起来相对麻烦；
   （不处理）学生端，需要改进成每次处理30毫秒音频数据，这样处理起来非常方便，但是需要调整压缩器的具体配置，目前还没有找到合适的方法；
   （已完成）学生端，对 CWebrtcAEC::doEchoEncode() 进行了改进，可以支持64毫秒数据块压缩，时间戳始终使用IPC时间戳，这样不会造成服务器和讲师端音频时间戳混乱问题；
   （已完成）学生端，之前采用的是帧数进行时间累加，这种方式非常不精确，会造成巨大的音视频延迟或严重不同步，现在的模型始终同步，同步时间戳来自IPC而不是PC机器；

06.（不处理）2019.08.07，学生端，云台控制窗口，可以直接手动调节IPC摄像头的视频码流，“+”每次增加50Kbps，“-”每次降低50Kbps

07.（不处理）2019.08.07，学生端，网络拥塞时，curl会阻塞整个界面层，造成软件无响应，这个修正，将所有的curl修改为QNetworkAccessManager
   （不处理）2019.08.07，学生端和讲师端合并之后一起解决，需要进行统一的规划和处理；

08.（已完成）2019.08.05，直播录像 => C:\Users\Jackey\Videos\2019-08-05_09-03-40.flv，发现录制视频没有录制交互学生端的声音；
   （已完成）2019.08.05，讲师端，混音轨道2是专门的录像通道，互动学生端的音频始终需要混音录制，无论多少路学生端音频都需要录像；可以通过高级音频属性来关闭轨道2的音频录制；
   （已完成）2019.08.08，讲师端，录像格式默认设置为mp4，便于移动端播放，以前默认是flv，不能直接使用移动端播放；
   （已完成）2019.08.08，讲师端，学生端声音，可以由老师主动控制，在窗口栏显示一个按钮（开启第三方监听）开启的同时；
   （已完成）2019.08.08，讲师端，由现在的学生端画面焦点监听模式，改进成由老师主动控制模式，由老师来选择让第三方接收哪个学生端的音频；
   （已完成）2019.08.08，讲师端，多路学生端时，只能有一个学生端处于第三方监听状态；详见 ResizeBtnMicAll()
   （已完成）2019.08.08，讲师端，麦克风按钮的提示问题；学生端被删除时需要处理相关麦克风按钮问题；详见 RemoveSceneItem()

09.（不处理）2019.08.08，讲师端，插拔耳机或扬声器，无法进行声音回放，必须重新创建monitor才行；
   （不处理）2019.08.08，讲师端，有可能与电脑上声音输出设备有关；

10.（不处理）讲师端，发现之前利用scene进行第三路混音统一播放输出的思路是错误的，所有的6路混音都是针对obs对外输出使用的，是统一的输出时间轴；
   （不处理）讲师端，本地播放输出，是每个数据源针对自己音视频进行的音视频输出，每个数据源都有自己的时间轴，不能跟obs的输出时间轴搞混了；
   （不处理）讲师端，现在的做法，利用的是obs混音(输出时间轴)，去跟数据源的本地播放视频时间轴同步，肯定无法同步；
   （不处理）讲师端，obs混音(输出时间轴)，与obs视频输出时间轴，是保持音视频同步的，它们的音视频是保持同步的；
   （不处理）讲师端，需要修改成 => 只有一个monitor输出(便于回音消除)，每个输出数据源通过信号通知scene去反向回调所有数据源，读取播放输出音频，全部混合后，统一播放输出；
   （不处理）讲师端，具体混音操作，参考scene_audio_render进行所有数据源的混音操作；
   （已完成）讲师端，恢复成本地播放都是通过source建立monitor模式，互动学生端只保留一路的形式；
   （已完成）讲师端，多路互动学生端，为了避免回音消除的问题，建议老师戴耳机进行直播互动；
   （已完成）讲师端，恢复之前使用scene的monitor，通过轨道3播放的代码，所有的混音都是输出的声音，本地播放并不是输出的声音；
             void OBSAdvAudioCtrl::monitoringTypeChanged(int index)
             void OBSBasicSourceSelect::on_buttonBox_accepted()
             void OBSBasic::ResetAudioDevice()

11.（已完成）讲师端，PPT本地文件，在调用外部PowerPoint.exe时，必须调用CoInitialize()，否则无法调用COM；
   （已完成）讲师端，win-dshow.cpp:DShowThread()调用了CoInitialize()，只要有本地摄像头就可以使用PPT本地文件；
   （已完成）讲师端，https://blog.csdn.net/thanklife/article/details/78258104 => 让线程注册一个套件，而线程运行过程中必然在此套件。
   （已完成）讲师端，CPPThread::doPPTExportJPG() 新增调用CoInitialize()，让PPT本地文件不依赖 本地摄像头 的启动；
   （已完成）小程序，E:\obs-studio\qidiweilai\wxapi\Lib\Model\UserMastModel.class.php，修正机构管理错位问题，对应的编号错位了；

12.（已完成）学生端，UDPPlayThread.cpp修改音频播放投递机制，当GetCurrentPadding()缓存超过300毫秒，需要使用sonic对音频进行加速处理；
   （已完成）学生端，这样达到变相减少数据量的目的，采用1.5倍加速，sonic可以做到变速不变调，需要解决数据残留的问题；
   （已完成）学生端，sonic可以输入任意大小的数据块进行加速或减速，内部都是用short操作，外部兼容float|char数据输入；
   （已完成）学生端，sonic可以通过接口获取到每次加速或减速剩余的残余数据，可以单独取出来，需要增加一些特殊接口；
   （已完成）学生端，改进播放格式转换，使用 audio_resampler_resample 接口；
   （已完成）学生端，采用渐进加速的方式 doRenderAudio，需要处理sonic里面的数据残留问题，已声卡缓存300毫秒为加速基准；
   （已完成）学生端，改进 CWebrtcAEC::doEchoCancel() 必须以麦克风为对齐标准，扬声器声音不足用空数据代替；
   （已完成）学生端，这样的处理后的AEC效果非常好，能够基本彻底解决网络抖动，网络延迟带来的麦克风与扬声器声音对齐问题；
   （已完成）学生端，因为，麦克风是本地网络相对持续稳定，但也要结合sonic的加速与扬声器的置空处理，始终快速对齐麦克风与扬声器的声音数据；

13.（已完成）讲师端，参考学生端，对AEC模块进行必要的改进操作；
   （已完成）讲师端，始终保持麦克风与扬声器的声音同步，扬声器声音不够，使用空数据代替，不要让麦克风等待；
   （已完成）讲师端，WASAPISource::doEchoCancel() => 之前就是一直使用麦克风为基准，现在跟学生端一致，当扬声器无数据时用置空代替；
   （已完成）讲师端，这样改进之后，即使网络抖动，延迟，只要麦克风与扬声器的声音保持对齐，回音消除的效果都还不错；
   （不处理）讲师端，wasapi-output.c:process_audio_delay()，在本地播放进行音视频同步时，采用的是丢包方式，造成声音断层，后续需要改进成降速或加速模式，不要丢音频数据；
   （不处理）讲师端，sonic在减速或加速处理上有输入缓存块限制(不能精确到样本点)，还会产生数据残留，实际应用中相对比较复杂，学生端参见 UDPPlayThread.cpp:doRenderAudio()，由于播放机制的原因，只进行加速处理；
   （不处理）讲师端，由于播放机制的原因，讲师端必须既有加速处理又有减速处理，因此，sonic必须要解决输入缓存限制问题，以及数据残留问题；
   （已完成）https://blog.csdn.net/weiqiwu1986/article/details/49099201 => 有关变速的应用思考 => 解决变速残留，精确到样本点；

14.（已完成）https://blog.csdn.net/lbaihao/article/details/52138804 => 声音处理文档 => 加速减速的某种方法
   （已完成）student-app.cpp:doTestAudioSpeed() => 尝试进行音频的加速和减速处理；
   （已完成）通过降低采样率并不能进行加速或减速，只会影响声音质量和占用空间(码率)；
   （已完成）E:\GitHaoYi\sonic => sonic 源码 => https://github.com/waywardgeek/sonic
   （已完成）https://blog.csdn.net/abcsunl/article/details/77196788 => 中文翻译
   （已完成）https://www.jianshu.com/p/2f9939111681 => libsonic更为详细的解释
   （已完成）https://blog.csdn.net/u010339039/article/details/89196814 => 音频倍速（变速不变调）的实现
   （已完成）https://blog.csdn.net/weiqiwu1986/article/details/49099201 => 有关变速的应用思考 => 解决变速残留，精确到样本点；
   （已完成）https://blog.csdn.net/liuxiaoheng1992/article/details/79379514 => 音频变时不变调处理(SoundTouch WSOLA)
   （已完成）snoic在不断变化的加速|减速过程中，没有发生像上文提到的soundtouch的问题；没有调用sonicFlushStream的情况；
   （已完成）snoic如果每次在发生变速时都调用sonicFlushStream时会发生空白数据的问题，因为内部故意填充了空白数据；snoic使用了最小计算单元造成的；
   （已完成）snoic使用时，不要随意调用sonicFlushStream，速度发生变化时数据被重叠使用不要紧，只要时间计算精确就行；在计算时间时需要考虑残留数据很重要；

15.（不处理）https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547697&idx=1&sn=acc748b7fcf0058b58e244970e51eabc => 网络延时分析

16.（已完成）讲师端|学生端，回音消除要彻底解决，目前最大的问题是，网络抖动延时对回音消除的影响，需要尝试对声音进行伸缩播放，动态调整频率；
   （已完成）讲师端|学生端，回音消除的根本问题是麦克风与扬声器声音的对齐问题，需要找一个参考基准，麦克风产生的声音稳定持续，扬声器(网络)的声音不稳定，需要加速或减速，还是不够，采用置空与麦克风声音对齐；
   （已完成）学生端，在播放层有时候会发生解码后的音视频数据帧累积，造成延迟变大；
   （已完成）学生端，这有可能是时间戳控制不够精确造成，从而进一步影响了回音消除？
   （已完成）学生端，这个问题需要进一步深入处理，有可能最大限度的解决回音消除问题，可以参考讲师端音视频时间戳同步的方法；
   （已完成）学生端，每个音频数据包持续时间相同，但是到达时间有间隔，会造成投递给扬声器的数据流时快时慢，造成抖动，需要始终保持声音数据量的匀速投递；
   （已完成）学生端，把不够的声音数据补上，把多余的声音压缩，快速播放，实在没有补的声音时候，用空数据代替；

17.（不处理）学生端，需要研究webrtc的NetEQ功能，专门针对音频播放的恒定速度播放，不受网络抖动的影响，数据量少就减速，数据量多就加速，这样就能避免网络抖动造成的问题；
   （不处理）学生端，如果这个功能完成，就能解决网络抖动延时造成的AEC回音消除不完全的问题，AEC回音消除与延迟无关，与网络抖动有关，AEC的回音消除算法已经非常好了；
   （不处理）学生端，有关论文 => E:\GitHub\HaoYiYun\Document\云教室\NetEQ，有关回音消除 => http://www.360doc.com/content/16/0802/17/9008018_580299182.shtml
   （不处理）学生端，有关 NetEQ => https://blog.csdn.net/qq_29621351/article/details/81541271
   （不处理）学生端，大牛直播 => https://www.daniulive.com/
   （不处理）学生端，tc qdisc add dev eth1 root netem delay 50ms 80ms 10% loss 1% corrupt 0.1% => D:\MP4\PCM\抖动 => 网络抖动对回音消除有严重影响，需要使用NetEQ做音频的平滑处理；
   （不处理）学生端，也就是说，所有的音频数据需要进行特殊处理，进行加速或减速，送给声卡的数据始终是稳定恒速的才能保证音频不受网络抖动的影响，从而保证AEC不受网络抖动影响；
   （不处理）学生端，NetEQ功能非常重要，直接关系到音频播放时的体验效果，采用弹簧似的伸缩播放策略，避免直接的跳跃卡顿非常重要；
   （不处理）学生端，突然想明白了为什么网络抖动会造成AEC消除困难，查看 E:\GitHub\HaoYiYun\Document\云教室\NetEQ\Audio.txt，投递给声卡设备的音频数据并不是匀速投递；
   （不处理）学生端，会突然投递过量数据，造成声卡无法消耗，直接覆盖，覆盖的数据并没有通过声卡播放出来，但是，这些数据投递给了AEC进行回音消除，这样就会造成错位，无法对齐的问题； 
   （不处理）学生端，需要搞清楚声音延迟、时间计算、音视频同步、匀速播放的核心逻辑与测试，这样才能彻底的解决好音频播放、长时间同步、随时控制延迟、有效控制AEC的核心问题；
   （不处理）学生端，只要将声音的播放投递时刻点，严格按照声音的时间戳去投递，就能解决投递的时间对齐问题，同时，需要保证不要过量投递，防止声音不被播放的问题；就需要配合加速减速来完成；

2019.07.06 - 2019.07.27 - 小程序 - 回音消除 - 讲师端|学生端合并
===============================================================================================
01.（已完成）小程序，中幼联合，必须完成针对机构的充值|扣费的功能，这样才能形成扣费循环；
   （已完成）小程序，屏蔽班级管理入口，先不要做面对家长的签到功能，后续版本再完善；
   （已完成）小程序，wk_agent|wk_flow|wk_consume，新增一些字段，方便计费统计；
   （已完成）小程序，学生端|讲师端通过wk_flow不断更新计费状态，只是记录不要直接扣除费用，扣除动作在小程序的“消费记录”当中完成；
   （已完成）小程序，消费记录，首先列举所有的以讲师端房间号为核心的计费记录，然后，可以单独对每次的记录进行单独的扣费；0.2元/分钟；
   （已完成）小程序，消费记录，每条记录是以讲师端房间号使用为核心，学生端使用情况也有一栏，可以点击进入二级页面，查看每个学生端单独的费用情况；
   （已完成）小程序，消费记录，每条记录都有一个单独的按钮进行扣费确认，这时会更新wk_flow|wk_agent相关记录；
   （已完成）小程序，消费记录，学生消费记录的查看详情 => FlowGather；
   （已完成）小程序，机构管理者，在‘我的’那一栏需要看到自己管理机构的账单信息；
   （已完成）学生端，数据库默认就是永久授权，不要再限制学生端，小程序已经做了限制；

02.（已完成）讲师端，PPT文件体验改进，在0点位置状态时，显示 当前页/总页数 ，增强用户体验；
   （已完成）讲师端，PPT文件体验改进，不要使用鼠标根据百分比位置进行内容切换，使用左右按钮进行上一页|下一页切换；
   （已完成）讲师端，PPT文件体验改进，处于浮动|待选状态时不要显示左右按钮，只有作为0点位置窗口时才显示左右切换按钮；
   （已完成）讲师端，PPT文件(slideshow)是延迟加载，必须等ss_update更新完毕之后，才能正确读取数据，因此，需要新增obs信号反馈通知source_updated；新增 obs_source_updated 接口；
   （已完成）讲师端，之前为了创建统一的混音播放通道，还增加了 source_monitoring 信号反馈通知，通过 obs_source_dosignal 发起界面层反馈；
   （已完成）讲师端，0点位置不要用坐标进行判断，相当不精确，需要通过保留变量的方式来进行切换和判断 => OBSBasic::doCheckBtnPage()；
   （已完成）讲师端，由于上次obs-browser的修改过程中造成的残留，会引发系统崩溃，全部清理Debug目录之后解决问题；
   （已完成）讲师端，数据源删除流程 => on_actionRemoveSource_triggered() => obs_sceneitem_remove() => SceneItemRemoved() => RemoveSceneItem()
   （已完成）讲师端，学生端，有关wk_flow流量计费的标识flow_teacher这个标识在多个终端标记和持续更新上可能存在问题，即：flow_teacher可能会被后续错误的编号重新更改；
   （已完成）学生端，服务器，CTCPClient::doCmdStudentOnLine()更新，反馈flow_teacher，以便持续更新，防止漏报情况发生；
   （不处理）学生端，讲师端，检测到已经有进程运行时，需要增加一个强制关闭并启动的按钮，这样保证只有一个进程运行；
   （已完成）学生端，讲师端，doProcessCmdLine => 解析外部命令行失败时的处理 => optreset=1
   （已完成）服务器，挂载终端有时候会出现混乱的情况，没有学生端在线也一直显示有在线；需要修改udpserver与udpcenter在线汇报机制；
   （已完成）服务器，之前的汇报机制是实时汇报，学生或讲师在线状态发生变化后就汇报，这样看似精确，但是容易发生误差，利用每隔10秒自动集中汇报更为简单快捷；
   （已完成）服务器，不应该去掉之前的汇报机制，应该新增Online汇报机制，做为以防万一的补充，实时汇报还是需要的；
   （已完成）服务器，修正 tcpclient.cpp 当中需要提前清空上次解析的json问题，如果当前为空，会使用上次的结果；parseJsonData()
   （已完成）发布新版本，升级到 1.2.10，主要修改 讲师端 优化 PPT文件，修正潜在的BUG问题；
   （已完成）2019.07.19 已备份数据库 => E:\GitHub\build\rpm_6.8\mysql-5.5.3\data\educate

03.（未完成）学生端与老师端合并，默认都是学生端，在数据库中有wk_gather标记，可以远程或小程序修改终端类型为讲师模式，讲师毕竟有限；
   （未完成）中幼联合，始终希望学生端支持USB|笔记本|采集卡等等各种即插即用的摄像头，还有操作界面的简化，学生端支持桌面共享；
   （未完成）中幼联合，最简单的方法就是升级讲师端，增加rtsp拉流插件，增加两种模式（讲师模式|学生模式）
   （未完成）中幼联合，将学生端的所有功能都移植到老师端，永远只更新一个软件就可以了；
   （未完成）中幼联合，这样更改之后，老师端既支持普通USB摄像头，又支持监控网络摄像头，使用起来就变得非常简单；
   （未完成）中幼联合，学生端合并后，通道配置可以通过特定的student.json进行本地保存，去掉数据库里的wk_gather|wk_camera，简化交互过程和操作；
   （未完成）中幼联合，需要新增win-rtsp插件，专门处理rtsp连接拉流过程，并符合obs的音视频传输|封装|播放机制的插件；

04.（不处理）讲师端，数据源需要增加拉取rtsp数据源的插件，支持直接从监控摄像头拉取数据进行直播；
   （已完成）讲师端，可以直接通过“媒体源”加入rtsp监控连接，但是延时有点大，在1秒以上；
   （不处理）讲师端，因此，需要单独编写一个插件，专门使用live555的rtsp拉取数据，视频264或265，音频aac或G.721，使用ffmpeg进行播放同步；
   （不处理）学生端，网络摄像头只有视频，没有音频，在讲师端无法拉取网络摄像头的数据，能看到列表，无法呈现图像数据；
   （不处理）学生端，需要增加调节显示亮度|对比度|饱和度的功能，应对显示屏亮度不够，发黑的问题；
   （不处理）讲师端，直播时间长了延时会增加，有可能是网络抖动或时间偏差，造成本地播放的缓存累积过多，造成缓存延时问题；这个问题之前就发现过，没有深究。

05.（不处理）学生端 => 可以使用任意的笔记本+摄像头+麦克风，就能进行实时的软压缩，进行个人的接入使用；这个只需要参考libobs的相关代码就可以实现；

06.（已完成）金色摇篮+人工智能课+双师系统，需要增加一个软件，安装在每个孩子的笔记本上，每隔几秒截屏发到网站上，讲师端会读取相同flow编号的学生电脑截屏，
   （已完成）讲师端，通过PPT文件（网络文件）图片的形式，展示出来，可以自由的切换网络图片；
   （已完成）难点在于如何有效、同步的将同一个房间里的学生屏幕展示在老师端，并不会发生冲突；
   （已完成）需要专门做一个截取全屏的软件，需要有登录房间功能，输入孩子姓名，房间密码；
   （已完成）这个软件，还需要在讲师端停止退出之后，自动断开退出功能，老师端能够控制屏幕截取软件全部被动退出；
   （已完成）老师端断开重新推流不要影响这个屏幕截取软件，而是可以让老师端控制退出，就像微信登录一样的操作；
   （已完成）新建一个工程Screen，一个简化版的只有屏幕截取功能的老师端，定期截取全屏，存盘到obs-screen，自动最小化，不回显；
   （已完成）Screen通过与udpserver的TCP中转连接，直接定期将生成的全屏截取JPG文件中转传递给Teacher，讲师端，直接保存到对应的PPT目录下面即可；
   （已完成）Screen每次在中转传递JPG文件时，都需要带上房间号码、登录用户信息等等；
   （已完成）Screen每次使用都需要登录指定的房间号码和密码（手动输入），还有孩子姓名；
   （已完成）Screen本身也能每次自动检测同步功能升级，与讲师端|学生端版本号码保持一致；
   （已完成）Screen界面初步完成，下面进入如何调用obs的核心代码进行屏幕截取并获取JPG文件内存的过程当中；
   （已完成）Screen需要重新整理思路，登录窗口与obs控制相互分离，只用一个场景和一个数据源，另一个单独的窗口进行回放，默认隐藏起来；
   （已完成）Screen主窗口是无边框窗口，后面的弹窗也会受主窗口影响；最终还是将回放窗口隐藏；
   （已完成）Screen需要修改libobs的obs-video.c代码，新增screen_mode参数，用来实现原始数据控制，开启时所有数据源都呈现给用户；
   （已完成）发现在存放JPG时，AV_PIX_FMT_YUVJ420P比AV_PIX_FMT_YUV420P好，没有色差，原来使用的AV_PIX_FMT_YUV420P图像颜色偏灰色；
   （已完成）需要进一步整理libobs，将数据进行有效的以screen_mode的形式输出给界面层；obs有专门的模型可以对外直接输出原始数据 => obs_add_raw_video_callback，之前直接DoProcSaveJpeg太过暴力；
   （已完成）obs_add_tick_callback => 控制每次绘制source时的外部操作，在绘制source之前可以做些自己的操作；
   （已完成）obs_add_main_render_callback => 在绘制主视图之前，可以做额外绘制，具体参见 window-basic-auto-config-test.cpp当中；这个可以用来做图像叠加，比如：绘制动态标注等等信息；
   （已完成）obs_add_raw_video_callback => 将原始视频帧数据直接对外输出，比如JPG截图的功能可以放在这里进行；
   （已完成）libobs的机制会通过等待时间，计算应该产生的帧数，修改obs-video.c::video_sleep()不要这么做，否则，video-io.c::video_output_cur_frame()会一直使用当前缓存帧不停的输出；
   （已完成）extern "C" { #include <libavformat/avformat.h> } => ffmpeg需要这么保护才能放到c++，否则link时会报告错误；
   （已完成）讲师端，slideshow数据源中增加 screen_slide 标志，可以进行特定目录内容的添加工作，在slideshow的基础上增加 screen_slide 标志，只能添加一个；
   （已完成）讲师端，每次学生端屏幕截图发生变化时，需要调用obs_get_source_by_name找到学生屏幕分享数据源，设定特定参数，调用ss_update，动态更新指定的图片文件；
   （已完成）讲师端，没有使用obs_get_source_by_name，通过settings的巧妙使用达到了动态更新的目的，image_source也是通过settings来动态加载；do_screen_change()；
   （已完成）讲师端，slideshow，在标题栏，需要增加每张幻灯片的名称内容，这样便于直接叫出参与学生的姓名；PPT幻灯片的命名规则与学生屏幕分享的命名规则有些差异；
   （已完成）讲师端，通过扩展image_file_data这个结构体来实现每张幻灯片图片的名称展示功能；
   （已完成）Screen需要加入升级检测机制，与Teacher|Student一起，形成新的升级模块；
   （已完成）Screen|Teacher|Student的升级检测模块统一整合到一起，大部分都相同，只是参数不同；
   （已完成）发布新版本，升级到 1.2.11，主要新增屏幕端；

07.（已完成）需要增加升级检测机制，包括DXWebSetup和VS2015的下载检测机制；
   （已完成）修正d3d11-subsystem.cpp::device_create()异常捕获机制的问题，需要增加catch (const char *error)，否则会被上层捕获，造成逻辑混乱的问题；
   （已完成）DXWebSetup的检测机制 => gs_device::InitCompiler() => D3DCompiler_xx.dll => 通过判断这个dll来确定是否支持D3D11
   （已完成）VC2015的检测机制 => msvcp140.dll|vcruntime140.dll，只要系统没有这两个dll就认为需要升级vc2015发行包；
   （已完成）VC2015的依赖包需要在manifest.json当中专门增加一栏，便于updater.cpp::HasVS2015Redist()进行提取验证；
   （已完成）VC2015的新的升级机制，并不能解决 讲师端|学生端|屏幕端 启动时缺乏运行时库的问题，只能解决运行起来之后，自动升级更新VC2015升级包的问题；
   （已完成）VC2015的新的升级机制，能解决的是能启动软件，但发行库不是VC2015的情况；
   （已完成）发布新版本，升级到 1.2.12，主要新增D3D与VC2015的检测升级机制；

08.（已完成）讲师端|学生端|屏幕端，发现有时候图标在任务栏无法显示出来；
   （已完成）CLoginMini::initWindow()当中加入setWindowIcon()函数，必须用png图片 => 解决有些机器不认ico，造成左上角图标无法显示；

2019.07.13 - 垃圾信息整合汇总
===============================================================================================
1.（不处理）首都师范大学的数学思维课最终判定我们的双师系统不成熟，采用了别的公司产品，主要用来做老师培训；
  （不处理）具体哪家公司还不太清楚，有待进一步了解确认；

2.（不处理）深圳一个客户需求：必须内网访问，不能对外连接，采集端和节点服务器都需要做一个改造，通过license文件或授权码进行授权；
   A：（不处理）做为首先更新的功能，采集端和节点服务器都支持本地授权，一旦进入本地授权模式，登录需要用户名和密码登录，不链接中心服务器；
   B：（不处理）采集端通过菜单进行授权文件输入，网站端通过后台输入文件，需要在网上找找这种授权方式的方法；
   C：（不处理）两种授权方式可以自由切换，自动匹配；

3. 词汇量测试网页 => https://www.shanbay.com/bdc/client/vocabtest/welcome
   QuickJS => https://bellard.org/quickjs/ => c语言编写的js解释器；
   E:\GitHaoYi\quickjs => 本地目录位置

9.（不处理）摄像头，需要选择一款清晰度更高的摄像头，相对DS-2DC2204-DE3/W而言，需要联系海康客服具体了解；DS-2CD3125D-IW2|DS-2CD3025D-IW2|DS-2CD1021FD-IW1
  （不处理）摄像头，清晰度的判断标准 => 码流|分辨率1080P|感光器件
  （已完成）上三角架|209元|1080P|内置麦克风|DS-IPC-T12H-I/POE| => https://detail.tmall.com/item.htm?id=568289704203&skuId=4015106356419
  （已完成）海康官网更新了几款很小的无线移动摄像头 => DC5V|1080P|120g|Wi-Fi|DS-IPC-S32P-IWT|DS-IPC-E32H-IWT|DS-IPC-E30H-IWT

10.（已完成）2019.07.06，田凯去临沂出差，了解到当地小龙人集团与央视某人物合作的幼儿双师试验课程，结果很失败，幼儿无法投入远程教学，特别是多个幼儿班级；
   （已完成）双师在幼儿远程教学当中是一个伪命题，难以实施，需要重新定位双师的应用场景，小龙人集团人员的建议是反向面对家庭和家长；
   （已完成）这样的转变，必然会要求讲师端和学生端的合并，登录时可以自由选择登录模式，所有的功能都集中到目前的讲师端，支持低延时RTSP；
   （已完成）07.08晚上讨论，发现这个需求存在问题：40%公办，40%民营，20%高端，国家政策是40%公办，40%普惠，20%高端，这样的话小龙人全部要变成普惠；
   （已完成）那小龙人只能从国家那里获得人头补贴和普惠园所的管理费用，有必要费那么大力气去反向服务家庭吗？幼儿园园长与老师有那么大动力去给家长开网络会议吗？
   （已完成）这个非常严重的市场需求问题，需要田凯去进一步了解情况；
   （已完成）07.10继续讨论，民办园基本都会变成普惠园，民办园的机构都会想法赚钱，线上培训课是新的赚钱渠道；
   （已完成）以往机构和老师没有动力，现在有动力线上开课赚钱，要以家园共育的模式进入，提供免费的刚需共育平台，再辅以线上课程；
   （已完成）07.11田凯去金色摇篮谈合作，全年1年建立500个加盟幼小衔接培训机构，主打幼小衔接的语数外课程线下培训；
   （已完成）这种幼小衔接的刚需很重要，老师有赚钱刚需，家长有升学刚需；需要将金色摇篮的线下培训课改造成线上版本；
   （已完成）为了适应幼儿的学习认知，需要让讲师端支持浏览器模式，这样可以让课件做成H5动画模式，课程变得生动有趣，久趣英语就是这么设计的；
   （已完成）所有的幼儿课程都需要改造成H5动画模式，这样不仅生动有趣，还可以无限扩展，还能实时互动交互；
   （已完成）技术的实现是利用obs当中browser数据源，直接内嵌了浏览器(额外工程)，而不是使用QT的复杂模式；输入网址，直接交互；
   （已完成）07.12继续讨论，凡是做课的机构，都会把课程当成宝贝，不可能轻易授权，需要让平台降低对课程的依赖；
   （已完成）因此，将所有课程做成H5的交互形式，虽然看上去很美，但是会严重依赖做课的成本和周期，还有一个更严重的问题是幼儿不是再跟老师交互，而是跟屏幕交互；
   （已完成）幼儿需要跟真实的老师交互更有效果，这种交互会极大降低对标准课程的依赖，更方便各个园所直接的实施；
   （已完成）久趣|VIP之所以会做成左侧H5动画，是因为可以降低对老师表演的依赖，降低老师标准；
   （已完成）我们目前这个平台的思路刚好相反，是降低课程标准化依赖，提高对老师真实交互的依赖，需要绿幕抠像叠加模式；
   （已完成）后期，可以专门做一个工具，配置大量动画|素材资源，由老师自行创建课程，通过特定遥控器控制动画的播放，来提升虚拟上课的体验，交互性更强；
   （已完成）07.12下午，田凯又来电说找到了语文|数学幼小衔接的动画课程，而且就是金色摇篮的采购对象，金色摇篮就是拿的这家的互动课程，根本不是金色摇篮开发的；
   （已完成）既然有现成的课程，现在就是把它标准化，推广给小龙人这些机构，转换成线上课程，以及做好对接工作，最好是teacher端直接融合，操作体验更一致；
   （已完成）这种交互动画课程，可以大大降低老师的依赖程度，可以让普通老师很快上手，快速铺开；

11.（不处理）目前的双师系统是针对ToB市场，为了让双师能够ToC，需要增加一个互动电子白板功能；
   （不处理）需要在讲师端增加一个插件，互动电子白板，可以参考ClassIn，讲师端和学生端都可以在白板上进行互动，画线，贴图，解题，讲题等等操作；
   （不处理）还可以点击PPT窗口的截图，专门进行批注解答，学生端和讲师端都可以通过电脑进行操作，从而完成互动电子白板的功能；
   （不处理）也可以设计成在主窗口，专门有一个功能按钮，点击之后就能定格画面，出现操作菜单，学生和讲师进行互动交流；
   （不处理）这个交互电子版本，可以借助外围设备（腾千里蓝牙电子笔）来实现，老师端需要添加电子笔资源 和 互动电子笔资源，学生端需要添加电子笔摄像头资源；

12.（已完成）EpocCam可以通过WiFi将iPhone变成无延时的无线摄像头，需要在手机和电脑上同时安装EpocCam => http://www.kinoni.com
   （已完成）EpocCam在iPhone上测试通过，有广告，收费版才支持声音，电脑端接收数据时CPU消耗过大，还是没有摄像头来的方便；
   （不处理）需要找到一款无线摄像头，而且还要低延时的那种设备；
   （不处理）需要打开Teacher端有关图片数据源的功能开关，这样有助于添加GIF动画背景图；
   （不处理）需要保持obs23版本的最新更新，以便跟上obs的新功能，避免落后太多，将来升级成问题；
   （已完成）I:\工具软件\winsxs => 非常简单好用的win7瘦身软件，可以释放C盘大量空间；
   （已完成）在油管上发现另外一款将手机变摄像头的应用 => IP摄像头，免费版有水印；安卓和iOS都能下载；
   （已完成）在油管上发现还有另外的翻墙方式 => SSR 速度快，不受限制，可以自建谷歌云或亚马逊云；
   （已完成）https://www.youtube.com/watch?v=c7ylVYcvLAM => Windows最佳免费翻墙方式
             Free-SS主站地址：https://free-ss.site => Free-SS镜像网站获取邮箱：ss@rohankdd.com
             Free-SS主站直连方法：https://youtu.be/jv8J64BjVpY
             SSRSHARE的主站地址（需翻墙）：https://www.ssrtool.com/tool/free_ssr
             SSRSHARE的镜像地址（可直连）：https://www.eruo.ml/tool/free_ssr
             SSR客户端下载地址：https://github.com/shadowsocksrr/shadowsocksr-csharp/releases
   （不处理）IP摄像头，讲师端可以直接使用http协议访问，需要修改讲师端媒体源模块，降低延时，播放声音；
   （不处理）IP摄像头，通过VLC可以设置延时50ms以内，声音播放有问题，需要修改讲师端的http播放代码，能够播放声音；
   （不处理）IP摄像头，还能直接通过Chrome浏览器访问，视频格式MJPEG，音频格式OPUS，估计这就是为什么讲师端无法直接播放声音的原因；
   （不处理）经查询得知，OPUS是一种优于AAC的音频格式，估计需要升级libavcodec才能获得OPUS的播放能力；这样就能利用手机进行远程无线直播；

13.（已完成）直播的形式可以有网页版本，可以参见 https://www.eeo.cn
   （已完成）https://www.eeo.cn/webcast.php?courseKey=62733c980cb29f1d&lessonid=22926583 => 一个直播的网页，手机页面；
   （已完成）电脑上的编辑软件 Premiere Pro CC 2018，可以在B站找到教学视频 => https://www.bilibili.com
   （已完成）手机编辑软件，美拍大师|巧影 => https://www.youtube.com/watch?v=C9EERC-iuAo
   （已完成）I:\工具软件\Everything-1.4.1.935.x86 => windows快速搜索工具

14.（已完成）如何制作高大上的PPT，通过素材简单快速改进：
   （已完成）http://www.588ku.com/ => 千库网，图片资源网站
   （已完成）http://www.51yuansu.com/beijing/ => 觅元素，免扣元素
   （已完成）https://mp.weixin.qq.com/s?__biz=MzU2ODEyNzY3Mw==&mid=2247491274&idx=1&sn=02405359876d221a5f66871ab13e08d2
   （已完成）https://zhuanlan.zhihu.com/p/62207655 => 48个无版权素材网站收藏，找素材再也不用那么费劲了；

15.（不处理）有关多个学生端登陆房间之后，镜头切换的问题，有了新的思路：
   （不处理）在讲师端右侧导航区域，新增一个互动教室的专属聊天窗口，分两栏，一栏显示已经在线的学生端摄像头列表，一栏显示学生端助教通过微信小程序发送的聊天文字、语音记录；
   （不处理）讲师端可以通过摄像头列表进行互动切换，也可以通过聊天文字信息直接进行镜头切换，这样就能快速实现切换，而且还不影响整体界面设计；
   （不处理）这个聊天窗口的设计，可以单独弹出来，进行扩大显示等等操作；

16.（不处理）百度网盘太垃圾了，下载文件必须下载百度网盘客户端，这个太麻烦了，需要将下载地址从百度网盘上移除；
   （不处理）https://myhaoyi.com 上制作自己的下载页面，使用layui制作简单大气的下载页面，不要使用百度网盘，直接下载；

17.（已完成）讲师端32位编译的程序，运行在win7-sp1-x64系统下，在窗口捕获时会有问题，出现窗口捕获异常；
   （已完成）讲师端32位编译的程序，运行在win7-sp1-x86系统下，在窗口捕获时没有问题，一切正常；
   （不处理）讲师端64位编译的程序，运行在win7-sp1-x64系统下，在窗口捕获时的情况，目前不清楚；

18.（不处理）有关数据源的音频静音或输出，可以直接放到数据源窗口的界面上，方便操作，也就是将高级音频属性放到视频显示窗口当中，做为快捷操作按钮；

19.（不处理）讲师端 => 启动时，显示虚拟教室房间列表页面，点击显示课程详情和小程序二维码，微信扫码验证用户登录身份，不是讲师身份禁止登录进行直播操作；
   （不处理）学生端 => 启动时，显示课程列表页面，点击显示课程详情和小程序二维码，微信扫码验证用户登录身份，不是助教身份禁止登录进行直播观看；

20.（不处理）网站端 => 后台管理的左侧导航配置情况：
   （不处理）房间管理 => 房间列表，需要更改名称，避免引起歧义；
   （不处理）用户管理 => 用户列表 | 助教 | 讲师 | 店长 | 运营 | 管理员 | 家长 | 孩子
   （不处理）后台管理 => 需要新增对学生端机器设备的控制和管理；
   （不处理）后台管理 => 需要对学生端进行终端类型的修改管理，分为3种角色 => 外网接收者|组播接收者|组播发送者

21.（不处理）讲师端，登录加载过程有一个加载进度条，避免等等很长时间，突然跳出主窗口界面；
   （不处理）讲师端，状态栏信息的完善：推流情况，网络状态，等等；
   （不处理）学生端，右侧窗口的码流信息，网络状态信息的显示情况；
   （不处理）学生端，状态栏窗口的中转服务器|存储服务器|网站服务器的连接状态显示；

22.（不处理）讲师端|学生端，需要捕获系统崩溃情况，并填充AppData\Roaming\obs-student\crashes或AppData\Roaming\obs-teacher\crashes目录；
   （不处理）实现方法 => 具体参考obs里面的崩溃处理代码 => obs_init_win32_crash_handler
   （已完成）讲师端的崩溃处理代码已经完全实现，并且已经升级了，主要是注册未捕获异常的方式完成；

23. 各种课件的录制范例 => http://www.bjycsy.com/superiorit

24. NativeDesktopService又在作怪，360只能清理表面，SpyHunter5这个软件能比较清晰专业的显示问题所在；
    I:\工具软件\SpyHunter
    Logitech BRIO 高清摄像头，效果不错，需要Win10才能支持；
    happyhope.net 数据备份地址 => 酷爸 => I:\PHPDev\APM\linux\happyhope\mysql\data\wan
    happyhope.net 代码备份地址 => 酷爸 => I:\PHPDev\APM\linux\happyhope\wan\wxapi
    happyhope.net 代码关联地址 => 酷爸 => I:\PHPDev\APM\linux\wan\wxapi => https://www.myhaoyi.com/wan
    Snipaste(截图工具) | Inpaint(去水印工具) | RemoveLogoNow(去视频水印) | Image Tuner(批量处理) | 500th Video Converter(格式转换) | 

    腾讯视频下载工具：维棠，可以不用格式转换，直接就是MP4格式；
    https://www.52pojie.cn/thread-729577-1-1.html
    https://www.rrxiu.net/ => 各种类似易企秀的模版
    https://jinshuju.net/ => 在线表单工具 => 有50条记录限制 => 499/年 => 无广告，很好用；
    https://www.wenjuan.com => 在线表单工具 => 大量功能开放免费，就是有广告，用起来体验一般，不太好用；

25. 谷歌开发者大会 - 2018
    Flutter可以维护一份代码，支持iOS和Android的应用；
    ARCore，主要用在小米和华为手机使用；

26.（不处理）微信支付服务商
    A：（未完成）微信支付服务商申请条件：微信认证的企业类型服务号，微信支付服务商目前只面对企业认证的服务号才能开发申请。
    B：（未完成）https://pay.weixin.qq.com/index.php/partner/public/home
    C：（未完成）只需要申请一个微信支付帐号，绑定到小程序就可以，只能通过微信认证的企业服务号，才能申请开通微信支付服务商；
    D：（未完成）在微信支付服务商下面申请的特约商户帐号是无需缴纳300元认证费用的，资金直接流入特约商户帐号，服务商可以看到流水；
    E：（未完成）我们没有可卖商品，我们是技术服务商，一次需要申请微信支付服务商，需要首先申请开通一个服务号“浩一云”，认证，申请微信支付服务商；

2019.06.28 - 2019.07.05 - 小程序
===============================================================================================
1.（已完成）将所有的门店信息修改为“幼儿园”；
  （已完成）用户管理 => 排序方式进行调整，按修改时间进行降序，而不是按幼儿园编号进行排序；
2.（不处理）增加家长充值功能，增加家长绑定学生信息功能，增加上课签到功能
3.（已完成）增加班级管理功能，是以幼儿园为基础的班级管理，班级管理 => 课程科目(wk_subject) => 班级分类(wk_grade) => 幼儿园(wk_shop) => 学生列表(wk_user)
  （已完成）wk_subject  => 网站端，主题科目表，记录系统支持的科目信息，例如：乐高课|科学课|培训课
  （已完成）wk_grade    => 网站端，阶段等级表，小班|中班|大班
4.（已完成）<van-field> 包含了 <van-cell> 无法传递两级的class，只能通过<van-field>提供的custom-style传递，custom-style="align-items:center;"
5.（已完成）当前版本的小程序并没有完全完成，由于发展方向发生改变，在幼儿园进行远程双师不现实，有人在山东临沂进行尝试失败，幼儿无法专注在屏幕前面听远程老师上课；
  （已完成）山东临沂的小龙人集团，想利用双师直接培训家长，利用双师进行家长课堂的培训，幼儿园老师开展小班课，与幼儿和家长一起进行多人会议互动，利用家长笔记本上的摄像头；
  （已完成）需要完成任务1 => 学生端与老师端合并，默认都是学生端，在数据库中有wk_gather标记，可以远程或小程序修改终端类型为讲师模式，讲师毕竟有限；
  （已完成）需要完成任务2 => 讲师端的PPT打开模式需要修改成，直接插入PPT文件模式，而不是窗口截图模式，这样老师在讲课时不用来回跳跃切换；

6.（已完成）讲师端的PPT打开模式需要修改成，直接插入PPT文件模式，而不是窗口截图模式，这样老师在讲课时不用来回跳跃切换；

8.（已完成）中幼联合，2019.07.01，提出的修改意见汇总：
  （已完成）互动教室 => 互动学生端；图像 => 背景图片；图像幻灯片 => PPT文件；媒体源 => 视频文件；显示器捕获 => 屏幕分享；
  （已完成）窗口捕获 => 窗口分享；色源 => 去掉；视频捕获设备 => 本地摄像头；音频输入设备 => 去掉；
  （已完成）右键菜单需要修改显示顺序 => 编辑尺寸(源) | 开启浮动(源) | 关闭浮动(源) | 云台控制 | 排序(源) | 绿幕抠像
  （已完成）发布新版本，升级到 1.2.7，主要修改 讲师端 添加数据源菜单命名等相关菜单信息；
  （已完成）讲师端，新加数据源时，需要重排待选区的数据源，浮动窗口除外，这样避免混乱；
  （已完成）讲师端，开启浮动数据源时，位置计算有问题，不是按照从左到右排列，而是直接到最左边，有可能是显示顺序造成的；OpenFloatSource
  （已完成）讲师端，关闭浮动数据源时，同样需要重排待选区数据源，排除0点位置和已经浮动的数据源；ShutFloatSource
  （已完成）发布新版本，升级到 1.2.8，主要修改 讲师端 窗口重排的问题；
  （已完成）讲师端，第二行待选区，进行浮动显示时，已经自动将浮动窗口置于了最顶层，这样就能叠加显示；
  （已完成）讲师端，第二行待选区，在双击切换位置时，需要把新的0点窗口置于最底层，这样能避免遮挡；
  （已完成）讲师端，由于set_order会重选焦点，需要重置焦点，OBSBasic::doSceneItemExchangePos()
  （不处理）讲师端，将一些经常使用的快捷操作放在数据源窗口的内部或边缘，形成操作按钮，便于快速点击；

9.（已完成）PPT的捕获通过插入PPT文件的形式加入，不要通过窗口或显示器捕获的形式来进行PPT的播放，参考ClassIn和拓课云；
  （已完成）利用QT的QAxObject接口，打开PPT文件，进行格式转换成jpg文件序列，保存到obs-teacher目录下面；
  （已完成）这种方式的前提是需要本机安装PowerPoint软件，对于PPT动画无法完全转换，都是转换成静态图片；
  （已完成）这样可以提供两种方式支持PPT文件，一种是窗口捕获模式，一种是文件转换模式，都需要本机安装PPT软件；
  （已完成）https://docs.microsoft.com/zh-cn/office/vba/api/powerpoint.application.visible => PPT标准文档
            E:\GitHaoYi\openmeeting2\DocShare\ConvertDocThread.cpp => 相关QT代码
            E:\GitHaoYi\lxpptDemo\lxpptDemo\lxpptdemo.cpp => 相关QT代码
            C:\Users\Jackey\Desktop\obs-code\PPT => PPT相关代码
  （已完成）讲师端，重新开启幻灯片功能，改造成输入PPT文件，自动转换成JPG，存放到obs-teacher目录下，自动关联成幻灯片目录；
  （已完成）讲师端，幻灯片功能改成“PPT文件”，只允许 .ppt 或 .pptx 格式的文件输入加载；
  （已完成）讲师端，幻灯片存放目是有ppt文件的全路径计算出来的md5值存放的；obs-teacher/ppt/
  （已完成）讲师端，简单改造“视频文件”，只允许选择 视频文件，默认选择 本地文件；
  （已完成）幻灯片，隐藏幻灯片预览显示框，隐藏可见性的行为，隐藏幻灯片模式(手动)，隐藏转换(幻灯片)
  （已完成）幻灯片，隐藏幻灯片之间时间，隐藏过渡速度(800)，隐藏循环，隐藏幻灯片完成时隐藏，隐藏随机播放；隐藏图像文件；
  （已完成）obs-app.cpp::MakeUserDirs() => 增加PPT转换目录，每个PPT文件会形成一个MD5计算目录，存放转码后的JPG图片序列；
  （已完成）讲师端，已经将PPT转换成JPG功能融入数据源的添加过程，需要进一步的增加一些易用性交互功能；
  （已完成）讲师端，新增 CPPTWait|CPPThread，模拟PPT转换时的等待状态，利用QMetaObject::invokeMethod()
  （已完成）讲师端，幻灯片所在图片目录读取顺序并没有按照图片文件名的标识来读取，顺序有点混乱；需要按数字序号排序；
  （已完成）讲师端，幻灯片利用darray存放image_file_data结构，darray并没有提供排序算法，可以借助qsort进行自定义排序；
  （已完成）讲师端，新增parse_slide(ent->d_name)解析序号，存放到image_source的settings当中，供排序时使用；
  （已完成）幻灯片，修改向前翻页的切换效果，现在总是从右向左滑动，向前翻页时改为从左向右滑动；
  （已完成）transition-slide.c::slide_update()专门有配置滑动方向的接口 => direction
  （已完成）obs-slideshow.c::ss_next_slide()|ss_previous_slide()都需要针对slide的transition做方向设定；
  （已完成）幻灯片，在窗口上增加左右滑动的按钮，代替快捷键的上一页下一页的命令触发操作；window-basic-preview.cpp::DoSelect()
  （已完成）幻灯片，将hotkey保存到配置，鼠标点击屏幕时提取配置，然后激发hotkey，以宽度的50%为界限，区分向前翻页还是向后翻页；
  （已完成）发布新版本，升级到 1.2.9，主要修改 讲师端 支持.ppt|.pptx格式；

10.（不处理）讲师端，尝试添加browser数据源这个扩展工程，直接可以代替捕获浏览器屏幕的模式，相当于直接支持.ppt文件一样，提高用户访问网站的交互体验；
   （已完成）https://blog.csdn.net/liukang325/article/details/55254267/ => obs编译说明 => obs-browser（CEF内核浏览器插件）
   （已完成）https://blog.csdn.net/gengxt2003/article/details/79070741 => 有关obs的详细编译过程
   （已完成）http://opensource.spotify.com/cefbuilds/index.html => CEF版本下载 => Standard Distribution，需要自己用cmake CMakeLists.txt生成编译工程；
   （已完成）https://github.com/obsproject/obs-browser/tree/5f830dd87c7cb3b228a0bb408039590829a3725d => 说了需要的版本号码 => 2987
   （已完成）http://opensource.spotify.com/cefbuilds/cef_binary_3.2987.1601.gf035232_windows32.tar.bz2
   （已完成）才会产生obs-browser需要的CEFWRAPPER_LIBRARY|CEFWRAPPER_LIBRARY_DEBUG|CEF_LIBRARY|CEF_LIBRARY_DEBUG
   （已完成）E:\obs-studio\UI\data\license => 这个目录不能删除，否则cmake-gui失败；
   （已完成）最终测试发现，obs-browser启动时容易崩溃，还是不要添加到工程配置当中；
   （已完成）由于obs-browser更新快，使用的CEF库也更新非常快，比配有一定的难度；
   （已完成）目前针对obs-browser的使用迫切度没有那么高，况且obs-browser需要的扩展支持太过庞大，暂停使用；

2019.06.18 - 2019.06.27 - 讲师端|学生端问题改进
===============================================================================================
1.（已完成）讲师端，需要显示多个互动教室，每个互动教室拉取的学生端摄像头编号不能重复；
  （已完成）讲师端，多个互动教室，可以给每个待选窗口标上文字信息，以便快速辨认；注意字体动态缩放；
  （已完成）讲师端，修改成 => 讲师端可以显示多路学生端在线画面，投影时都投影到一个整体屏幕当中；
  （已完成）服务器，需要先进行房间推流优化改造，优化CRoom，优化学生推流转发机制，优化老师端推流转发机制；
  （已完成）讲师端，远程登录接口去掉了摄像头通道信息，在单独的拉流命令中填写，以前是混在一起操作；
  （已完成）讲师端，修改拉流探测机制，现在是多个通道，win-rtp之前是单一通道，需要进行优化调整；
  （已完成）讲师端，OBSBasicSourceSelect，去掉了针对win-rtp资源的唯一限制，可以加载多个rtp资源；
  （已完成）讲师端，win-rtp插件，需要改造成适合多路数据的形式，去掉全局共享变量的方式；
  （已完成）讲师端，修改摄像头选择机制，不要在列表中进行变化选择，在用户点击确认之后进行操作，已经被占用的摄像头通道需要标记，相同通道编号只能加载一次；
  （已完成）讲师端，服务器，不要传递场景会话编号，只传递摄像头编号，让讲师端通过摄像头编号去查找场景会话数据源，因为现在是多路模式；
  （已完成）讲师端，第三方音频的判定和输出是依据当前所处的互动教室的焦点状态决定的，需要通知服务器当前交互的学生端摄像头编号，来做为第三方的判断条件；
  （已完成）服务器，讲师端TCP离线时，需要重置CRoom里面的流量统计和学生焦点推流统计；
  （已完成）讲师端，云台控制，当焦点变化时需要更新云台控制的摄像头编号，不能用全局变量保存；
  （已完成）讲师端，新增 文字数据源，可以插入文字资源，但不在右键菜单中显示出来，只能隐含增加；
  （已完成）讲师端，新增 图片数据源，可以插入图片资源，只需要打开obs的开关，之前有，是我们主动关闭的；
  （已完成）讲师端，添加第三个窗口时，会跟第二个窗口的位置重叠，添加第6个窗口时会跟第5个窗口重叠；
  （已完成）讲师端，这个叠加问题，可能是只用了一个顶点来判断位置造成的，需要多增加一点偏移来进行判断；
  （已完成）学生端，需要改进支持同时多路通道被拉取，目前只能一路通道被拉取，回音消除和通道上传都需要进行改进；
  （已完成）学生端|讲师端|服务器，发现一个巨大的BUG => static 的乱用 => 在多路推流时会造成数据混乱；
  （已完成）讲师端，win-wasapi插件，doFindRtpAudio()，针对互动教室的音频选择需要改进，静音与输出判断之后，还需要是否处于混音状态来判断；
  （不处理）讲师端，多路音频输出的混音问题，本地回放的多路音频，需要进行集中混音之后，再投递给麦克风进行回音消除；
  （不处理）讲师端，目前的做法 => 没有混音，只投递互动教室的音频进行回音消除，现在，由于开启了多路互动教室，造成回音消除的代码出错；
  （不处理）讲师端，目前的测试 => 添加两路本地媒体源，本地回放声音，然后混音，再投递给麦克风线程进行回音消除，通过存放音频数据文件来验证回音消除的效果；
  （不处理）讲师端，需要彻底了解多路音频的混音算法，到底是怎么进行混音处理的，每路音频的缓存是如何界定的；
            静音判定接口 => source_muted(source, os_time) => 可以不用管，混音时会根据缓存的量进行，一旦静音，就不会向缓存投递数据；
            obs自己有音频的输出控制，这个配置是指输出网络音频的配置，跟系统配置的声音配置不同；
            obs的source->monitor是指每个数据源获取扬声器的音频配置，是声音播放配置；
            每一个monitor当中需要增加一个circlebuf，用来缓存投递给扬声器的声音数据，便于另一个线程进行混音；
            专门的声音处理线程会定期读取每一个monitor的扬声器缓存进行混音，混音完毕之后投递给麦克风数据源；
            混音线程每次处理相同的数据量，暂定为16KB，是一个固定的缓存，每次处理前清空，每个monitor处理之后需要删除已处理的缓存；
  （不处理）讲师端，https://blog.csdn.net/liuhengxiao/article/details/83059314 => 有关obs音频混音流程；
  （不处理）讲师端，混音模式代码 => C:\Users\Jackey\Desktop\obs-code\混音-消除\teacher => 多路混音的回音消除有问题，消除不充分；
  （已完成）讲师端，重新修改多路互动教室的展示方式，只有处于焦点状态的互动教室数据源才能在本地回放，否则处于静音状态；
  （已完成）讲师端，这样处理的目的是为了防止多路互动教室的声音引发本地声音混乱，同时，回音消除也无法有效处理多路混音；
  （已完成）讲师端，先将多路混音的代码进行恢复；最终还是在wasapi-output.c当中进行直接的回音投递工作，这样才能有效回音消除；
  （已完成）讲师端，setAudioMixer 当中设置 focus_mix 参数，然后on_audio_playback当中使用，只播放并消除处于焦点状态的互动教室音频；
  （已完成）发布新版本，升级到 1.2.0，包括 讲师端|学生端|服务器|网站 都要同步升级；
  （已完成）讲师端，有关多路学生显示的回音消除的处理还是有问题，目前这种焦点模式还是不正确，还是要全部打开互动教室声音，全部投递回音消除；
  （已完成）讲师端，wasapi-output.c当中不要主动屏蔽非焦点互动教室，只投递互动教室的音频进行回音消除；
  （已完成）发布新版本，升级到 1.2.1，多路学生的声音放开限制，都输入回音消除进行处理，潜在的回音消除问题后续再处理；
  （已完成）讲师端，回音消除还是要使用多路混音的思路，否则，无法实现多路学生的应用模型；
  （已完成）讲师端，多路混音回音消除思路改进 => 利用obs自身的混音机制，将轨道3做为混音回放轨道；
  （已完成）讲师端，轨道3多路混音后统一本地播放输出，而不是各个资源单独输出，这样就能保证所有的资源都统一输出，然后统一投递给回音消除器进行声音消除；
  （已完成）讲师端，整个思路还是要归一化，参照录音的方式，混音之后统一输出，而不是数据源单独输出的方式；
  （已完成）讲师端，利用两个视频文件进行多路混音输出播放的测试，最终目标 => 只要通过讲师端播放的音频都是混音后一起输出，而不是单独输出；
  （已完成）讲师端，需要先屏蔽目前讲师端的本地每个数据源单独播放输出的方式；麦克风数据源永远不要混入轨道3，因为，轨道3是要被本地回放的轨道；
  （已完成）讲师端，音频轨道1(网络输出)混音输出流程 => AdvOut:TrackIndex:1 => AdvancedOutput::StartStreaming()
  （已完成）讲师端，音频轨道2(录像输出)混音输出流程 => AdvOut:RecTracks:2 => AdvancedOutput::SetupRecording() => obs_output_set_audio_encoder()
  （已完成）讲师端，audio-io.c:input_and_output => obs-audio.c:audio_callback => obs-source.c:obs_source_audio_render => obs-audio.c:mix_audio

2.（已完成）obs内部资源结构的层次结构有了一个大致了解 => obs_view是最外层，有64个source频道 => obs_source_t * channels[MAX_CHANNELS] => obs_set_output_source
  （已完成）0 => transition_source => 下面挂载 scene source => 下面挂载普通 source
  （已完成）1 => DESKTOP_AUDIO_1 本地桌面播放音频 => 目前处于屏蔽状态，后续可以考虑放开，这样可以有更多扩展；
  （已完成）2 => DESKTOP_AUDIO_2 本地桌面播放音频 => 目前处于屏蔽状态，后续可以考虑放开，这样可以有更多扩展；
  （已完成）3 => AUX_AUDIO_1 本地麦克风音频 => wasapi_input_source；
  （已完成）4 => AUX_AUDIO_2 本地麦克风音频 => 目前处于屏蔽状态；
  （已完成）5 => AUX_AUDIO_3 本地麦克风音频 => 目前处于屏蔽状态；
  （已完成）了解上面的频道结构对audio_callback音频的混音处理非常重要，每次的音频混音都需要进行排序和根节点(obs_view频道)的重新更新；
  （已完成）obs->audio->render_order => normal_source|scene_source|transition_source|wasapi_input_source
  （已完成）obs->audio->root_nodes   => 0(transition_source)|3(wasapi_input_source)
  （已完成）obs->audio->render_order => 音频数据源的渲染与混音流程，根据数组下标依次来进行渲染或混音；
            normal_source => process_audio_source_tick => 渲染 => 将数据源input里面的音频根据轨道混音状态，依次拷贝到output缓存，等待进一步混音使用；这个混音状态是数据源自身是否在轨道中进行混音的标志 => audio_mixers
            scene_source => scene_audio_render => 混合 => 将当前场景下所有的普通数据源已渲染的output音频混合到当前场景的output缓存当中；每个普通数据源都要遍历6个混音轨道，根据混音标志进行混音；这个混音标志是混音输出标志(网络|录像|播放)，与数据源自身的混音标志不同；
            transition_source => obs_transition_audio_render => 拷贝 => 将场景里面混音后的全部数据(6个轨道)全部直接拷贝到变换数据源的output音频缓存当中，目前的配置都是直接拷贝，没有进行变换操作；
            wasapi_input_source => process_audio_source_tick => 渲染 => 将数据源input里面的音频根据轨道混音状态，依次拷贝到output缓存，等待进一步混音使用；这个混音状态是数据源自身是否在轨道中进行混音的标志 => audio_mixers
  （已完成）obs->audio->root_nodes => obs_view里面有效频道的混音过程 => 将节点输出音频最终混合到 audio->mixes 当中，所有6个轨道都要进行混合；
            0(transition_source) => mix_audio => 混合全部轨道，每个轨道混合有效声道 => source已经做了有效轨道处理，无效轨道数据重置为0
            3(wasapi_input_source) => mix_audio => 混合全部轨道，每个轨道混合有效声道 => source已经做了有效轨道处理，无效轨道数据重置为0
  （已完成）input_and_output => 音频线程主要处理函数执行过程
            /*get mixers*/ => 累加每个轨道使用标志 => audio_mix.inputs => 记录每个轨道被输出的格式，例如：网络输出|录像输出|播放输出等等
                           => 目前轨道1被输出1次，专门进行网络压缩输出，输出格式跟软件配置保持一致；
                           => 目前轨道2被输出1次，专门进行录像压缩输出，输出格式跟软件配置保持一致；
                           => 目前轨道3被输出1次，专门进行本地播放输出，输出格式跟软件配置保持一致，在进行具体播放时，需要根据本地系统音频配置，进行重采样处理；
                           => 注意：每个轨道都可以被输出多次，由于目前网络输出|录像输出|播放输出 的音频数据都不一样，所以，采用了多个轨道的方式；
            /* clear mix buffers */  => 将audio->mixes所有6路混音轨道上的音频缓存置0，
            /* get new audio data */ => audio->input_cb => audio_callback => 详见上面的分析，对节点分类渲染或混音，最终将混音后的数据存入audio->mixes当中；
            /* clamps audio data to -1.0..1.0 */ => clamp_audio_output => 消除混音后的音频尖峰，将音量控制在-1.0与1.0之间，避免爆破音；同时，只处理audio_mix.inputs有效的轨道，即被输出使用到的轨道才处理；
            /* output */ => do_audio_output => 根据每个轨道的audio_mix.inputs配置，调用对应的callback进行混音后的音频输出工作；同一个轨道可能会被输出多次；
  （已完成）audio_mix.inputs是如何被填充和赋值的，当前使用到的网络输出|录像输出的配置是如何进行的：
            obs_output_begin_data_capture => hook_data_capture => start_audio_encoders => obs_encoder_start => obs_encoder_start_internal => 
            add_connection => audio_output_connect => audio_input_init(输入与输出格式转换)
  （已完成）ResetAudioDevice => 自动屏蔽麦克风数据源的第三轨道混音，第三轨道混音(索引编号是2)专门用来本地统一播放使用的混音通道；
  （已完成）doLocalPlayAudioMixer => 轨道3 => 输出给本地播放，数据源大于OBS_MONITORING_TYPE_NONE时，才进行混音处理；
  （已完成）OBSAdvAudioCtrl::monitoringTypeChanged => 只要音频监视输出大于OBS_MONITORING_TYPE_NONE时，就需要将当前数据源音频的轨道3设置为混音状态；
  （已完成）obs_sceneitem_t一定是不相同的，每个obs_sceneitem_t对应一个obs_source_t，多个不同的obs_sceneitem_t可以对应一个相同的obs_source_t
  （已完成）这就是为什么只能从obs_sceneitem_t找到对应的obs_source_t，而不能反过来从obs_source_t找到对应的obs_sceneitem_t，因为一个obs_source_t可能对应一个列表；
  （已完成）obs_source_set_monitoring_type => 修改音频监视本地回放流程，不要挂载本地声音回放过程；
  （已完成）为第三轨道增加audio_mix.inputs配置，便于do_audio_output调用scene的monitor进行本地播放；
               audio_output_connect   => 通过这个接口进行第三轨道的音频本地播放参数配置，需要配置相关参数如下：
                     audio_t *audio   => obs_get_audio() => obs->audio.audio
                          size_t mi   => 2 => 混音轨道3(索引编号是2)
     audio_convert_info *conversion   => 通过audio_output_get_info进行转换获得，详见get_audio_info()
     audio_output_callback_t callback => 构造scene的音频数据回调函数，就是将音频数据包如何挂载到scene上的monitor的回调中转函数；
                          void *param => 具体执行中转回调的source对象指针，最终挂载到monitor上面进行具体的播放工作；
  （已完成）obs_scene_create_monitor  => 增加新接口，专门在scene的source上创建新的唯一监视器；
  （已完成）obs_scene_destory_monitor => 增加新接口，删除在scene的source监视器；
  （已完成）receive_scene_audio => 在最终播放混音后的轨道3数据时出现问题，无法正常播放，需要进行特定的存盘进行测试验证；
  （已完成）跟踪检测结果发现，没有进行持续的混音，只混了很少的数据，就停止传输音频数据了，那就是混音的源头上有问题；
  （已完成）是由于OBS_MONITORING_TYPE_MONITOR_ONLY配置，会阻止音频数据的进一步向下传递，造成没有把数据源的音频数据投递给播放层；
  （已完成）需要修改OBS_MONITORING_TYPE_MONITOR_ONLY，让音频数据能够继续往下投递进行混音操作；OBS_MONITORING_TYPE_MONITOR_ONLY跟OBS_MONITORING_TYPE_MONITOR_AND_OUTPUT一样了；
  （已完成）obs-source.c:1302 => 控制音频数据是否继续对外输出的开关，由于本地播放的调整，需要总是对外输出...
  （已完成）发布新版本，升级到 1.2.3，主要升级讲师端，利用多路混音后的轨道3进行本地播放，形成归一化，进行回音消除，这样效果非常好；

3.（已完成）学生端|讲师端，将升级检测放在进程启动之后，而不是登录成功之后，登录之前就检测，这样一开始就能自动升级而不是登录之后才自动升级；
  （已完成）TimedCheckForUpdates()转移到CLoginMini当中，而不是放在原来的OBSBasic当中；OBSBasic当中也可以右键强制升级检测；
  （已完成）发布新版本，升级到 1.2.4，主要改进升级检测，从OBSBasic转移到CLoginMini当中；
  （已完成）修正 win-update.cpp 当中 App()->GetMainWindow()的问题，可能是CLoginMini登录窗口；
  （已完成）发布新版本，升级到 1.2.6，主要改进升级检测，修正 win-update.cpp 当中父窗口获取的问题；

2019.05.18 - 2019.06.17 - 讲师端|学生端问题改进
===============================================================================================
1.（已完成）可能由于分辨率的原因，拉伸显示画面，造成微信无法正确扫描识别二维码，从而无法打开学生端软件；
  （已完成）永丰小学的学生端的分辨率是1024*768，但是怎么调试分辨率都会出现无法扫码成功的问题；
  （已完成）E:\GitHub\HaoYiYun\Document\云教室\测试问题\永丰小学 => 对图片进行宽度缩小后，就能快速扫码；
  （已完成）也可以在微信扫码时，斜着扫，变相的拉伸，需要不断的尝试也可以进行扫码，华为手机图片编辑不能进行图像缩放；
  （已完成）找了半天，安卓手机的SnapSeed可以进行部分缩放，但效果不好； 
2.（已完成）登录界面，可以配置成第三方扫码登录模式，目前需要对接第三方的微信网站应用登录模式；
  （已完成）这种登录模式，牵涉一个难点，如何进行页面跳转和对接，第三方用户必须在我们系统中有一个对应；
  （已完成）还有一个难点，就是如何用QT实现WEB页面的微信网站应用的二维码显示；
  （已完成）https://blog.csdn.net/evinxu/article/details/82761017 => QT网页交互；
  （已完成）C:\Users\Jackey\Desktop\obs-code\QtWebEngine => 初步试验通过 => 放弃这种网页交互模式，需要额外增加打包内容，太过庞大；
  （已完成）第三方扫码模式，可以进一步简化改进如下 => 采用二维码场景参数，直接获取二维码图片数据，直接显示的方式；
            wk_user表新增一个is_third标志，默认为0(不是第三方)，为1表示是第三方用户标志；
            快捷方式添加 -z URI参数(表示特定登录模式，附带特地的URI启动参数，不带URI第三方启动无效)，onTriggerTcpConnect之后得到二维码场景值；
            加入场景值参数%1_%2_%3调用第三方生成二维码图片接口，以网络图片数据方式获取并显示出来；第三方接口 => URI/scene/%1_%2_%3
            用户打开微信扫描，获取到场景值，第三方将用户信息+场景值$arrUser['scene']的数组信息用json编码反向调用 => https://www.qidiweilai.com/wxapi.php/Third/login/wx_json/xxx
            Third/login/wx_json/xxx => 解析出登录用户信息，先写入数据库得到用户编号；再用场景值通知服务器中转给显示二维码的进程(扫码成功)；最后返回给第三方调用结果；
            我们返回数组err_code|err_msg|user_id返回调用结果，返回通过json编码的字符串；
            第三方弹框显示输入房间密码$arrJson['room_pass']，用户输入完毕之后调用接口 => https://www.qidiweilai.com/wxapi.php/Third/check/wx_json/xxx
            我们返回数组err_code|err_msg|room_id返回调用结果，返回通过json编码的字符串；
            第三方拿到user_id|room_id|scene之后，数组进行json编码，调用接口 => https://www.qidiweilai.com/wxapi.php/Third/success/wx_json/xxx
            我们返回数组err_code|err_msg返回调用结果，返回通过json编码的字符串；
  （已完成）将第三方的接口改造成 API 模式，修改 nginx.conf，API入口修改为 https://www.qidiweilai.com/api/v1/ => APIAction.class.php
  （已完成）参考以前的API文档写法，完成第一版API接口文档 => E:\GitHub\HaoYiYun\Document\《启迪云-API接口.doc》
  （不处理）还需要进一步完成 js 交互过程测试，从而实现第三方微信登录过程；中转方式可以不用网页端用js反向调用C++接口；
  （已完成）讲师端|学生端，访问第三方连接显示二维码(带上特定参数)，用户扫码，第三方网站认证，第三方网站调用启迪网站接口，带上参数触发反向调用，关闭登录窗口；
  （已完成）后来了解到，中幼联合也是用exe进程，不是单纯的网站，因此，这种网页模式的登录不适用了，他们想做成“钉钉PC版”的样子，做成平台，做成应用的集成平台；
  （已完成）发布新版本，升级到 1.2.2，支持第三方微信扫码登录模式，通过外接参数 -z https://xxx
  （已完成）之前发生的蠕虫修改 html|dll 的问题，造成很多dll被修改了，最终靠360安全卫士给清理干净了；在打包过程中还是遇到了之前用暴力删除造成的问题；
3.（不处理）学生端，右侧播放画面窗口，需要新增其它在线学生通道的预览画面窗口；全屏时，也跟着一起全屏；其它学生的预览窗口可以由老师控制显示或关闭；
4.（不处理）讲师端，右侧去掉 统计和退出 按钮，加入 开启或关闭浮动 | 开启或关闭学生交互声音 | 开启或关闭学生远程云台控制；
5.（已完成）讲师端，录像内容需要录制交互学生的声音（只录制处在推流状态的交互学生，如果交互学生不在推送状态，不录制，或者全部录制？）还需要做各种尝试，比如本地视频声音的录制？录制声音的输入方式？只要有推送就有录制？不要进行过多的人为干预？
  （已完成）讲师端，所有待选区域的音频和视频都不会被录制，麦克风除外，需要找到之前处理的切换方式，以及麦克风控制方式，还要解决互动教室音频录制方式；
  （已完成）讲师端，可以采用多路音轨的方式来解决这个问题，obs支持同时6路音频的单独压缩，直播用音轨1，录像用音轨2；
  （已完成）讲师端，音轨1和音轨2都要采用待选切换模式，唯一不同的是，互动教室的声音在音轨2上不要强制屏蔽 => doSceneItemExchangePos()
  （已完成）讲师端，互动教室的音频输出方式需要修改成“监视器和输出”，这样能够让数据顺利进入轨道2进行录像工作；
  （已完成）讲师端，需要默认修改系统的音频录制参数是“轨道2”，默认是“轨道1”，这个需要进行软件硬编码修改；
6.（不处理）讲师端，在进行学生画面投影时，需要进行多窗口显示，中间有一个主画面(正在交互学生画面)，旁边一圈是其它所有在线学生动态截图；
  （不处理）讲师端，老师可以自由的切换交互学生画面和待选学生画面；采用单击选中，双击切换的模式；
7.（已完成）讲师端和学生端，需要新增vs2015.x86的检测并自动下载安装的检测机制，需要参考obs的具体实现代码；
  （已完成）讲师端和学生端，E:\obs-studio\UI\win-update\updater\updater.cpp，都是利用udpater.exe进行升级判断；
  （已完成）讲师端和学生端，并不能完成进程启动前的自动升级需求，因此，调试完毕，但是仍然不启动这个升级功能；
  （已完成）2019.08.02，重新更新并启动了自动更新功能，但并不能解决进程启动前的自动升级需求，即无法解决缺少运行时库的问题；
8.（已完成）讲师端，待选区窗口超过5个以上时的界面处理方式，需要用一个左右箭头进行控制，还需要考虑浮动窗口的问题；
  （已完成）讲师端，待选区窗口超过5个以上时，开启和关闭浮动操作会出现问题，由于窗口的位置发生越界，造成显示问题；
  （已完成）讲师端，window-basic-source-select.cpp:AddSource()，需要改进显示方式，待选区超过5个窗口需要修正显示；
  （已完成）讲师端，待选区左右翻页按钮已经绘制完成，使用的是QPushButton，并计算了显示位置；OBSBasicPreview::CreateBtnPage()
9.（已完成）讲师端，新增 可以浮动多个数据源，目前只能浮动一个数据源，可以浮动多个数据源，由用户自行选择；
  （已完成）讲师端，修改了渲染代码，支持渲染多个浮动窗口的功能改造；
  （已完成）服务器，修正了讲师端登录之后没有反馈，造成无法推流的问题；
10.（已完成）有关计费方式的调整，详见2019.03.17的第10条的最后部分；还差讲师与机构的绑定，这部分需要和小程序结合改造；
11.（已完成）辉声乐22HA(128元)与SN700(400元)实测报告 => F:\MP4\222.aac => 128元的拾音效果更好，400元的相对浑浊，时大时小；
   （已完成）辉声乐22HA灵敏度横向垂直LINE-IN模式；SN700灵敏度调节到最小，专为更大空间设计，但实测效果不好；
   （已完成）使用拾音器时，海康IPC的音频参数配置 => AAC|32kHz|64kbps|LineIn|50|环境噪声过滤关闭，拾音音量不能太大，太大杂音太重；
   （已完成）辉声乐22HA与海康IPC自带麦克风实测报告 => F:\MP4\333.aac => 自带的效果好一点点 => AAC|32kHz|64kbps|50|环境噪声过滤关闭
   （已完成）之前在金二小的IPC参数配置 => MicIn|85|环境噪声过滤开启 => 太大的拾音量与额外处理，或许造成比较大的杂音；
   （已完成）辉声乐22HA之前有电流声，现在已经加入了NS模块解决；SN700虽然加入了降噪功能，但是有声音亏损，感觉时大时小；
   （已完成）最终还是采用辉声乐22HA，参数配置 => AAC|32kHz|64kbps|LineIn|50|环境噪声过滤关闭；灵敏度横向垂直LINE-IN模式；
12.（已完成）专门做音频 => http://www.twirlingai.com/，网络应用少，主要做硬件设备，可以定制；
   （已完成）墙壁反射回音消除，大多采用吸音墙纸的方式来解决，几乎不会用软件算法的方式解决，定制成本太高；
   （已完成）淘宝上有大量的吸音墙纸售卖，大概都是70cm*77cm => https://item.taobao.com/item.htm?id=587091491779
13.（不处理）学生端，利用腾千里的智能笔SDK，开发智能书法教室交互软件，让老师和学生在电子屏一体机上呈现书写过程，老师可以查看每个学生的实时或录像数据；
   （不处理）学生端，老师可以直接多屏幕展示，对每个学生的画面进行实时讲解，老师不用下讲台，学生不用上讲台，实现真正的智慧教室；
   （不处理）学生端，实现真正的学生|老师上课过程数字化，这是双师教学的第一步，也是最重要的一步；下一步可以考虑实验课，使用自定义的海康摄像头，进行试验课程的音视频数据化；
14.（已完成）讲师端|学生端|OBS，都不支持WinXP系统，只支持Win7以上系统；
15.（已完成）学生端，中幼联合一体机，在进行海康摄像头画面切换时，会发生黑屏现象，无法显示画面；
   （已完成）讲师端，发现是由于讲师端的数据源配置造成的问题，删除所有数据源，重新配置之后问题解决；
16.（已完成）https://blog.csdn.net/huangyifei_1111/article/details/77573944，windows上用这个编译ffmpeg相当给力，可以转换成vs的工程进行单步调试。
17.（已完成）如果第一个窗口是互动教室，添加新资源之后会覆盖第一个窗口的位置，造成窗口重叠的现象；
   （已完成）讲师端，doSceneItemLayout()，判断坐标位置的窗口对象时，x和y都进行5个像素的偏移，不要只用最角落的顶点，会造成误差；
   （已完成）讲师端，对于弧形的显示器的分辨率问题，0点位置有偏差，几乎百分百的出现由于0点位置偏差造成的窗口重叠问题；
18.（已完成）2019.06.19 => 折腾一下午的翻墙总结：
   （已完成）LEDE是KoolShare论坛提供的软路由，但是由于国内管得严，大量翻墙插件已经被阉割了；
   （已完成）I:\工具软件\LEDE => 在U盘上运行软路由，需要配置SS|SSR|V2Ray服务器或机场，才能变身翻墙路由器；
   （已完成）I:\工具软件\LEDE\Win32DiskImager-0.9.5-binary => 这个工具写入的U盘，Win7无法识别，需要用 HP U盘格式化工具 V2.0.6.EXE 这个工具格式化触发系统识别；
   （已完成）G:\Jackey\下载软件\翻墙下载 => 先翻墙，访问 https://free-ss.site/ 加入大量免费ss服务器到 G:\Jackey\下载软件\翻墙下载\ShadowsocksR-win-4.9.0，最终实现高速多服务器均衡翻墙；
   （已完成）折腾中，还遭到了木马攻击，后来连续用360全盘扫描两次才最终解决掉；

2019.03.17 - 2019.05.17 - 小程序
===============================================================================================
1.（已完成）小程序 => 正式开启“启迪双师”的小程序开发当中，需要先进行环境熟悉和搭建；
            E:\GitHub\HaoYiYun\myhaoyi\wxapi\Lib\Action\MiniAction.class.php => “中心服务器”小程序接口代码
            E:\GitHub\HaoYiYun\educate\wxapi\Lib\Action\MiniAction.class.php => “启迪未来双师”小程序接口代码
            E:\obs-studio\wechat\qidi => “启迪未来双师”的小程序代码目录
            E:\GitHub\HaoYiYun\myhaoyi\wechat\cloud => “浩一云”的小程序代码目录，由于直播限制，无法发布；
            E:\GitHub\HaoYiYun\myhaoyi\wechat\device => “浩一云服务”的小程序代码目录，已正式发布；
            center => wk_user => wx_qidi_mini => “启迪未来双师”的小程序openid
  （已完成）开始搭建“启迪未来双师”小程序的基本结构，完善目录结构和代码框架，参考之前的两个小程序；
  （已完成）小程序 => 存放小程序相关的文档进程等等信息 => E:\GitHub\HaoYiYun\Document\小程序
            C:\Users\Jackey\Downloads => 一些c++代码的例子程序存放点
            E:\GitHub\HaoYiYun\Document\WEB => 一些网站应用代码的存放点
            F:\谷歌下载 => 一些c++、小程序、网站代码的存放点
  （已完成）小程序UI库iview，可以参考一些组件，最好能单独使用单个组件；
            E:\GitHaoYi\iview-weapp => 另一个小程序UI库iview
            iview-weapp帮助文档 => https://weapp.iviewui.com/
            iview-weapp仓库地址 => https://github.com/TalkingData/iview-weapp
            wuss-weapp仓库地址 => https://github.com/phonycode/wuss-weapp
            wuss-weapp帮助文档 => https://phonycode.github.io/wuss-weapp
            minui仓库地址 => https://github.com/meili/minui
            微信小程序图表工具 => https://github.com/xiaolin3303/wx-charts
            小程序营销组件 => https://github.com/o2team/wxapp-market
            微信小程序图表charts组件 => https://github.com/hawx1993/wxapp-charts
            小程序海报组件 => https://github.com/jasondu/wxa-plugin-canvas
            微信小程序，图表组件 => https://github.com/ioneday/wxchart
  （已完成）小程序UI库wux，可以参考一些组件，最好能单独使用单个组件；
            E:\GitHaoYi\wux-weapp => 本地源码拷贝
            wux帮助文档 => https://wux-weapp.github.io/wux-weapp-docs/#/quickstart
            wux仓库地址 => https://github.com/wux-weapp/wux-weapp
            wux在example当中使用到了weui的样式 => wux-weapp\example\assets\styles\weui.wxss
  （已完成）小程序UI库 => 之前使用的有赞小程序界面已经由zanui-weapp升级成了vant-weapp
            E:\GitHaoYi\vant-weapp => vant-weapp => 移动端、PC端、小程序端都有不同的实现；
            vant-weapp仓库地址 => https://github.com/youzan/vant-weapp
            vant-weapp帮助文档 => https://youzan.github.io/vant-weapp
            fontawesome字体库 => http://www.fontawesome.com.cn/faicons/
  （已完成）https://developers.weixin.qq.com/miniprogram/dev/devtools/devtools.html => 小程序开发指南
            setData({text: 'xxx'}); => 设置单个变量 => setData({'text': 'xxx'});
            setData({'object.text': 'xxx'}); => 设置对象里的当个变量
            setData({middle: !this.data.middle}); => 设置变量内容取反的方法 => setData({middle: !this.data['middle']});
            setData({[`object.${type}`]: !this.data.object[type]}); => 利用参数访问特点对象里的特定变量方法，type是字符串参数
            setData({[`object.middle`]: true}); => setData({'object.middle': true}); => setData({['object.middle']: true});
  （已完成）改造 wux-weapp里面的grids，使用fontawesome里面的图标字体做为导航栏；
            始终记住，fontawesome是一种文字，是字体，它的定位是通过字体的大小进行自动定位的；
            如果是图片，比如<van-icon>的叠加，就需要用font-size|absolute|left|top的计算来定位；
            完成了fontawesome针对字体图片的叠加，完成了<van-icon>针对图片的叠加定位；
            这种字体或图片的叠加显示思路都是父节点使用relative，子节点使用absolute的容器模式；
  （已完成）https://ibaotu.com/ui/15-91804-0-0-0-1.html => 移动应用界面设计 => 可以从这里寻找小程序的界面设计思路
  （已完成）组件的custom-class无法覆盖组件元素里面相同的样式内容，需要通过customStyle才能覆盖原有的样式内容；
  （已完成）也可以使用custom-class来解决，使用样式的 !important; 修饰，提高样式的优先级；
  （已完成）custom-class可以直接被元素的class使用，元素的style需要通过setData才能被使用；
  （已完成）<slot></slot> 指明这个位置可以插入任意的元素，<slot name="top" /> 指明只能插入特定名称的元素 => <view slot="top" />
  （已完成）所有的vant组件自动带有custom-class附加样式属性 => component.js里面有定义；
  （已完成）组件的属性支持驼峰输入origin-price => originPrice => 这种书写方式都是可以的；
  （已完成）小程序的域名访问，不能有跳转重定向，否则在post时会丢失参数；“启迪云”当中必须写成 https://www.qidiweilai.com
  （已完成）wx.request 当中必须使用 dataType: 'x-www-form-urlencoded', header: { 'content-type': 'application/x-www-form-urlencoded' }, 否则，post时，php会报错；
  （已完成）https://www.icourse163.org/ => 可以参考一些课程的移动端界面样式；
  （已完成）.van-card__title 需要修改样式为 min-height:34px; 这样就能保证永远2行显示，之前是max-height:34px;
  （已完成）van-card 目前通过调整字体 customStyle="font-size:14px;"，可以实现两种样式的展示，一种纯展示，一种带购物车；
  （已完成）display:-webkit-box;
overflow:hidden;text-overflow:ellipsis;word-break:break-all;-webkit-box-orient:vertical;-webkit-line-clamp:2; 实现两行显示，外面再包一个样式的话，需要用min-height，而不是max-height
  （已完成）van-card 增加 van-card--hover 样式，增加 bind:tap="onTap"，去掉onClickThumb，点击时有翻转效果，也有事件响应；
  （已完成）两种方式传递参数给click事件，直接使用id(event.currentTarget.id)，或者data-item(event.currentTarget.dataset['item'])
  （已完成）小程序的登录和授权是分离的，登录只能获取一个code，授权需要弹框确认，直接调用wx.getUserInfo()不会弹出授权框，会返回失败，必须通过按钮模式才能重新弹框授权；
  （已完成）需要改进为 => 弹出自定义对话框，包含文字和授权按钮，关闭按钮，或取消按钮 => van-dialog
  （已完成）为了应对小程序可能的被动下架失效，但保持讲师端|学生端不变，需要在网站端变换小程序appid，这样最大限度的减小下架带来的影响；
  （已完成）这种方式，不用在讲师端|学生端|小程序里面标注身份标识，只需要在网站端修改appid就可以了；
  （已完成）wx.reLaunch() => 不可返回，wx.navigateTo() => 可返回；在bind.js当中有两处调用wx.reLaunch('home')，在home.js中的onReady()中调用wx.navigateTo()
  （已完成）https://blog.csdn.net/imryss/article/details/47837459 => QT当中有关背景图片样式的特殊处理；
  （已完成）<view style="position:absolute;min-width:100%;min-height:100%;background:#fff;"> 可以动态改变page背景色；

2.（已完成）educate 双师平台数据库的数据表说明：
  （已完成）wk_system   => 系统配置表，记录节点网站的配置信息；
  （已完成）wk_user     => 微信用户表，记录从微信扫码获取到的用户记录，有三个方向扫码：网站扫码(网站应用)|讲师端或学生端扫码(小程序码)|家长线下门店扫码(小程序码)
            shop_id     => 用户所在分店或分校编号，默认0（总部），总部扫码后跳转/Admin，分店扫码后跳转/Agent，cookie当中需要记录shop_id编号；
            user_type   => 用户身份类型，默认0（家长），1（助教），2（讲师），3（店长），4（门店老板），5（运营维护），6（管理员），只要类型大于0的用户都可以登录后台进行管理，只是后期权限不同而已；
            lesson_num  => 剩余有效课时数，家长通过购买课时数进行充值，前期通过分店后台进行充值，后期通过微信支付直接充值；
            parent_name => 家长姓名
            parent_type => 家长身份(0无，1妈妈，2爸爸，3亲属)
            maker_id   => 当前用户的介绍人的用户编号，这样可以建立用户的层次关联关系；
            child_id    => 去掉这个字段，因为一个用户可能会有多个孩子，因此，在wk_child表中带user_id，一个孩子只能对应一个家长，让一个家长进行课时消耗；(还是要child_id，前期需要简化）
            user_tick   => 去掉这个字段，已经被shop_id和user_type代替了；
  （不处理）wk_teacher  => 当用户身份不是家长时的信息扩展记录表，用于记录用户身份的扩展信息；
            teacher_id|user_id|poster_id(讲师海报图片编号)|title_name(讲师职称)|detail_short(讲师短评)|detail_info(讲师详评)|created|updated
  （已完成）wk_child    => 网站端，孩子信息表，记录上课孩子的详细信息内容；新增user_id字段，记录孩子所属的家长用户编号；
            如果牵涉到一个孩子对应多个家长的情况时，需要新增一个孩子与用户的对应关系表，相互关联才能解决，目前只能解决一个孩子对应一个家长，一个家长可以对应多个孩子的情况；
  （已完成）wk_gather   => 学生端，记录表，记录学生端的详细信息，包括MAC地址、IP地址、操作系统、机器名称，等等配置信息；
  （已完成）wk_camera   => 学生端，摄像头通道表，记录每一个摄像头通道的配置信息，通常是rtsp拉流地址；
  （已完成）wk_room     => 网站端，虚拟教室房间记录表，记录没一个讲师创建的房间记录，一个讲师可以创建多个房间记录；
            teacher_id  => 一个房间必须对应一个讲师，讲师必须对应一个有效的用户记录；
            teacher_id  => 直接对应wk_user里面的user_id，在没有使用wk_teacher表的时候；
            只有讲师身份的用户才能登录讲师端，只要大于家长身份的用户都可以登录学生端，这样的设计避免限制太死造成使用上的不方便；
            目前，针对添加房间时，在上传海报时的处理上有问题，应该是有一个集中上传图片的地方，然后，在海报上传处进行已上传海报的选择操作；
  （已完成）wk_agent    => 网站端，代理机构记录表 或 分校记录表，记录机构信息，一个微信帐号可以被授权管理多个机构，在导航栏可以进行切换管理；
  （已完成）wk_subject  => 网站端，主题科目表，记录系统支持的科目信息，例如：乐高课、科学课、教学会议
  （已完成）wk_image    => 网站端，图片记录表，包含直播房间自动生成图片，讲师个人展示图片，课时展示图片，宝宝风采头像等等，所有上传的图片集中地；
  （已完成）wk_grade    => 网站端，阶段等级表，与主题科目对应，记录阶段等级的名称、课时、描述等等信息；
  （已完成）wk_chat     => 网站端，聊天表，记录小程序|讲师端|学生端的聊天记录；目前只支持文字聊天；
  （已完成）wk_flow     => 网站端，流量统计表，记录讲师登录用户使用指定房间时，房间里的上行和下行流量，每隔5秒统计更新一次；
  （已完成）wk_shop     => 网站端，门店表，记录每个门店的信息，单独小程序二维码(shop_id)，只有运营者|管理员能够进行添加|修改|删除；

3.（不处理）小程序，增加助教发文字|图片功能；
  （不处理）小程序，需要参考酷爸 => I:\PHPDev\APM\linux\wan\wxapi => http://baby.myhaoyi.com/wxapi.php/Mobile/member
  （不处理）服务器，计费需要加入机构表，增加充值记录，机构按照使用时间进行每分钟计费，并扣除费用，并有相关记录可以查询，都通过小程序查看；
  （不处理）讲师端，计费方式需要按照每通道每分钟的计费模式，并通过小程序展现出来，每次直播所产生的费用；

4.（已完成）小程序，需要根据登录用户的身份不同，显示不同的操作菜单，目前归结为3种不同菜单：
            家长身份|老师身份   => 我的账号|我的订单|消费记录|宝宝风采
            助教|店长|门店老板  => 我的账号|支付管理|会员管理|门店管理
            运营维护|系统管理员 => 我的账号|支付管理|会员管理|门店管理|课程管理|房间管理|终端管理|
  （已完成）小程序，学生端进入房间的方式可以有两种，一种是查看房间列表选择，一种是直接输入房间密码进入；
            小程序，老师端进入房间的方式也可以采用两种方式，一种是查看房间列表选择，一种是直接输入房间密码进入；
            小程序，这种方式或模式的设定可以在小程序创建房间时交给机构的老师进行自行设定，应该设计成只有一种模式，都是输入房间密码的方式？
            小程序，输入数字密码的方法参见 => wux-weapp 里面的 KeyBoard 数字键盘功能；
  （不处理）讲师端，每个讲师可以绑定指定的唯一房间通道，这样就不用选择直播房间编号了；
  （不处理）讲师端，运营者或管理员或绑定的讲师自己，可以设定指定房间的临时密码，只有输入密码正确的用户才能允许登录指定的房间；
  （已完成）小程序，过渡版本，“我的”页面只实现管理员功能，非管理员的“我的”页面进行屏蔽；
  （已完成）小程序，“机构表”只与“门店表”关联，任何机构 都 必须包含一个门店，任何用户都要属于一个门店；
  （已完成）小程序，“房间表”与“机构表”关联，机构关联费用，这样通过房间使用时间计费，最终落到机构身上；
  （已完成）小程序，房间管理，加上房间密码，讲师和学生扫码后都需要输入房间密码才能登录成功，通常为4位或6位数字；
  （已完成）小程序，机构管理，需要新增机构管理员角色；一个用户可以管理多个机构，只有管理员身份可以添加和删除机构，其它机构管理员只能修改机构；
  （已完成）小程序，只有老师身份以上的用户才能成为机构管理员，进行机构信息的管理，才能有 机构管理|门店管理|直播间管理；
  （已完成）小程序，机构管理员只能修改房间信息，不能添加或删除房间信息，所属机构不能调整；
  （已完成）小程序，“会员管理”改成“用户管理”，“家长信息”改成“用户信息”；
  （已完成）小程序，不同身份的用户，展示不同的管理操作页面；过渡版本，去掉“我的账号”；
  （已完成）小程序，2019.06.19，提交1.2.1版本进行审核，扫码后输入房间密码审核，而不是选择房间；

5.（已完成）小程序，第一版本，解决学生端|讲师端 硬件设备在小程序上的管理工作，即硬件设备管理；
  （已完成）小程序，目前的页面，可以做为“我的”页面，用户可以直接看到页面，但是必须点击授权之后才能进行具体的操作；
  （已完成）小程序，修改首页，直接展示目前有的课程列表(房间列表)，用户点击时需要进行授权确认，普通用户只能查看当前房间的状态，课程表等信息；助教和讲师进入房间进行提问交流；
  （已完成）小程序，用户点击房间，记录房间数据，跳转到房间页面，有两个标签，聊天内容|在线用户；
  （已完成）小程序，房间聊天室参考 => https://blog.csdn.net/sinat_27612147/article/details/78456363，支持文字|语音|图片；第一版只支持文字；
  （不处理）小程序，需要将Websoket接口转换成API接口，上传文字|语音|图片数据，存放到聊天数据库当中；每隔2秒钟自动从服务器刷新聊天数据；
  （不处理）小程序，不使用Websocket上传，使用 wx.uploadFile 上传，后台使用php接收并存放到数据库当中；需要支持文字|语音|图片；第一版只支持文字；
  （已完成）小程序，改进聊天功能，支持群聊模式，默认显示用户昵称，目前的聊天室并没有显示用户昵称；微信昵称 - 真实姓名 - 身份类型；
  （已完成）小程序，房间聊天记录的刷新需要记录当前最小聊天号（向上刷新），最大聊天号（向下刷新），不能简单按照分页刷新，需要用编号刷新；
  （已完成）小程序，房间聊天，屏蔽语音入口，屏蔽图片入口，只留下文字入口；
  （已完成）小程序，房间聊天，安卓手机端，出现<scroll-view>失效问题，所有数据被压缩到一起，无法滚动；是由于手机端必须写成 scroll-y="true" 
  （已完成）小程序，房间聊天，输入聊天表情后，能回显，但是存入数据库之后，再读取出来就发生错误，出现无记录的问题；
  （已完成）小程序，房间聊天，是由于聊天表情存入数据库的内容为空，造成回显时，无法显示，造成错误；
  （已完成）小程序，房间聊天，支持表情，目前的修改方式是进行字符串转义，也可以用utf8mb4的方法，需要改动整个数据库；
  （已完成）小程序，房间聊天，标签切换与页面滚动还有问题，原因是手动设定了scroll-view的高度，需要减去tab的高度，44px；
  （已完成）讲师端，先弹出小程序二维码，讲师身份用户扫码登录，非讲师身份登录失败；二维码附带的信息为 => type_TCPSocketFD_time => 总共3个标识；
  （已完成）讲师端，udpcenter需要产生两个标识，一个是tcp_socket，一个是tcp_time，只用tcp_socket不保险，可能已经删除，但socket号又被新来者占用；
  （已完成）讲师端，udpcenter产生的第二个tcp_time标识符号，不能用时间戳，无法做到精确又不越界，还有场景值限制等等问题，最终使用全局计数器来解决；
  （已完成）讲师端，弹出的小程序二维码，需要包含反向链接的讲师端编号，因此，需要让讲师端先链接中心服务器，远程连接需要一开始就要启动；
  （已完成）讲师端，修改登录流程，弹出小程序二维码的同时，需要直接连接中心服务器，通过中心服务器建立小程序与讲师端|学生端中转关联；
  （已完成）讲师端，新增 CCenterSession 会话，专门处理讲师端|学生端与中心服务器的长链接，用来与中心服务器的直接交互，一开始就需要建立的连接；
  （已完成）讲师端，新增 CLoginMini 过程，将获取中心服务器的地址和端口加入，同时，还要加入连接中心服务器的过程；
  （已完成）讲师端，当用户点击“确认登录”之后，CLoginMini还要增加一个获取用户详细信息的过程，包括用户绑定房间列表等等信息；
  （已完成）讲师端，当用户点击“确认登录”之后，CLoginMini增加两个过程 kMiniUserInfo => kMiniLoginRoom，获取用户信息，登录房间获取节点服务器信息；
  （不处理）讲师端，需要做到登录界面的一键切换 => 小程序扫码登录 和 普通通道选择登录的自由切换，避免小程序被封杀后的功能正常使用；
  （已完成）小程序，针对扫码登录的用户类型进行判断识别，小程序将获取到的用户身份，反馈给讲师端，只有讲师端身份的用户才能登录讲师端；
  （已完成）小程序，非讲师用户，扫码授权之后，只跳转到首页，不能跳转到具体房间页面，因为不会得到具体的房间号码；
  （已完成）小程序，模拟扫码登录过程基本完成，现在需要优化扫码登录等待过程的界面信息，不要显示空白界面；
  （已完成）小程序，学生端扫描成功之后的页面跳转有问题，不能够跳转到房间页面，而应该跳转到房间列表页面；
  （已完成）小程序，当扫描学生端二维码时，需要在小程序端选择房间教室，这样就可以去掉学生端的房间教室选择步骤；
  （已完成）小程序，这样的操作模式，可以进一步的降低学生端的操作，减少可能的障碍，让小程序发挥更大的作用；
  （已完成）小程序，讲师端也要采用在小程序选择进入房间的模式，讲师端，需要验证用户身份是讲师，学生端不用验证扫码用户身份；
  （已完成）小程序，讲师端|学生端，用户身份验证授权成功之后，不是弹出确认框，而是弹出房间列表供用户选择要进入的房间教室列表；
  （已完成）小程序，讲师扫码时，选择教室之后需要在服务器判断是否已经有讲师在线，同一个教室只能有一个讲师在线；
  （不处理）讲师端，先弹出小程序二维码，也可以点击“快速登录”，输入房间号和密码登录；代替微信扫码登录；
  （已完成）讲师端，每一个讲师对应一个唯一的房间号，房间号从200001开始，讲师登录成功之后，不用再选择房间；
  （已完成）学生端，先弹出小程序二维码，任何人都可以直接扫码登录，不用修改用户身份类型，只要是微信用户；
  （已完成）学生端，开始学生端的小程序二维码显示|扫描|登录，全过程的实现，需要参考讲师端的实现过程；
  （已完成）学生端，扫描小程序二维码成功之后，还需要小程序选择要进入的房间号，然后进入房间进行直播观看；
  （已完成）小程序，2019.04.20，完成第一版本的上传，等待审核；2019.04.22，审核通过，发布第一版本 1.1.0；
  （已完成）小程序，出现扫码错误之后，需要增加一个返回首页的按钮，否则，无法正常返回；
  （已完成）小程序，2019.04.23，提交1.1.1版本进行审核，审核通过，发布第一版本 1.1.1；
  （已完成）小程序，2019.06.19，提交1.2.1版本进行审核，扫码后输入房间密码审核，而不是选择房间；

6.（不处理）小程序，第三版本，增加支付功能，服务商模式的支付，可以关联其它多个商户的支付形式；
  （不处理）小程序，第四版本，增加答题功能，与直播课程相关联的答题功能，与学校|家长|学生相关联；

7.（已完成）讲师端，数据源的变换属性居然是与数据源所在的位置相关，而不是与数据源本身关联，造成并没有进行变换的数据源，如果发生位置交换时，会发生属性变换；
  （已完成）讲师端，这是由于在进行数据源的配置交换时，只交换了位置，没有交换其它变换数据造成的，只需要加上其它变换数据的交换就可以了；
  （已完成）讲师端，OBSBasic::doSceneItemExchangePos() => 不能交换全部信息，只交换坐标位置和图像高宽；
  （已完成）讲师端，打印日志当中需要打印播放缓存里的音视频大小，目前只打印了接收缓存里的音视频缓冲块大小；
  （已完成）学生端，打印日志当中需要打印播放缓存里的音视频大小，目前只打印了接收缓存里的音视频缓冲块大小；
  （不处理）学生端，发现学生端在播放时，音视频有不少的缓存，是解码后的缓存，没有来得及播放的缓存，说明还有进一步优化降低延迟的空间；
  （不处理）网站端，将教室号码的偏移量从200000改成20000，这样方便说，从2万开始；
  （不处理）互动教室的方向转动，镜头拉近拉远，可以使用键盘快捷键来完成，PageUp|PageDown完成放大缩小；
  （已完成）udpserver，当udpcenter断开时，udpserver重连速度太快，造成日志不断在更新，造成日志文件急剧增大；
  （已完成）udpserver，tcpthread.cpp，改进tcpcenter的重建方式，不要发生错误就重建，在超时事件当中重建；
  （已完成）需要考虑翻译笔的二次开发功能，这样就能利用翻译笔实现遥控操作功能，不仅能操作PPT，还能操作讲师端，不用非要用鼠标操作；
  （已完成）http://bbs.mydigit.cn/read.php?tid=2519527 => 有人也有跟我一样的想法；收到相应的按键后再虚拟成自己需要的按键。
  （已完成）https://detail.tmall.com/item.htm?id=41363481560 => 诺为N99，PPT带鼠标功能，可充电，就能实现远程遥控操作。
  （已完成）讲师端，需要打开系统崩溃检测机制，目前遇到有的机器开始录像|开始推流，都发生崩溃的问题，但是无法找到问题；
  （已完成）联想笔记本，1366x768 => 1092x614 分辨率，在进行自动分辨率缩放时会出问题，swscale-4.dll崩溃；
  （已完成）DoProcSaveJpeg => sws_scale => 空间分配发生问题 => 614不是4的整数倍 => X/4*4 => 转换成4的整数倍；
  （不处理）学生端，在进行监控视频的通道预览时，也会用到sws_scale进行缩放显示，目前没有对长宽进行4的整数倍处理；
  （已完成）main_crash_handler => 将OBS文字转换成Teacher就可以了，直接转中文会牵涉到字符编码转换的问题；
  （已完成）学生端|讲师端，升级版本到 => 1.1.12

8.（已完成）学生端，海康无线摄像头的选型，720P以上|无线IW|AAC音频|RTSP|200块以下|桌面夹装
  （已完成）DS-2CD3125D-IW2  => https://item.taobao.com/item.htm?id=562101732517  => 225元|1080P
  （已完成）DS-2CD3025D-IW2  => https://item.taobao.com/item.htm?id=560533171861  => 205元|1080P => 配置后网络非常缓慢，退货了。
  （已完成）DS-2CD1021FD-IW1 => https://detail.tmall.com/item.htm?id=573532133336&skuId=4028807993829 => 198元|1080P => admin:qidi9527
  （已完成）以上三款都带外置天线，无线效果好，DS-2DE2204IW-DE3内置天线，无线效果相对差些，总体都在2~50ms以内，偶尔会超过100多毫秒，画面偶尔有卡顿现象；
  （不处理）安装在桌面上的弓形支架夹，因为牵涉到各种桌面，只能根据每个学校的桌面进行定制，不能用统一的型号，同时，还牵涉到摄像头的供电问题；
  （已完成）海康无线IPC在连接无线AP时，不能连接级联桥接的AP，能PING通但无法进行访问传输数据；
  （已完成）一个普通无线AP，通常能连接20个左右无线节点，要连接更多节点，需要对无线AP进行网线级联，不同的SSID处于同一网段内，达到扩展节点的目的；
  （已完成）海康IPC的有线IP地址与无线IP地址可以设置成相同的IP地址，如果同时连接，内部会自动有线优先；如果IP不相同也没关系，只是在应用上比较麻烦，因此，最好让有线和无线的IP地址相同；
  （已完成）海康IPC在配置无线IP连接时，最好关闭WPS的开关，只用SSID的模式，WPS是用PING号码一键连接无线AP的方式，需要无线AP的WPS功能支持才行；
  （已完成）用两个无线AP不同SSID用网线级联，这样可以确保出口网络的稳定，同时，又能让两个无线AP服务多个节点，做到节点扩展，比无线AP的WDS桥接模式要稳定很多；

9.（已完成）GMPullerX，改造，可以按时间间隔录像，交错录像，可以从XML配置表中读取配置，只拉取rtsp，录像到指定位置，存成MP4格式文件；
  （已完成）H:\CVSKHStream\KHBase\AVCaster2\SaveRTMP 移植到 E:\GitHub\HaoYiYun\Source\GMSave，先开始界面的简单移植，第一个版本限制连接10个IPC地址；
  （已完成）配置文件放在 %APPPATH%/GMSave/Config.xml 里面，存放 切片时间|交错时间|截图时间间隔
  （已完成）完成了第一个版本，可以进行切片、交错录像，只有一个可执行文件，拉流地址没做存盘功能；
  （已完成）/OPT:NOREF => https://zhidao.baidu.com/question/509842028.html
  （已完成）新增 使用ffmpeg动态截图功能 => E:\GitHaoYi\GMSave\GMSave.rar

10.（已完成）学生端，云台控制，当有多个IPC，只要有一个IPC的云台无法控制，会造成其它正常IPC的云台也无法控制；
   （已完成）学生端，云台控制，由于命令能力查询失败之后，还会周期发起命令，造成始终有错误命令，需要在能力查询失败之后，阻止周期调用就可以了；

11.（不处理）学生端，小程序登录成功之后，优化与Web的交互过程，不要使用curl，去掉CWebThread，直接使用QT的QNetworkAccessManager，放到CStudentApp当中；
   （不处理）学生端，摄像头通道状态、学生端自己的状态，都通过udpserver的接口存取，而不是从数据库存取，这样gather|camera里面的status字段都需要废弃了；
   （不处理）学生端，讲师端，在与udpserver交互的Login命令当中，已经把mac地址上传上去，可以通过这个mac地址进行状态查询的唯一标志；
   （不处理）学生端，doWebGetMiniUserInfo或doWebGetMiniLoginRoom当中，网站端需要加入自动注册或更新讲师端在网站端数据库的记录操作；
   （不处理）学生端，doWebGetMiniUserInfo或doWebGetMiniLoginRoom当中，需要在网站端反馈当前讲师端主机是否流量欠费的判断；
   （不处理）学生端，小程序登录成功之后，需要在学生端自行计算上行与下行流量统计，并每隔15秒钟通过Web接口汇报给网站端；
   （不处理）学生端，将终端注册登录过程放到CLoginMini，这样方便网站端进行流量|计费|验证操作，部分简化或更新CWebThread里面的操作；
   （已完成）学生端，阿里云的流量计费 => 0.8元/GB，我们的计费标准 => 50.0元/GB，上行和下行流量累加计费的方式；
   （不处理）讲师端，doWebGetMiniUserInfo或doWebGetMiniLoginRoom当中，网站端需要加入自动注册或更新讲师端在网站端数据库的记录操作；
   （不处理）讲师端，doWebGetMiniUserInfo或doWebGetMiniLoginRoom当中，需要在网站端反馈当前讲师端主机是否流量欠费的判断；
   （不处理）讲师端，小程序登录成功之后，需要在讲师端自行计算上行与下行流量统计，并每隔15秒钟通过Web接口汇报给网站端；
   （不处理）讲师端，阿里云的流量计费 => 0.8元/GB，我们的计费标准 => 50.0元/GB，上行和下行流量累加计费的方式；
   （已完成）讲师端，OBSApp当中去掉Web交互时使用的curl，直接用QT的QNetworkAccessManager，放到OBSApp当中；
   （已完成）讲师端，计费统计放在微信登录的用户身上，每隔15秒钟从讲师端发起一个web请求询问udpserver当中指定房间的上行下行流量，记录到web数据库当中；
   （已完成）网站端，新建wk_flow流量统计表，讲师端小程序登录成功之后会创建一条记录，将记录ID传递给讲师端，讲师端每隔15秒钟触发web向udpserver统计上行下行流量；
   （已完成）网站端，这样就可以避免专门为讲师端建立一张记录表，而只需要建立wk_flow流量统计表就可以了；也不用在学生端统计流量，全部交给讲师端触发就可以了；
   （已完成）讲师端，房间状态的登入登出记录，不要通过网站接口，而是直接通过udpserver接口去实现，避免状态不清晰而造成的混乱；
   （已完成）讲师端，学生端，升级版本到 1.1.13 => 新增 流量统计功能；
   （已完成）服务器，udpserver => tcpclient.cpp:517 => 没有验证tcproom对象有效性，导致崩溃，是由于login失败，导致没有创建tcproom对象；
   （已完成）服务器，房间流量统计有问题，当房间里的讲师退出之后，需要重置房间流量统计，因为房间对象并没有被删除，而是讲师对象离线了；
   （已完成）服务器，在学生端登陆或讲师端推流时，会向学生端通知讲师端的flow_teacher流量编号，以便学生端与讲师端相互关联；
   （已完成）学生端，每隔15秒自动统计计算本地的上行下行流量，并调用网站接口进行对应的流量记录更新操作；
   （已完成）网站端，每次讲师端直播时的流量计费统计与观看的学生端进行了相互关联，通过wk_flow里的flow_teacher关联；

2018.02.27 - 2019.03.16 - 回音消除 与 讲师端软硬件优化
===============================================================================================
1.（已完成）阿里云上的Linux漏洞处理办法：
  （已完成）先根据提示，找到CVE编号，例如 => CVE-2017-15670
  （已完成）在通过网站查看详情 => http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-15670
  （已完成）在详情页面，找到CentOS相关的REDHAT升级包信息地址，再根据RedHat的提示，进行yum升级；
  （已完成）https://blog.csdn.net/tao_627/article/details/52136091 => 内核升级资料
  （已完成）http://www.catalog.update.microsoft.com/Search.aspx?q=KB4284878 => Windows补丁下载
  （已完成）时刻关注阿里云后台报告的高危漏洞，通常只需要一个 yum update 就能全部搞定；
  （已完成）直接在阿里云每个漏洞点击“详情”，从“影响说明”里面找到对应软件直接升级；
  （已完成）CentOS内核修复常规方法：
            yum update kernel
            yum update kernel-firmware
            yum update kernel-headers
            yum update kernel-devel
            uname -r => 查看内核版本
            rpm -qa|grep kernel => 查看内核安装包版本
  （已完成）Win7修改boot.ini实战技巧 => 由于不是Administrator登录，在使用Ghost备份或还原时，无法删除开机启动项，只能手动删除；
  （已完成）手动删除开机启动项命令 => bcdedit /delete {...} /cleanup
  （已完成）使用软碟通UltraISO制作U盘启动盘 => https://jingyan.baidu.com/article/fec4bce2788d06f2618d8b8e.html
  （已完成）新创云的mini机器套餐八|i7-6500U，只支持Win8以上系统，不能支持Win7系统；它们自己有纯净版Win10更新，但是不好用；
  （已完成）G:\迅雷下载\Win7\Oem7F7.exe，小马激活工具，有很多都有大量的病毒与木马，这个没有，但是硬盘分区格式必须是MBR
  （已完成）如果不是MBR可以用WinPE加载之后，用硬盘工具进行硬盘格式修改，目前准备了2个PE的iso文件，都可以用UltraISO进行U盘启动；
  （已完成）G:\迅雷下载\Win7\7pe_x64.iso（Win7版PE）和 G:\迅雷下载\Win10\Win10PE_x64.iso（Win10版PE）
  （已完成）G:\迅雷下载\Win10\DigitalLicense.exe => Win10有效激活工具；
  （已完成）G:\Jackey\变革资料\移动-微课\字体库 => 以前收集的有意思字库目录
  （已完成）突破百度网盘下载缓慢的方法 => https://greasyfork.org/zh-CN/scripts/39504
  （已完成）首先要翻墙下载Chrome扩展 暴力猴，百度网盘 下载助手脚本，下载IDM下载工具，安装IDM谷歌浏览器扩展，登录百度网盘，选中下载文件，点击下载助手；
  （已完成）学生端 => G:\迅雷下载\Win7 => 使用Win7，带激活程序，制作一个U盘启动安装盘，附带应用程序；
  （已完成）讲师端 => G:\迅雷下载\Win10\1809里面的专业版，带激活程序；能够对USB3.0支持更好，直接C1000E的罗技摄像头；制作U盘启动安装盘，附带应用程序；
  （已完成）更新设备采购连接里面的网线与延长线采购链接地址 => E:\GitHub\HaoYiYun\Document\云教室\双师设备\云教室-双师设备-幼儿园.docx

2.（已完成）DS-2DE4420IW-DE => 400万像素，20倍变焦的远程云台控制完成测试；
  （已完成）辉声乐22HA双咪头拾音器，回音消除的效果测试 => 效果很好，默认调整到最小状态；
  （已完成）辉声乐22HA双咪头接线柱套餐版本，配合DS-2DE4420IW-DE，可以直接连接，不用增加其它接线柱；拾音器调到最小，太大杂音重；
  （已完成）DS-2DE4420IW-DE配合拾音器(调节到最小状态)的音频配置参数：采样率(32K)，码率(64K)，音频输入(LineIn)，输入音量(80)，环境噪音过滤(开启)
  （已完成）更新了摄像头配置，加入汇博士悬臂高清USB摄像头；更新了学生端 投影仪|幕布 的采购型号和规格，具体参见 => E:\GitHub\HaoYiYun\Document\云教室\双师设备\《云教室-双师设备-幼儿园.docx》

3.（已完成）学生端，回音消除问题严重，服务器在北方，北方讲师端推流，南方学生端拉流，讲师说话时会听到严重的学生端回音，发生在延迟超过2秒以上时，回音非常严重；
  （已完成）学生端，回音消除不应该与网络延时相关，只与扬声器到麦克风的延时相关，因此，现在的回音消除处理过程有问题，人为的制造延时看看消除的情况；
  （已完成）学生端，为了方便测试，将音频存储路径修改为 => D:/MP4/PCM
  （已完成）学生端，新增一个开关配置，可以保存回音消除的音频数据；student-app.cpp:876 => SaveAECSample
  （不处理）学生端，调试回音消除时，会造成线程卡死，发生互锁现象（后来，仔细调试时，又没有发生，等再次遇到再调试吧）
  （已完成）学生端，webrtc-aec.cpp:422 => App()->SetAudioHorn(true) => 必须在正式投递扬声器消除数据时，才进行标志设定，就能避免网络延迟对AEC的影响...
  （已完成）学生端，如果屋子特别空旷，声音反射严重的话，回音消除的效果也会很差，嗡嗡的声音特别严重，回音的起始消除时间也会变成6秒；
  （已完成）学生端，海康IPC的麦克风拾音，噪音很小，起始消除时间始终3秒以内，已收集的数据样本位置 => D:\MP4\PCM\海康IPC
  （已完成）学生端，辉声乐拾音器的电流噪音比较大，起始消除时间有时会超过3秒，已收集的数据样本位置 => D:\MP4\PCM\120主机
  （已完成）学生端，辉声乐拾音器捕获的音频有比较大的电流噪音，这个需要在回音消除之后，再次进行噪音消除，需要研究webrtc的NS模块；
  （已完成）webrtc-ns降噪模块验证完毕 => 必须采用nsx模式，测试代码 => student-app.cpp:608 => doTestWebrtcNS()
  （已完成）webrtc-ns降噪模块是先把麦克风降噪，还是回音消除之后再降噪，经测试验证，回音消除之后再降噪效果好些；
  （已完成）webrtc-ns的使用文档 => https://www.cnblogs.com/dylancao/p/7667750.html
  （已完成）翻墙下载webrtc，有两个地址，https://chromium.googlesource.com/external/webrtc 和 https://webrtc.googlesource.com/src
  （已完成）需要使用git命令行设定本地代理 => git config --global http.proxy "localhost:8580" | git config --global --unset http.proxy
  （已完成）参考文档 => https://blog.csdn.net/wangyubin2010n/article/details/83302635
  （已完成）目录说明 => https://blog.csdn.net/garrylea/article/details/77899109
  （已完成）更新代码 => https://www.cnblogs.com/wisherzhang/p/6588487.html
  （已完成）断点续传 => mkdir webrtc | git init | git fetch https://webrtc.googlesource.com/src
  （已完成）断点续传 => mkdir webrtc | git init | git fetch https://chromium.googlesource.com/external/webrtc
  （已完成）git根本就不支持断点续传，找到一个webrtc的国内镜像 => https://blog.csdn.net/yangzhenping/article/details/52368132
  （已完成）下载完毕，还需要配合这个文章 => https://blog.csdn.net/qq_17011423/article/details/82850973 => git checkout chromium.org/master
  （已完成）git同步更新代码 => https://blog.csdn.net/longlc123/article/details/78652569 => git pull
  （已完成）webrtc代码已经同步，现在需要更新验证AEC的代码 => https://source.codeaurora.org/quic/lc/external/webrtc => E:\GitHaoYi\webrtc-mirror
  （已完成）这是目前使用的比较老的版本 => https://github.com/JumpingYang001/webrtc => E:\GitHaoYi\webrtc-Jumping
  （已完成）webrtc音频处理介绍 => https://blog.csdn.net/boywgw/article/details/46790937
  （已完成）发现最新版本与我们正在使用的AEC版本完全一样，没什么变化；
  （已完成）学生端|讲师端，升级版本到 => 1.1.10

4.（已完成）网站端，修改下载限制，可以放宽至两个下载连接，放宽至512k字节；
  （已完成）怀柔主机，显卡是技嘉730-2G，支持3屏显示(VGA+DVI+HDMI)，CPU是i5-7400，主板是B250m-d2v（B250M-D3H支持PCI采集卡）
  （已完成）怀柔主机，需要重装系统，Win7-32位版本，去掉所有的垃圾软件，这样速度会快点；下一台主机需要尝试使用U盘引导安装；
  （不处理）学生端|讲师端，版本修改 E:\obs-studio\libobs\obs-config.h 需要调整，每次修改版本文件，只需要编译exe即可，而不需要编译其它无关的模块；
  （不处理）obs-config.h 目前的方式，暂时保持不变，因为obs的机制是每个插件都需要保持版本同步，因此，版本号改变，本身就是要重新编译各个插件；
  （不处理）为了不影响update.exe功能，以及方便使用QT网络接口，将上传功能放在Student.exe当中，update.exe升级需要没有使用QT，造成网络代码比较复杂；
  （不处理）利用Student.exe进行自动化升级上传的工作，这样方便一键升级，避免每次都要通过ssh远程上传，太过麻烦；
  （不处理）需要验证php的md5计算值与本地计算值是否一致，做为是否上传的依据凭证；
  （不处理）需要验证本地通过QT网络接口调用php上传接口进行升级文件的上传和覆盖工作；
  （不处理）利用Student.exe的外部参数upload进行具体的一键上传升级操作；升级上传需要包括按照包，php配置文件，php运行库的更新；
  （不处理）由于牵涉到较大的改动，比较占用时间，等以后有空再进行自动化的一键升级操作；

5.（已完成）望京幕布模式，出现的新问题，老师浮动窗口抠像学生端出现底部黑线，估计是双缓存渲染时，窗口高度的计算有偏差造成的？
  （已完成）老师端隐藏窗口后，学生端仍然显示，这是由于进行的双缓存的缘故，用于压缩的窗口渲染没有判断窗口是否已经隐藏这个状态标志；
  （已完成）罗技C1000E无法在Win7系统下被识别，必须使用Win10-64位支持的更好些，这个需要用两个U盘来安装，一个当Win10PE，一个当Win10完整版系统盘；
  （已完成）利用身边的套餐八迷你机进行Win10-1809版本安装，激活，测试C930E和C1000E双摄像头的同时测试工作；
  （已完成）望京主机延时比较大，需要升级讲师端从i5-7400升级到i7-7700，安装Win10-x64-1809版本，双摄像头测试延时问题；
  （已完成）浮动窗口的推流绘制改进，浮动窗口的对齐问题，都是在同一个地方修改 => obs-video.c:325
  （已完成）Win10的启动速度非常快，占用系统资源也比较小，用x64的版本也飞快；
  （已完成）浮动窗口底部黑线的问题是由于特定的桌面分辨率(1920*1080)对应特定的摄像头(1280*720)，在进行比例缩放时发生的误差；
  （已完成）这个误差可以通过变换矩阵来实现，裁剪下方1个像素就可以，但是，同样由于双缓存的缘故，推流渲染缓存没有进行裁剪数据的处理，造成学生端没有裁剪，还是能看到原始内容的原因；
  （已完成）这个黑线问题是由于裁剪区域的渲染问题，需要进行特殊的渲染，否则，裁剪区域无法渲染，参见 => obs-video.c:render_export_source()
  （已完成）顺便解决了裁剪区域被重置的问题，是由于window-basic-main.cpp:doSceneItemToFirst()和doSceneItemLayout()故意重置造成的。
  （已完成）后续等有时间，还要处理浮动窗口自动还原问题，不要向现在这样，每次启动都回到了固定状态，需要让浮动窗口恢复到以前的浮动状态。
  （已完成）数据源窗口的水平翻转状态记录与还原，数据源窗口的浮动还原问题，目前的数据源窗口采用简单的重排还原，造成无法真实还原数据源窗口状态；
  （已完成）OBSBasic::DeferredLoad()里面，屏蔽ShutFloatSource()，不要对数据源窗口重排，就能还原数据源本来的状态；
  （已完成）OBSBasic::ShutFloatSource()，关闭浮动窗口的算法需要修改，不能对数据源数据源窗口进行重排，只对浮动数据源窗口进行位置变换；
  （已完成）调整思路，不进行所有数据源的窗口重排，只针对新添加和关闭浮动窗口时的重排，即只针对单个数据源的排列，通过位置查找数据源 => OBSBasic::doSceneItemLayout()
  （已完成）视频捕获设备，总是会自动添加音频设备，这个需要去掉，要不然每次都要手动去隐藏这个音频显示 => AddSource()
  （已完成）学生端|讲师端，升级版本到 => 1.1.11

6.（已完成）讲师端，也要用拾音器模式，寻找质量好的拾音器产品；
  （已完成）拾音器，可以直接插入声卡的麦克风线路当麦克风使用，实测效果来看还不错，就是声音有点小；
  （已完成）高端拾音器  => https://item.taobao.com/item.htm?id=571997042672 => 附送电源和3.5转接线，自带降噪功能；
  （已完成）吊麦+混音器 => https://item.taobao.com/item.htm?id=539690572829 => 单个吊麦168，外加混音器550；
  （已完成）吊麦的混音器，需要将Aux|Echo|Bass调节到最小，才不会出现重音等问题；
  （已完成）吊麦的混音器，可以接通用的卡侬接口吊麦，不一定非要用混音器厂家的吊麦；

2018.01.21 - 2019.02.27 - 远程云台控制 + 服务器模型优化 + 旁观者能听到交互声音
===============================================================================================
0.（已完成）编写新的讲师端和学生端硬件配置，用在幼儿园；
  （不处理）编写《电子屏直播PPT制作规范.doc》，改成了绿幕模式，就可以省掉电子屏的方案；
  （已完成）http://www.bjrbj.gov.cn/csibiz/indinfo/index.jsp => 社保打印申请订单流水号 => 20190214008272
  （已完成）讲师端，摄像头画面，绿幕抠像问题，研究obs的使用技巧，终于找到了一个完美教程；
  （已完成）OBS动态绿幕抠图效果教程 => https://www.bilibili.com/video/av21889973/
  （已完成）最新设备文档 => E:\GitHub\HaoYiYun\Document\云教室\双师设备\云教室-双师设备-幼儿园.docx
  （已完成）发布新版本，升级版本号为 => 1.1.7
  （已完成）讲师端|学生端，不要乱改播放系统0点时刻，这个时刻点是相反的，具体参见UDPRecvThread.cpp:202和UDPPlayThread.cpp:314
  （已完成）学生端，扩展音频的互斥对象，不要放在CPlaySDL里面，需要放在外面(CViewRender)，因为会发生多次删除的情况；

1.（不处理）云台控制协议相关资料收集整理：
            https://zhidao.baidu.com/question/1895263649971599260.html => ONVIF不只是简单的云台控制协议，包含更多信息；
            https://blog.csdn.net/benkaoya/article/details/72453403 => ONVIF协议网络摄像机（IPC）客户端程序开发
            https://www.cnblogs.com/lsdb/p/9157302.html => ONVIF协议学习笔记
            https://blog.csdn.net/zjf535214685/article/details/81298694 => 有关 opaque 的讲解；
            https://blog.csdn.net/maoliran/article/details/51841420 => www-authenticate之Basic认证过程；
            https://blog.csdn.net/dev_hanyu/article/details/47783015 => www-authenticate之Digest认证过程，也有MD5计算公式；
            https://blog.csdn.net/jszj/article/details/8918967 => www-authenticate之Digest认证过程，包含MD5计算方式；
            https://www.cnblogs.com/devcjq/articles/2287198.html => 随机数生成方法；
  （已完成）PTZ => PAN水平转动|TITL垂直转动|ZOOM变焦
  （已完成）总结，ONVIF/ISAPI都能实现全部摄像头的控制命令，相对而言，ISAPI的方式更简单，海康的网页控制就是采用ISAPI的方式；
  （已完成）ONVIF/ISAPI目前都没有找到比较合适的开发文档，目前只能通过Fiddler4进行HTTP截包来进行自己需要的控制命令分析和处理；
  （已完成）E:\GitHub\HaoYiYun\Document\HK\ISAPI，这里放置一些截包和网络收集文档；
  （已完成）D:\Users\Jackey\AppData\Local\Programs\Fiddler => Fiddler软件安装位置；
  （已完成）目前，想要完成的云台控制|图像配置|网络配置|镜像控制，都可以通过ISAPI的方式完成，不要使用ONVIF和海康提供的SDK，相对都比较复杂，没有ISAPI简单；
  （已完成）目前，海康两种不同型号的摄像头都已经通过Digest模式，完成了curl模式下的ISAPI登录过程，下面进入xml的解析，使用到tinyxml；
  （已完成）注意，Digest的授权登录过程需要在一定时间之内完成，超过几秒中就会被服务器IPC拒绝登录；
  （已完成）QT经验，通过云台控制的界面设计，终于可以掌控复杂的界面，并能灵活利用QT规则，综合应用CSS、PS，制作非常复杂的好看界面；
  （已完成）通过curl调用与IPC的http交互过程，速度非常缓慢，还会阻塞界面，摄像头响应缓慢，发送PUT命令非常麻烦，需要改进，使用Windows自带接口，参考WinUpdate；
            http://www.bubuko.com/infodetail-1680672.html => 使用QNetworkAccessManager的高级方式
            https://blog.csdn.net/icebergkevin/article/details/50133341 => 使用QNetworkAccessManager的高级方式
            https://blog.csdn.net/wukai_std/article/details/60144318 => ComboBox样式升级代码
            https://www.cnblogs.com/weizhixiang/p/5891105.html => ComboBox基本用法
  （已完成）QNetworkAccessManager::finished()|authenticationRequired()这种网络命令，如果绑定多个对象，网络事件会通知每个注册对象，这里一定要小心，需要改进；
  （已完成）上面的问题是由于都用了同一个QNetworkAccessManager造成的，在每一个摄像头对象中使用一个QNetworkAccessManager，但代码逻辑并没有改变，解决了多次事件通知的问题；
  （已完成）海康IPC的型号不同，云台的转动方式有差异，需要画面缩放到最小，才能快速转动云台，画面在放大状态下，云台转速非常慢，DE2204没有这个问题；
  （不处理）经测试验证：QT的QNetworkAccessManager(支持HTTP|HTTPS|FTP) 比 libcurl 效率高很多，授权过程根本不用自己计算，而且还是异步不会造成阻塞，libcurl的缺陷太多；
  （不处理）后期需要将所有用curl的地方替换成QT，特别是登陆和通道交互的地方，还有升级的代码；
  （已完成）学生端，实现了两种海康摄像头DS-2DE2204IW-DE3和DS-2106通过ISAPI接口的PTZ控制；
  （已完成）讲师端，开始进行云台控制交互界面的设计与实现，然后，进行远程控制命令的实现；
  （已完成）讲师端，需要先在互动窗口，增加一个快捷按钮，可以点击弹出PTZ窗口；
  （不处理）讲师端，由于预览窗口和主窗口的特殊性，造成透明贴图时会发生黑屏现象，云台窗口用蒙板解决了，但是，想在预览窗口使用贴图快捷按钮时，没能解决；
  （不处理）讲师端，后期需要在每个资源窗口创建快捷操作按钮，直接点击而不是通过右键的方式；现在由于透明按钮黑屏的问题占时没能实现；
  （已完成）讲师端|学生端|udpcenter|udpserver，将相互关联的变量进行了统一整合，避免修改多个地方造成的潜在风险；
  （已完成）华为|苹果 的耳机，既是耳机也是麦克风，而且麦克风的效果很好，嘴巴可以离麦克风有一定距离；可以用耳机麦克风插入小蜜蜂的发射器，可以做备用麦克风；麦克风在音量控制位置；

2.（已完成）重新梳理讲师端|学生端，在客户端和服务端的不同处理方式和模型：
  （已完成）讲师推流者 - 客户端 - 缓存 => 发送探测命令时不处理，收到服务器反馈命令后，根据服务器已经收到的连续包号进行本地缓存的清理 => CUDPSendThread::doProcMaxConSeq()
            讲师推流者 - 服务端 - 缓存 => 发送探测命令时要处理，主动删除超过5秒缓存的数据包，探测命令反馈包只进行RTT值的计算 => CTeacher::doCalcAVJamStatus()
            讲师推流者 - 客户端 - 补包 => 只发生在推流者与服务器之间，由前面的缓存机制，服务器丢包在推流客户端肯定没有被删除 => CUDPSendThread::doSendLosePacket()
            讲师推流者 - 服务端 - 补包 => 必须缓存5秒音视频数据包，提供给n个学生观看端补包使用，每秒发送服务器主动探测命令时，做一次缓存判断清理 => CTeacher::doCalcAVJamStatus()
  （已完成）讲师推流者|学生推流者，改进成了相同的模型，都在服务器端建立缓存，让观看者直接从服务器获取数据包，而不是通过推流者直接获取；
            学生推流者，之前的模型，老师观看者会不断将探测命令发给学生推流者，学生推流者会根据老师观看者的探测命令来删除缓存，现在变成了服务器的探测包，一直都处于连接状态，需要调整；
            学生推流者，经过这样的模型改造之后，会带来一个问题，老师观看者退出时，没有通知学生推流者，造成学生推流者一直在推送数据流；因此，需要发送一个通道停止推流的命令；
            学生推流者，在老师观看者被删除时，强行向学生推流者发送通道停止推流的命令方案，会在通道切换时带来副作用 => 重复发送通道停止推流命令；因为，通道切换时，就是让老师推流者自动删除；
            还有一种简化方案 => 增加标志CStudent::m_bIsCanDetect，在CStudent::doServerSendDetect()中判断标志，阻止学生推流端进行探测，造成学生端缓存超过伐值，自动删除；
            保留方案1的代码，做好标记和注释，实际采用方案2，这样可以保持学生推流者在学生端的表现不变；

3.（已完成）udpserver，单独转发交互学生端的音频，从服务器端入手而不是讲师端或学生端，这种方式，还是会有新的问题，组播转发的问题；
  （已完成）udpserver，不需要对学生端进行标记，详见udp房间对象CRoom，里面已经通过idTag对学生端进行了身份标记；
  （已完成）udpserver，只需要在CRoom中新增接口，专门将特殊的学生推流音频转发给所有观看端，并做好排查自己的工作；
  （已完成）udpserver，讲师端|学生端，在服务器都有唯一TCP连接，udp分为推流和拉流，两个无状态连接；
  （已完成）udpserver，无论讲师端还是学生端，udp的两个无状态连接，已经通过rtp_create_t里的tcpSock关联了，tcp连接总是先于udp启动，登录成功之后会返回tcpSock，在udp的推流和拉流对象中都会带上这个tcpSock，形成自然的关联；
  （已完成）udpserver，CRoom当中新增doStudentPusherToStudentLooker接口，这个接口里面就要排除学生推流者关联的学生观看者，确保学生推流者音频数据不要回到自己的观看者对象当中；
  （已完成）udpserver，同一个房间当中，学生推流端直接转发音频数据给所有在线的其它学生观看端，和讲师端；
  （已完成）udpserver，学生推流端在转发音频数据给学生观看者时，需要在每个音频包中附带音频序列头信息；在rtp_hdr_t当中新增保留字段 unsigned int noset
  （已完成）udpserver，需要修改讲师端|学生端的rtp_hdr_t，新增unsigned int noset，将所有812字样，全部改成结构体计算值，不能是硬编码；
  （已完成）udpserver，单独转发“互动教室”的音频数据，这种附加音频单独进行补包，拿到之后直接进行播放就可以了；
  （不处理）udpserver，是否转发“互动教室”的音频数据，由讲师端是否浮动“互动教室”的视频窗口做为控制命令；
  （已完成）udpserver，讲师观看者，改造前，拉取学生推流者的补包命令，是直接转发给了学生推流者，从学生推流者源头补包；
  （不处理）udpserver，学生观看者，改造前，拉取学生推流者的扩展音频补包命令，是直接转发给了学生推流者，从学生推流者源头补包；
  （已完成）udpserver，讲师推流者，改造后，它的音视频在服务器上已建立音视频环形缓存，学生观看者直接从服务器补包，不用再到讲师推流者的源头补包；
  （已完成）udpserver，学生推流者，改造后，它的音视频在服务器上要建立音视频环形缓存，讲师观看者|学生观看者(扩展音频)都直接从服务器补包，不用再到学生推流者的源头补包；
  （已完成）udpserver，CRoom当中需要新增通道切换次数m_wExAudioChangeNum，就是扩展音频切换，因为，音频发生变化，扩展音频包序号也发生了变化，影响终端播放；
  （已完成）讲师推流者，改造后，它的补包只来自服务器的补包，没有直接来自学生观看者的补包，在服务器端已建立补包缓存；
  （已完成）学生推流者，改造后，它的补包只来自服务器的补包，没有直接来自学生观看者|讲师观看者的补包，在服务器要建立补包缓存；
  （已完成）服务器|学生端，恢复到之前的状态，先对学生推流端的服务器缓存，与讲师推流端的过程进行整合统一；
  （已完成）目前正在改造的是：学生推流端 参考 讲师推流端，都在服务器上建立缓存，而不是通过服务器转发命令，包括探测和补包；
  （已完成）C:\Users\Jackey\Desktop\obs-code\扩展音频 => 这个目录存放的是扩展音频模式改造了一半的代码，发现学生推流端在服务器没有缓存，造成扩展音频补包成问题，需要改造成学生推流端也要在服务器建立缓存；
  （已完成）学生端，这种模式下，学生端推流必须通过服务器中转，不能走P2P模式；
  （已完成）学生端，处理组播转发者、组播接收者有关扩展音频的转发和播放的实现；
  （已完成）学生端，在TCP连接登录时，需要回报学生的角色状态(外网接收者|组播接收者|组播转发者)，便于扩展音频的转发时判断；
  （已完成）服务器，被交互的学生推流者，只有是组播发送者时，才需要被转发扩展音频数据包，学生端接收后，不能本地播放，只能组播转发；CRoom:190
  （已完成）学生端，组播发送者，又是交互推流者，需要接收扩展音频，但不要播放，只是进行组播转发；
  （已完成）学生端，组播接收者，又是交互推流者，是通过内网中组播转发者接收扩展音频数据包，本学生端收到组播数据后，不能播放扩展音频数据包；

4.（不处理）学生端，利用ONVIF协议，不使用SDK的模式下，进行IPC的云台控制；最终选择ISAPI方式，ONVIF在有些IPC上不一定支持；只用海康IPC的话ISAPI是一定支持的；
  （已完成）云台控制标准协议 => VISCA、PELCO-D、PELCO-P，都是通过RS232串口通讯；USB可以模拟串口，也能实现云台控制，可以免去串口线；会议摄像机里面用的多；
  （已完成）还有一种云台控制协议 PTZ，通常通过 ONVIF 协议控制，目前在海康监控摄像头里面用的多；PTZ应该是网络协议，其它的是串口通讯协议；
  （已完成）学生端的摄像头窗口新增右键菜单，新增两个菜单内容：预览画面|开启云台
  （已完成）学生端的每个正在运行的摄像头通道都可以通过右键菜单开启画面预览功能（SDL2.0播放）；
  （已完成）云台窗口只有一个，是浮动窗口，可以上、下、左、右、还原、光圈、焦距控制摄像头；
  （不处理）需要能够自动探测当前摄像头是否支持ONVIF协议，根据摄像头的IP地址进行探测；
  （已完成）学生端，在创建|修改摄像头通道时，需要对rtsp地址进行分离，提取出 IP地址|用户名|密码，存放到数据库，备用；
  （已完成）学生端，从数据库获取的通道信息需要包含 IP地址|用户名|密码，用来进行HTTP的ISAPI摄像头Digest认证；
  （已完成）学生端，无论是写入wk_camera记录，还是读取wk_camera记录，都需要分解stream_url字段，获取 IP地址|用户名|密码 不存放到数据库，然后返回给学生端；
  （已完成）学生端，doWebGetCamera|doWebRegCamera，还要改动GatherAction.class.php|getCamera|regCamera，分解stream_url字段，不写入数据库，返回给学生端；
  （已完成）学生端，利用时钟在检测到IPC拉流成功之后，进行ISAPI的登录探测，即自动进行ISAPI的登录过程，由探测结果来确定是否开启“云台控制”菜单；
  （已完成）学生端，左侧通道窗口右键时，需要判断是否能够进行预览，不能预览将菜单置灰

5.（已完成）系统设置 => 配置框内容的完成；
  （已完成）关于 => 配置框内容的完成；
  （不处理）aboutToShow => 这个菜单按钮自动关联的信号槽，可以解决菜单状态的更新问题；
  （已完成）菜单状态更新，最简单的还是用Timer进行状态更新，但有延时；目前用的是触发机制，无延时机制；
  （已完成）每次启动，自动重连IPC通道，当修改状态时，不对自动重连进行检测，便于操作；
  （已完成）学生端 => 自动重连IPC，拉取rtsp数据的过程，需要重新梳理一下，目前的方式，容易造成线程卡死的问题；
  （已完成）学生端 => Live555里面的 Locale l("POSIX"); 会造成程序卡死，很久才能返回，需要屏蔽，总共有4个地方；
  （已完成）学生端 => 自动重连的rtsp窗口，会造成与QT冲突，页面卡死，之前解决过，但没有完全解决；
  （已完成）学生端 => 上面的问题是由于RTSP线程直接调用了QT线程的相关套接字代码，造成的冲突，换成信号槽调用就没有出现过问题了；
  （不处理）老师端可以对摄像机打开云台操作窗口（VISCA、PELCO-D、PELCO-P）
  （不处理）非压缩的摄像机，自动探测云台协议：VISCA、PELCO-D、PELCO-P，通过右键弹出云台控制窗口，选择USB端口，进行摄像机的云台控制；
  （不处理）互动教室的摄像头，也可以弹出云台控制窗口，对教室里的IPC摄像头进行远程云台控制，通过中转服务器来完成；
  （不处理）老师端 => 互动教室 => 当互动教室发生全屏投影时，会自动开启一个在最上层的浮动窗口，显示可以进行切换的学生端在线通道列表，并能实时更新；
  （已完成）老师端，第一行增加一个浮动窗口，自由伸缩，这样第一行就会有两个窗口，可以通过右键进行浮动或回到第二行窗口排列当中去；

2018.12.21 - 2019.01.21
===============================================================================================
0.（已完成）https://open.weixin.qq.com，完成网站应用的添加工作；帐号 => 3522218170@qq.com
  （已完成）开放平台的开发者资质认证已经完成，发票已经下载；
  （已完成）现在需要完成《网站信息登记表》的工作，完成网站应用的登记工作；
  （已完成）小程序申请完毕（启迪云），网站应用正在审核中（启迪未来）
  （已完成）网站迁移正在进行，把中心节点、公司网站，全都放到qidiweilai.com下面，前端就是公司展示网站，后端就是双师后台管理网站；
  （已完成）https://qidiweilai.com/wxapi.php/Index  => 前端展示页面 => https://qidiweilai.com
  （已完成）https://qidiweilai.com/wxapi.php/Admin  => 后台控制页面 => https://qidiweilai.com/admin
  （已完成）https://qidiweilai.com/wxapi.php/Mini   => 小程序接口页 => 小程序内部隐藏访问
  （已完成）https://qidiweilai.com/wxapi.php/Index  => 微信网站应用 => 微信网站回调隐藏访问
  （已完成）https://qidiweilai.com/wxapi.php/Gather => 学生端|讲师端接口调用隐藏访问，注意：中心与节点合并；
  （已完成）E:\obs-studio\qidiweilai\wxapi          => 所有网站存放 => 所有的应用与页面都存放到一个目录下面，每个应用对应一个页面；
  （已完成）服务器的配置需要进行位置调整，调整后的结果如下：
  （已完成）myhaoyi.com(118.190.45.238)   => 去掉 udpcenter，即不要加载中心服务器；
  （已完成）myhaoyi.com(118.190.45.238)   => 修改 udpserver，连接的中心服务器修改为 => qidiweilai.com，仍然保持“调试模式”
  （已完成）qidiweilai.com(47.92.150.159) => 新增 udpcenter，即增加中心服务器的功能；
  （已完成）qidiweilai.com(47.92.150.159) => 修改 udpserver，连接的中心服务器修改为 => qidiweilai.com，仍然保持“生产模式”
  （已完成）将中心数据库与教育数据库合并成中心数据库 => educate，公司前端展示网站目前没有用到数据库功能；
  （已完成）虽然将中心网站和节点网站合并，数据库也进行了合并，但是，访问流程不能减少，避免大的改动；
  （已完成）www.qidiweilai.com，前端展示网站要做一个简化版本的移动端网站页面；
  （已完成）学生端|讲师端 升级版本号为 1.1.6，同时更新到新的中心网站服务器 => https://qidiweilai.com
  （已完成）新配置的服务器，fdfs的存储配置会获取本地服务器的地址，而不是外网地址，E:\GitHub\build\rpm_bin\config.sh 不要用auto参数；
         A：fdfs-storage的当前配置，fdfs-tracker是获取storage链接过来的IP地址，因此fdfs-storage必须设置主机的外网地址，这样tracker就能把链接的外网地址当成storage的地址；
         B：使用阿里云的专有网络会出现两个tracker，造成不停的在选择leader，目前没有好的处理方法，但不影响使用
         C：调试FastDFS的配置目录 => E:\GitHub\HaoYiYun\Document\云教室\Fiddler => /etc/fdfs
         D：使用了各种方法尝试，直接把tracker和storage的地址都直接设定成外网地址47.92.150.159，但都会造成tracker一直在寻找leader的错误；
         E：这个错误的本质是由于47.92.150.159并不是服务器的本地地址(172.26.96.164)，tracker无法设定为leader，从而一直报错；
         F：最终，还是要用sh config.sh auto，自动寻找本地地址配置tracker和storage的地址，这样并不影响访问，因为47.92.150.159与172.26.96.164存在自动关联关系；
         G：要修改学生端和讲师端，在获取到storage地址之后，不要使用，而是使用tracker地址进行文件的上传工作，这样直接使用tracker的映射地址，而不是内网地址；
         H：网站的图片上传不受影响，因为是js先传到服务器，服务器再通过php的FastDFS接口上传给storage，就不会出现这种问题；
         I：因此，学生端|讲师端最好的改进办法是不要自己做CStorageSession，而是直接通过curl上传jpg，再触发php进行上传，但是，太过麻烦，花费时间太多；
         J：找到了一种更好的方法 => CTrackerSession获取到storage的IP地址之后，分析判断出是内网地址，就用连接tracker的地址去替换storage的地址；
         K：详见 FastSession => CTrackerSession::doStorageWanAddr()里面针对内网地址的判断方法；
  （已完成）obs.dll(libobs) 讲师端|学生端 都需要的发行库，在编译时需要投递两个目录rundir/Release和student/Release
  （已完成）obs-app.cpp:385 => 默认关闭配置 => RecordWhenStreaming => false
  （不处理）讲师端，录像时，如果要录制互动教室的音频，需要将录制音频的轨道设定为2，目前的录制音频轨道默认是1；
  （不处理）轨道1是专门回传给互动教室的音频(屏蔽互动教室音频)，轨道2是专门发送给未交互终端的学生端，需要包含互动教室的音频；
  （不处理）当将“互动教室”做为主推场景时，需要将“互动教室”的音频监测修改为 => 监视器和输出，并启动轨道2的压缩，这时向所有学生端推送2个轨道的音频；
  （不处理）轨道1当中不包含“互动教室”自身的音频数据（提供给已选中学生端播放），轨道2当中包含“互动教室”自身的音频数据（提供给未选中学生端播放）；
  （不处理）录像时，需要录制轨道2（包含“互动教室”自身的音频数据）；

1.（已完成）调整讲师端 互动教室 的音频输出，让所有的连接终端都可以听到互动教室的声音；默认设置成既输出又监视的模式；window-basic-source-select.cpp:243
  （已完成）利用三台机器进行声音的交互实验，一台学生端在屋外采集声音被交互，一台学生端在里屋监视，一台讲师端在里屋进行控制；
  （不处理）学生端收到讲师端音频解码之后，不要直接播放，而是先进行回音消除，消除之后再进行播放，消除的比对数据，是学生端发送给老师端的音频数据；
  （不处理）学生端收到讲师端音频解码之后，直接存盘测试，丢弃；学生端发送给讲师端的音频数据，需要存盘测试；然后，对这两个数据进行回音消除，然后比对；
  （不处理）以上两条采用回音消除的方法行不通，会造成严重回音震荡的问题，处理起来也不稳定，准备采用两个轨道同时压缩输出，在服务器端进行分离转发的方法；
  （不处理）讲师端，互动教室，音频监测，默认设定成 => 监视并输出 => 输出选项能控制后面轨道是否有数据；
  （不处理）讲师端，互动教室，轨道1，无论焦点窗口如何切换，都要屏蔽混音输出功能，即永远设定成 false 状态，window-basic-main.cpp:5858
  （不处理）讲师端，互动教室，轨道2，无论焦点窗口如何切换，都要选中混音输出功能，即永远设定成 true 状态，window-basic-main.cpp:5858
  （不处理）讲师端，焦点窗口切换，窗口对应的音频输出，轨道1和轨道2，都要跟进焦点的切换而调整；
  （不处理）讲师端，轨道1和轨道2的音频数据，同时压缩，输出，在rtp打包时专门做标记，标明是哪个轨道，需要在rtp协议上做扩展；
  （不处理）讲师端，轨道1和轨道2的音频数据，同时压缩，这样就可以保证音频的时间戳同步，又不额外增加通道，丢包补包都用一个通道；也没有让服务器混音，服务器只是对讲师端过来的音频rtp数据包做简单的分发转移就可以了；
  （不处理）讲师端，需要将 win-rtp 修改成 OBS_OUTPUT_MULTI_TRACK 支持音频多轨道，能够接收处理音频的多轨道压缩数据包功能；
  （不处理）讲师端|学生端|服务器，rtp.h => rtp_hdr_t => 新增 unsigned char pai:2; => 记录音频轨道编号 => 0(不混互动)1(混音轨道)
  （不处理）服务器，udpserver，由于同一个音频包有两个轨道，需要在服务器上做分发，学生推流端只能接收轨道1音频，旁观学生只能接收轨道2音频；
  （不处理）服务器，udpserver，对音频进行轨道分离的时候，需要注意修改音频轨道的序号，序号必须大于0，从1开始递增；轨道编号加1进行编号计算；
  （不处理）服务器，udpserver，不能在服务器端对音频轨道进行分离，会造成序号不连续，会带来丢包后的补包困难，同时，还要在服务器匹配推流学生端和接收学生端；
  （不处理）服务器，udpserver，服务器端完全不变，讲师端两个音频轨道都是通过一个udp套接字传输，分发机制完全不变，只是增加了带宽冗余，让学生端自己去分辨自己该播放哪个轨道的音频数据；
  （不处理）学生端，是推流者，播放来自讲师端轨道1的音频数据包；是旁观者，播放来自讲师端轨道2的音频数据包；
  （不处理）讲师端进行多轨道音频压缩、传输，实验失败，会带来音频声音卡顿严重，没有达到预期效果，还会造成网络传输|补包问题，目前放弃这种方式；
  （不处理）后期可以考虑先实现“互动教室”的浮动功能，再考虑音频在服务器端的单独分流功能，不要让讲师端进行多轨道压缩；

2.（已完成）启迪双师 => https://www.qidiweilai.com，只设定一个站点，将中心站点与数据节点都整合到一起去，这样可以简化管理；
  （已完成）中心数据库、节点数据库、分校数据库都整合到一起，形成一个唯一数据库，educate数据库；
  （已完成）这样的安排，可以将微信授权、小程序授权、学生端、老师端授权都集中到一起，统一管理；
  （已完成）这样的安排，可以将通过一个网站来对总部、分校，等等信息进行统一的集中管理；
  （已完成）wk_gather => ip_send 的默认值是 INADDR_ANY，就是0，不要用NULL，意思不一样；
  （已完成）给 www.qidiweilai.com 设置 https 安全链接访问功能，申请并设置 SSL 安全链接；
  （已完成）微信开放平台的网站授权访问的问题总结 => 如何避免重定向拦截问题；
         A：在开放平台需要填写唯一的域名 => www.qidiweilai.com，在页面当中也需要输入完整的重定向地址 redirect_uri => https://www.qidiweilai.com
         B：用户在输入时有可能输入http://www.qidiweilai.com或http://qidiweilai.com，所有需要先把所有的http://重定向到https://，详见nginx.conf配置
         C：如果用户通过https://qidiweilai.com访问，扫码之后微信会自动重定向到https://www.qidiweilai.com，域名不一致会被谷歌浏览器拦截，提示重定向被阻止；
         D：在nginx.conf当中把所有不是www.qidiweilai.com的域名重定向到www.qidiweilai.com，详见nginx.conf配置文件；
         E：在学生端|讲师端内嵌的域名也必须是https://www.qidiweilai.com，因为curl不会自动再转移重定向，不能用https://qidiweilai.com
         F：udpserver当中由于只是获取域名的IP地址，不受跳转的影响，为了统一起见，都换成 www.qidiweilai.com
         G：如果是二级域名，不要支持 www 格式，太长了；让所有的域名都指向一个 www.qidiweilai.com
         H：把wk_system里面的sys_site|web_tracker_addr都改成统一的 https://www.qidiweilai.com
  （已完成）对头像地址的https修正，放到了网站应用返回数据的时候，而不是写入数据库之后，可以简化后续的操作；
  （已完成）网站应用获取的头像是http格式，小程序头像是https格式，由于全站都用https，网站应用返回的数据，需要对头像地址进行验证和修正；
  （已完成）https://www.qidiweilai.com官方网站，使用fullpage.js和animate.css，实现滚动动画功能；
            fullpage.js => https://github.com/alvarotrigo/fullPage.js/tree/master/lang/chinese
            animate.css => https://daneden.github.io/animate.css/
            参考文档 => https://blog.csdn.net/cplvfx/article/details/80649574
            完整示例 => E:\GitHaoYi\fullPage.js ― 回调函数演示和animate.css使用
  （已完成）官方网站，设定三个分辨率，其中电脑2档分辨率，手机1档分辨率，每种分辨率采用不同的样式；
            默认样式 => 分辨率大于1280的电脑屏幕 => 显示宽度 => 1200px
            中间样式 => 分辨率大于1024，小于1280的电脑屏幕 => 显示宽度 => 900px => @media screen and (min-width: 1024px) and (max-width: 1280px) {}
            手机样式 => 分辨率小于750的手机屏幕 => 显示宽度 => auto => @media screen and (max-width: 750px) {}
  （已完成）https://www.qidiweilai.com/admin => 在扫码登录成功之后，没有跳转到管理页面，始终跳转到前台首页；
  （已完成）前端页面也需要有扫码登录的入口引导按钮，也需要退出登录机制；
  （已完成）在网站的“双师系统”页面，直接加入讲师端和学生端的下载按钮，每次升级都要对应更新页面内容；
  （不处理）后期可以考虑直接让php从update_studio目录读取下载文件，并直接反馈到下载的方式，这样可以避免每次都要修改下载地址的麻烦；
  （不处理）这个功能等到下次升级到 1.1.6 版本时一起解决，包括那个日志显示的地方，也让php自动去读取并显示处理，避免每次手动修改；
  （已完成）E:\GitHub\HaoYiYun\Product => /weike/educate/update_studio => 升级内容放置位置
  （已完成）升级内容会根据状态，适当保留老版本，版本会不断被更新替换掉；
  （已完成）需要在nginx进行下载限流，设定为最大流量为1024kbps，避免流量消耗；
            https://www.cnblogs.com/MacoLee/p/6023201.html => 限流配置
            https://blog.csdn.net/weixin_29135773/article/details/60764426 => 更详细说明
            http://www.cnblogs.com/chenpingzhao/p/4971308.html => 更精确更简单的说明
  （已完成）最终配置如下 => 针对单个IP的流量限制，比如用户开迅雷等等 => 迅雷实测有效，1M字节之后限制在126KB码流；
            limit_conn_zone $binary_remote_addr zone=one:10m; => http{} 里面，命名为one，10m缓存
            location ~/update_studio/ {        => 只针对update_studio这个目录
                limit_conn      one    1;      => 限制连接数，只允许一个下载连接
                limit_rate          128k;      => 限制连接码流 128*8 => 1024kbps
                limit_rate_after      1M;      => 在下载量达到1M之后才进行流量限制
            }

3.（已完成）https://www.qidiweilai.com，官方网站，准备用layui进行栅格布局，而不是自己手动进行页面布局；
  （已完成）通常采用一行的方式，不断累加列，每隔12个等分自动换行，这样排列内容就比较简单了；不用考虑分行的麻烦；

4.（已完成）2019.01.03，阿里云遇到一个非常奇怪的问题，ssh远程、访问网站非常缓慢，通过网页版“远程连接”速度还行；
            尝试将固定1Mbps修改为按流量5Mbps峰值，还是访问缓慢，通过网页监控发现网络负荷很小，CPU负载也很小，就是通过网络访问速度慢，讲师端、学生端打开都慢；
            尝试重启本地光猫之后，访问速度恢复了正常状态；之前阿里云有提示异地登录问题，1.180.18.194(呼和浩特)，重启之后分配IP为223.72.57.183，访问正常了；
            通过 last 命令查看，大多数都是223开头的IP地址，今天突然出现的1.180.18.194，估计就是这个光猫分配的异地IP地址造成的问题；
            https://help.aliyun.com/knowledge_detail/40573.html => 阿里云客服提供的反馈，通过双向mtr进行测试分析；这个回答很专业；
            mtr正向测试：本地电脑（打不开网站的地方）--->服务器
            mtr反向测试：服务器--->本地电脑（打不开网站的地方）
            mtr工具使用方法：https://help.aliyun.com/knowledge_detail/40573.html => 具体详见提交的工单记录；
            让我知道了还有比tracert更为强大的网络探测工具，Linux下mtr，Windows下的WinMTR(I:\工具软件\WinMTR-v092\WinMTR_x32)
            http://ip.taobao.com/service/getIpInfo.php?ip=[ip地址字串] => 查询IP地址归属地的API接口，就是偶尔会发现无法连接的问题；
            http://www.ip138.com/ => 访问稳定，需要付费使用IP地址查询接口功能；
  （不处理）后续思考 => 服务器在山东青岛(118.190.45.238)，运行了nginx|udpserver|udpcenter，学生端|讲师端在呼和浩特，IP地址为1.180.18.194，就会造成访问非常缓慢，打开网站都非常慢，更不要说进行视频数据交换了；
            后续思考 => 这个问题将来在服务多地域的用户时，会是一个大问题，如何部署服务器是个大问题，如何根据用户连接的IP地址进行有效的服务器分配也很重要；
            后续思考 => 需要对服务器的功能事先进行规划，学生端|讲师端都需要探测服务器地址，哪个快速就连接哪个，只不过由于业务原因，可能需要探测多个地址，这需要服务器的业务事先规划才行；
            后续思考 => 本来是想着怎么改进服务器的分布与配置，但想到如果是运营商错误的分配了IP地址，造成链路混乱，就可以暂时不用管这个问题；
            后续思考 => 这个问题也能解释为什么zhihu.com上的视频无法播放的问题，也是由于分配了1.180.18.194，无法到达视频服务器的缘故；但是B站的视频就处理的很好；
            后续思考 => 上回在购买ECS遇到的访问特别慢的问题，估计也是这个原因，因此，极有可能这个问题还会重现，就是当光猫重新分配地址的时候就可能发生问题；
            后续思考 => 阿里云通过提交工单的方式，更容易更准确的解决问题，比打电话要专业的多；
            解决方法 => https://mp.weixin.qq.com/s?__biz=MzU1NTEzOTM5Mw==&mid=2247488830&idx=1&sn=6f91b52ebfb0b1475ea34f6bca693d32
            解决方法 => 这是提供了一种思路，但不能完全照搬，这种方式模块非常多，不确定性非常大，需要借鉴思路进行优化自己开发接口；
 
5.（不处理）讲师端 => 互动教室，长时间拉取学生端数据流，感觉会造成延时增大，还没有找到具体产生延时的原因，需要进一步的测试；
  （不处理）讲师端 => DX安装提示D3D的提示错误，需要dxwebsetup.exe支持；提示信息还是英文的，需要修改成中文；

6.（已完成）在极客时间上购买了一直想学习的《TensorFlow快速入门与实践》这个视频课程，可以快速了解TensorFlow；

7.（已完成）利用Fiddler截包工具，查看受限制的微信页面，即只能在微信中打开的页面；
  （已完成）安装Fiddler => I:\工具软件\Sniffer\FiddlerSetup-5.0.20173.50948.exe
  （已完成）使用教程 => https://www.cnblogs.com/qinyulin/articles/6843829.html
  （已完成）核心思路 => Fiddler在PC端创建一个代理服务器，手机通过代理上网，所有数据都会被Fiddler截获，并自动解码，导出页面；
  （已完成）问题收集 => 这种方式好像对websocket无法起作用，无法打开微信公众号分享的文章，对直接的网页很有用；
  （已完成）演练实例 => E:\GitHub\HaoYiYun\Document\云教室\Fiddler\小灯塔 => http://qidiweilai.cn/courseDetails.html
  （已完成）专门建立一个网站域名用来测试这种拔取样式的方法，模拟一些操作；
手摇手动简易办工电脑桌单桌面升降调节站立办公职工人体学
8.（已完成）讲师端 - 最新硬件设备参考：
            吃鸡主机 => https://item.taobao.com/item.htm?id=571604650526
            迷你主机 => https://item.taobao.com/item.htm?id=42292521015   => 1899元|套餐八|4G内存|120G硬盘|双显|i7-6500U => 预装Win7纯净版|很好很干净
            迷你音箱 => https://detail.tmall.com/item.htm?id=551672957604 =>   20元|AIEK-DX11
            无线键鼠 => https://detail.tmall.com/item.htm?id=537609594534 =>  110元|罗技MK245nano
            摄像头1  => https://item.taobao.com/item.htm?id=566420654479  =>  400元|罗技C930E|自带麦克风|USB
            摄像头2  => https://item.taobao.com/item.htm?id=579291774593  =>  400元|罗技C930E|自带麦克风|USB
            摄像头3  => https://item.taobao.com/item.htm?id=562771741881  => 1200元|罗技C1000E|自带麦克风|USB
            摄支架1  => https://item.jd.com/28709307629.html              =>   40元
            摄支架2  => https://item.jd.com/28709307629.html              =>   40元
            显示器1  => https://detail.tmall.com/item.htm?id=559784338211 =>  799元|AOC24寸液晶显示器
            显示器2  => https://detail.tmall.com/item.htm?id=559784338211 =>  799元|AOC24寸液晶显示器
  （已完成）学生端 - 最新硬件设备参考：
            迷你主机   => https://item.taobao.com/item.htm?id=42292521015   => 1399元|套餐五|4G内存|60G硬盘|双显|i7-四线程
            高效音箱   => https://item.jd.com/974882.html                   =>  230元|漫步者（EDIFIER）R26T
            无线键鼠   => https://detail.tmall.com/item.htm?id=537609594534 =>  110元|罗技MK245nano
            POE交换机  => https://detail.tmall.com/item.htm?id=563770319020 =>   99元|腾达5口百兆POE交换机
            IPC摄像头  => https://item.taobao.com/item.htm?id=553420566965  =>  680元|DS-2DE2204IW-DE3/W|200万|4倍变焦
            扩展拾音器 => https://item.taobao.com/item.htm?id=523261695288  =>  128元|辉声乐22HA双咪头拾音器
            短焦投影仪 => https://item.jd.com/5342470.html                  => 4999元|明基E610短焦投影仪(焦距1米)
            短焦投影仪 => https://item.jd.com/1019819.html                  => 2999元|明基MS3083ST+(焦距2米)
            投影大幕布 => https://item.jd.com/11021339873.html              =>  329元|帝诺80寸电动投影幕布
  （已完成）编写文档 => E:\GitHub\HaoYiYun\Document\云教室\双师设备\《双师设备-乐高.docx》：

9.（已完成）讲师端、学生端，新增自动升级功能，具体参考obs-studio的方法，每次启动都会检测版本，并下载安装升级；
  （已完成）首先，需要搞清楚obs-studio的自动升级检测、自动下载、自动安装的过程；
  （已完成）改进过程，在每次讲师端、学生端登陆之前检测软件版本，并与自己的当前版本进行比较，而不是系统进入之后再进行版本比较；
  （已完成）自动更新功能的加载流程有了大概的了解，现在需要分析update.exe下载与更新的具体实现流程；
  （已完成）自动更新整体思路 => 服务器端每个文件需要创建一个hash表，保存到json文件，更新工具下载json文件，临时计算本地文件的hash值，来判断是否需要下载服务器上的文件；
  （已完成）讲师端、学生端，所有的打包程序需要纳入git管理，便于判断变化和升级更新；DLL发生更新需要明确知道，否则，容易错误；
  （已完成）需要重新把各个模块的数据进行必要的整理，避免不必要的数据被检测或更新，特别是那些多语言配置，只留下中文配置；
  （已完成）更新模块进程需要通过不同的参数进行不同的操作：
            update.exe teacher       => 执行讲师端的升级过程...
            update.exe student       => 执行学生端的升级过程...
            update.exe json_teacher  => 执行讲师端生成manifest.json升级文件...
            update.exe json_student  => 执行学生端生成manifest.json升级文件...
  （已完成）update.exe有关字符串的处理函数总结：
            StringCbPrintf() => 字符串格式化
            StringCbCopy()   => 字符串拷贝
            StringCbCat()    => 字符串追加
  （已完成）讲师端、学生端本地升级目录结构如下：
            vsbuild/rundir/Release   => 32位讲师端发行版编译输出目录、打包读取目录
            vsbuild/student/Release  => 32位学生端发行版编译输出目录、打包读取目录
            vsbuild/update_studio/bin/32bit  => 讲师端|学生端升级程序32位发行版编译输出目录
            vsbuild/update_studio/teacher/manifest.json => 讲师端升级json索引文件，方便下载升级
            vsbuild/update_studio/teacher/changelog.txt => 讲师端更新日志，格式参考下面的notes节点
            vsbuild/update_studio/student/manifest.json => 学生端升级json索引文件，方便下载升级
            vsbuild/update_studio/student/changelog.txt => 学生端更新日志，格式参考下面的notes节点
  （已完成）注意：update.exe里面，访问路径名称必须是宽字符，与系统保持一致...
  （已完成）注意：update.exe里面，json和txt存盘内容必须是UTF8格式，适应通用性...
  （已完成）jansson这个json库，很容易造成内存泄漏还不好检查，也不提示，json_decref，完全靠引用计数自动删除关联的节点数据；
  （已完成）之前一直用json_object_set，这个函数会自动增加引用计数，会造成无法自动删除，需要使用json_object_set_new，不会产生引用计数；
  （已完成）jansson的使用需要非常小心，特别是引用计数器，不同的函数有不同的计数方式，直接影响节点的释放；
  （已完成）jansson的核心思路是 => 只需要释放根节点，所有节点都以不同的形式挂接到根节点上面，这是最重要的思路；
  （已完成）jansson的json_dumps()会分配内存并返回字符串，这个字符串一定要手动释放，否则会有内存泄漏；
  （已完成）在使用jansson.h这个json库的时候，发现有内存泄漏问题，json_set_alloc_funcs() 重定义内存分配函数进行跟踪；
            需要重定义json_malloc_t和json_free_t，增加 ..\..\..\libobs\Debug\obs.lib ，增加 include <util/bmem.h>
            bmalloc|bfree需要使用到obs.lib库，运行时需要大量的动态库，内存检测跟踪完毕之后就需要去掉；
            如果不想这么麻烦，也可以采用单步跟踪~OBSJson析构函数的方式，json_decref()，看看是否完整释放了所有节点；
  （已完成）由于简化了update.exe本地流程，无需上传本地数据，可以去掉 HTTPPostData()，但无法去掉 HTTPGetFile()，因此还是不能去掉zlib.dll的支持；
  （已完成）只将release版本的发行文件上传到github当中，并预先配置好manifest.json文件的结构；
   {
     "notes":"
       <h1>讲师端更新日志</h1>
       <h2>1.1.5 版本更新日志</h2>
       <ul>
         <li>xxxxx
           <ul>
             <li>xxx</li>
             <li>xxx</li>
           </ul>
         </li>
         <li>xxx</li>
         <li>xxx</li>
       </ul>
       <h2>讲师端更新历史日志</h2>
       <h2>1.1.4 版本更新日志</h2>
       <ul>
         <li></li>
         <li></li>
       </ul>
     ",
     "packages":
      [
        {"files":
          [
           {"hash":"md5","name":"bin/32bit/avcodec-57.dll","size":12196288},
           {"hash":"md5","name":"bin/32bit/avdevice-57.dll","size":138688},
           {"hash":"md5","name":"bin/32bit/avfilter-6.dll","size":2260928},
           {"hash":"md5","name":"bin/32bit/avformat-57.dll","size":2338240},
          ],
         "name":"core"}
      ],
     "vc2015_redist_x64":"md5",
     "vc2015_redist_x86":"md5",
     "version_major": 1,
     "version_minor": 1,
     "version_patch": 4
   }
  （已完成）只留下中文还不行，必须还包含en-US的配置文件，这样data语言必须包含 en-US 和 zh-CN，因为en-US是原始文件；
  （已完成）还要注意区分teacher与student的更新，每个软件又分为32位和64位的更新，目前只进行32位系统的发行工作；
  （已完成）updater本身是否带有自动计算hash并生成manifest.json文件的功能？目前的升级功能只能放在edu.ihaoyi.cn当中；
  （已完成）updater过程 => 解析、下载、安装...
  （已完成）updater里面的连接地址全部修改为 https://edu.ihaoyi.cn
  （已完成）updater使用一个外部参数进行manifest.json的生成工作；
  （已完成）https://edu.ihaoyi.cn 自动升级目录结构如下：
            https://edu.ihaoyi.cn/update_studio/updater.exe
            https://edu.ihaoyi.cn/update_studio/teacher/manifest.json
            https://edu.ihaoyi.cn/update_studio/student/manifest.json
  （已完成）讲师端 => 屏蔽manifest.json的数字签名验证，这样可以简化edu.ihaoyi.cn的配置，只需要把manifest.json放在指定位置就可以了；
  （已完成）https://www.cnblogs.com/xuzhudong/p/8339853.html => 有关WEB缓存，Etag 和 If-None-Match
  （不处理）网站端 => 可以利用EnableAutoUpdates来控制是否让所有系统开启自动升级或关闭自动升级；系统基本配置当中已经有设定；
  （已完成）global.ini有关升级检测的配置参数设置：
            General => EnableAutoUpdates => 自动检测标志，控制是否进行升级检测，后续可以通过右键菜单强制升级；
            General => LastVersion => 记录上一次升级的版本，Major|Minor|Patch，记录在uint32_t当中；
            General => LastUpdateCheck => 记录上次更新检测的时间，超过4天(UPDATE_CHECK_INTERVAL)才会弹框强制升级；
            General => ETagManifest => manifest.json在服务器端生成的标记(不是md5，只要修改时间变化就会重传)
            General => ETagUpdater  => updater.exe在服务器端生成的标记(不是md5，只要修改时间变化就会重传)
            General => SkipUpdateVersion => 记录用户跳过升级的版本号，如果是手动强制升级，即使跳过的版本也要强制升级；
            https://edu.ihaoyi.cn/update_studio/updater.exe => {{APP_PATH}}\\obs-student\\updates\\updater.exe
            https://edu.ihaoyi.cn/update_studio/updater.exe => {{APP_PATH}}\\obs-teacher\\updates\\updater.exe
            https://edu.ihaoyi.cn/update_studio/student/manifest.json => {{APP_PATH}}\\obs-student\\updates\\manifest.json
            https://edu.ihaoyi.cn/update_studio/teacher/manifest.json => {{APP_PATH}}\\obs-teacher\\updates\\manifest.json
  （已完成）update.exe teacher => 重点跟踪teacher自动升级过程；
            E:\obs-studio\vsbuild\update_studio  => update.exe 独立调试运行时工作目录
            E:\obs-studio\vsbuild\rundir\Debug   => teacher.exe 调试版外部启动update.exe的工作目录
            E:\obs-studio\vsbuild\rundir\Release => teacher.exe 发行版外部启动update.exe的工作目录
            C:\Program Files\讲师端              => teacher.exe 安装版外部启动update.exe的工作目录
            FOLDERID_RoamingAppData\\obs-teacher\\updates\\manifest.json => 讲师端升级脚本存放位置
            FOLDERID_RoamingAppData\\obs-student\\updates\\manifest.json => 学生端升级脚本存放位置
            AppData\\Local\\Temp\\xxx.tmp  => 升级文件下载后临时存放目录，所有下载文件平铺，用md5值命名，校验完毕之后再转移到指定位置
  （已完成）update.exe => 下载升级文件时，需要开启gzip模式，这样可以降低网络的使用带宽；
            修改nginx.conf的配置，新增支持类型 application/octet-stream application/json
            https://www.cnblogs.com/mitang/p/4477220.html => 有关开启nginx的gzip方法；以及使用curl验证的方法；
            curl -I -H "Accept-Encoding: gzip, deflate" "https://edu.ihaoyi.cn/update_studio/teacher/manifest.json"
            注意：在下载manifest.json时，没有使用gzip，因为没有指定"Accept-Encoding: gzip, deflate"
            注意：通过测试指定了Accept-Encoding之后，GetRemoteFile()通过curl可以下载gzip数据，但还需要gzip对象解压，因此，下载manifest.json|update.exe不要用压缩模式；
  （已完成）update.exe => 目前只支持32bit的升级，因此64bit升级32bit的代码需要修改 => AddPackageUpdateFiles()
  （已完成）讲师端 => OBSApp::InitGlobalConfigDefaults() => 默认开启自动升级检测功能 => OBSBasic::TimedCheckForUpdates()
  （已完成）讲师端 => 调试版和发行版的编译开关中加入ENABLE_WIN_UPDATER，支持自动升级功能；
  （已完成）讲师端 => 在升级时的退出不能出现询问框，直接退出就可以了；
  （已完成）讲师端 => win-update.cpp:766，执行外部升级指令需要注意两个目录：
            lpFile => update.exe这个可执行文件所在的目录位置；
            lpDirectory => 给update.exe设定的工作目录，就是讲师端进程所在的启动目录；
            这样就可以让update.exe在任何地方启动，但都认为自己与讲师端进程所在目录是一起的；
  （不处理）每次完成自动升级之后，需要删除global.ini，以便再次启动后重建基础配置；因为升级版本可能依赖这个配置启动，有可能造成用户必须手动删除；
  （已完成）讲师端 => 去掉了gplv2.txt，txt格式在linux当中自动转换成单回车格式，与windows不一致，导致md5的哈希值不一致，因此，删除了；
  （已完成）讲师端 => 在启动外部升级模块之后，需要删除WebCenter和WebClass这两个参数的配置，新版本可能发生变化，从而导致无法连接服务器；
            win-update.cpp:774 => 设定LastUpdateCheck|SkipUpdateVersion为0
            win-update.cpp:779 => config_remove_value()删除服务器配置，新版本可能发生变化；
  （已完成）讲师端 => 根据对LastUpdateCheck的理解，只有在用户点击“稍后提醒”才会起作用(4天后)；如果是相同版本，也会每次启动都会检测；
  （已完成）版本号 => LIBOBS_API_MAJOR_VER(占8位),LIBOBS_API_MINOR_VER(占8位),LIBOBS_API_PATCH_VER(占16位)
  （已完成）讲师端 => 将版本与学生端保持统一为 1.1.5，升级工具的版本也要统一成 1.1.5 版本；obs-config.h当中统一修改版本号；
  （已完成）讲师端 => 始终将Pre19Defaults|Pre21Defaults设置为false状态；
  （已完成）讲师端 => 开启右键菜单，强制升级功能；强制升级的作用 => 用户点击“稍后提醒”或“跳过版本”之后又反悔的时候非常有用；
  （已完成）学生端 => 能够自动检查升级，并与讲师端保持一致，只是修改了一些下载路径；

2018.10.14 - 2018.12.20
===============================================================================================
0.（已完成）网站部分，各个模块的访问设计思路：
  （已完成）https://myhaoyi.com   => 中心服务器|认证服务器|微信开放平台账号管理
  （已完成）https://edu.ihaoyi.cn => 双师平台网站，展示前端，显示正在开课的云教室列表（房间）；
  （已完成）https://edu.ihaoyi.cn/admin => 管理者统一微信扫码登录入口；根据微信帐号的身份不同，跳转到不同的管理页面；
  （已完成）https://edu.ihaoyi.cn/Admin => 总部后台管理网站页面，统一管理总部的所有相关操作，对微信用户进行身份授权管理等等操作；
  （已完成）https://edu.ihaoyi.cn/Admin => 培训机构自己的后台管理网站页面，主要是针对课表和会员进行管理；根据不同的shop_id显示不同的后台配置页面内容；
  （已完成）2018.11.16，对所有模块进行了代码更新和上传；

1.（已完成）学生端 => 只要有视频播放时，右侧画面自动全屏，已经处于全屏状态的情况不处理；
  （已完成）网站端 => 通过后台网站进行虚拟教室房间的添加、修改、删除操作；
  （已完成）网站端 => 进行虚拟教室房间的讲师列表显示，并能修改房间讲师；
  （已完成）网站端 => 将layui升级到2.4.5最新版本，虚拟教室新增海报上传和修改功能；
  （已完成）网站端 => 首页展示已有房间列表信息，为了简化，将学生端和老师端的登录页面调整为保持一致；
  （已完成）网站端 => 通过后台网站进行虚拟教室房间的添加、修改、删除操作；
  （已完成）学生端 => 将DEF_CLOUD_CLASS|DEF_WEB_HOME|DEF_WEB_PORT都放置到obs-student的配置文件当中，不要写死硬编码到代码当中；
  （已完成）讲师端 => 将DEF_CLOUD_CLASS|DEF_WEB_HOME|DEF_WEB_PORT都放置到obs-teacher的配置文件当中，不要写死硬编码到代码当中；
  （已完成）讲师端 => obs的常规配置当中有两个值 => 默认设置和用户设置，可以同时存在；InitGlobalConfig()进行网站地址初始读取与赋值；
  （已完成）学生端、讲师端，打开接收线程的调试打印信息，便于查看播放延时情况；
  （已完成）网站端 => 只有一个前台页面，只有一个后台页面，根据用户类型的不同，显示不同的页面，不要对页面进行分离，会造成大量的麻烦问题；
  （已完成）网站端 => 用户后台登录权限控制，用户等级在运营维护以上的用户才能登录后台进行管理操作；

2.（已完成）网站端 => 需要将 edu.ihaoyi.cn 升级为 https:// 访问，这样小程序和网站都相对安全，因为不会牵涉到有关flvjs与hls播放的问题；
  （已完成）网站端 => nginx.conf，修改配置，升级为 https://edu.ihaoyi.cn，支持SSL安全访问，并且将所有的80端口访问也转移到443端口下面；
  （已完成）学生端、讲师端，都会牵涉到 https 链接的访问修改操作；
  （已完成）学生端、讲师端，重新编译打包，讲师端需要新增libcurl.dll与相关ssl动态库的更新；curl头文件还是使用obs的头文件 <curl/curl.h>
  （已完成）学生端、讲师端，需要在AppData\Roaming\obs-student\global.ini与AppData\Roaming\obs-teacher\global.ini当中更新配置；WebCenter与WebClass配置的更新；
  （已完成）学生端、讲师端，升级到1.1.4版本，并更新相关日志文件；
  （已完成）udpcenter => 配合网站后台的组件设置进行了升级改造，可以查看并设置中心服务器的状态信息；
  （已完成）udpcenter => 有一个SO_REUSEPORT重复使用端口的代码，可以让多个udpcenter同时运行，就会造成随机接入的问题，因此，要确保只有一个进程启动；

4.（已完成）申请小程序名 => 启迪未来双师
  （已完成）先用myhaoyi.com这个域名去申请相关小程序，做测试，等新的www.qidiweilai.com这个域名成功备案之后再申请新的小程序，命名为：启迪未来
5.（已完成）讲师端，以登录房间编号为基准，在开始推流之后，自动截取推流图片，自动上传到对应wk_room记录当中，更新到wk_image记录当中；
  （已完成）educate\wxapi\Lib\Model\RoomViewModel.class.php => 一个视图当中可以对应同一张表的两个字段，'_table'=>'wk_image'，这个是关键，要写完整表名称；
  （已完成）这样可以通过一个视图就能读取完整的截图与海报图片，而不用读取两次或写两个视图，简化了操作；
6.（已完成）https://blog.csdn.net/ZhangXiaoyu_sy/article/details/78925221 => 各种QT界面汇总
            https://blog.csdn.net/liang19890820/article/details/50773382?utm_source=blogxgwz1 => QLabel显示网络图片
7.（已完成）QPainter::setFont() => 使用这个方法可以在paintEvent()中任意改变字体大小、颜色等等；也就是及时设定字体，而不是只用系统设定的字体；
            QPainter::setOpacity() => 同样道理，也是可以实时设定，在绘制之前设定，可以绘制出不同的效果；
8. （已完成）阿里云 - 启动双师，专有网络，弹性公网IP，这些有点晕，新购买的ECS主机，只能看到172.26.96.164内网地址，无法看到47.92.150.159外网地址；
   （已完成）阿里云 - ECS和网络可以单独分开购买，网络分为三种形式 => 包年包月/按流量付费/弹性网络
   （已完成）阿里云 - 包年包月/按流量付费，都是有固定的对应公网IP，弹性网络是没有固定公网IP，需要与ECS的内网IP绑定，采用NAT的方式，进行弹性绑定；
   （已完成）阿里云 - 包年包月/按流量付费，都有固定公网IP，又分为经典网络和专有网络，经典网络服务器上能看到两个网卡，专有网络只有一个内网地址，公网是外部映射的；
   （已完成）阿里云 - 阿里云倾向于专有网络和弹性网络，这样阿里云可以有效的控制网络数量，并更好的利用网络资源进行有效分配；
   （已完成）阿里云 - 云盾Web应用防火墙，CNAME保护，将 edu.ihaoyi.cn 解析到另一个别名 xxx.com，由这个别名再访问真正的网站，通过这个别名桥梁来保护，防止直接获取IP而进行攻击；
   （已完成）阿里云 - 云盾Web应用防火墙，必须通过CNAME解析，所有的Web数据都进入一个专门的流量清洗通道，这样就能进行网站的各种保护；
   （已完成）阿里云 - 弹性IP的作用是在服务器受到攻击时，可以随时解绑公网IP更换新的公网IP，结合云盾Web的CNAME保护，可以针对随机的攻击起到一定的作用；
   （已完成）阿里元 - 如果是针对性的业务攻击，更换IP之后，攻击者针对性的跟踪业务，还是能针对性的攻击，就得使用防DDOS攻击的方式，专门对流量进行清洗，只能硬抗；
   （已完成）udpserver：屏蔽获取外网地址的接口，阿里云的专有网络无法在本地获取外网地址；
   （已完成）udpcenter：配合udpserver屏蔽获取外网地址的接口，直接使用udpserver的TCP链接地址做为远程地址和UDP地址；
   （已完成）目前服务器的各个部件的配置如下：
             网站端 => http://edu.ihaoyi.cn
             udpcenter => TCP:118.190.45.238:26026 => 通过wk_system可以手动配置修改，设置udpcenter指定安装地址；
             udpserver => TCP:47.92.150.159:21002 | UDP:47.92.150.159:15252 => 通过在服务器上安装udpserver完成；

9. （已完成）讲师端 => 麦克风输入的问题：为了回音消除，将麦克风的输入声音自动转换成了单声道声音；
   （已完成）一拖二小蜜蜂，通过3.5mm的输入，左右声道都可以进行输入，没有问题；
   （已完成）一拖四麦克风，通过3.5mm的输入，只有一组有声音，怀疑是由于在立体声转换成单声道时，将一个声道的声音扔掉了造成的问题，
   （已完成）要解决这个问题的最好办法是修改回音消除接口webrtc的AEC接口，使它能够支持立体声的回音消除，这样才能正在解决问题；
   （已完成）也可以跟踪看看，为什么一拖四麦克风，通过3.5mm输入之后，立体声转换时，会丢掉一个声道的数据内容；
   （已完成）一拖四麦克风，通过3.5mm的输入，插入跟踪摄像头，声音压缩选单声道时，会有一组声音丢失，声音压缩选立体声时，所有声音都是有效的；
   （已完成）这个问题，也可能跟一拖四麦克风的两组声音混合有关系，它们是将两组声音最终混合成了单声道输出了，而3.5mm的插头，是两组声音分开输出；
   （已完成）需要找找看，有没有一拖四的麦克风支持，两组分开输出的方式，而不是只能输出一组的方式；
   （已完成）最终结论 => 6.5转3.5的绿联一分二转换线没有问题，讲师端软件也没有问题，立体声转单声道没有丢失声道数据；是由于主板上的声卡驱动没有更新的问题；
   （已完成）最终结论 => 反过来，自动跟踪摄像头在单声道输入时会有声道丢失的问题，没有转换而是直接只使用了一个声道的原因；

10.（已完成）学生端 => 左侧拉流通道可以开启或关闭本地音频的回放功能，使用WASAPI的方式播放音频数据； 
   （已完成）学生端 => 左侧拉流通道可以预览视频画面，需要新增专门的播放窗口与SDL2.0接口对接，参考右侧的画面预览功能；
   （已完成）学生端 => webrtc的回音消除功能与网络延时和网络抖动有很大关系，发生网络延时和抖动时，回音消除效果差很多；
   （已完成）学生端 => 发现从rtsp的序列头里面解析出来的视频高度和宽度有问题，与解码之后的高度和宽度不一致，应该使用实际解码出来的高度和宽度，而不是用预设的高宽；
   （已完成）学生端 => 左侧窗口和右侧窗口的音视频回放做了改进，针对视频，始终以解码后的视频图像高宽来做为基线，而不是从序列头里解析的高宽（有可能解析有错误）；
   （已完成）学生端 => 需要将 window-view-render.h 与 window-view-player.h 进行合并操作，两个类99%的内容都是相同的；
   （已完成）学生端 => 左侧显示区的每个摄像头通道在预览时，可以屏蔽音频的回放；同时，修正了主菜单状态更新的问题，使用 aboutToShow() 这个信号槽事件；
   （已完成）学生端 => 新增 左侧或右侧播放窗口可以用键盘控制音量的放大或缩小，最大6倍，最小1倍；
   （不处理）学生端 => 发现多个SDL窗口进行显示|回放|开启|关闭过程中，会相互影响，在右侧窗口不断退出、开启过程中，尝试重建左侧播放对象，会引发各种未知崩溃问题；
   （已完成）学生端 => 发现多个WASAPI进行音频回放时，每个线程都必须使用CoInitializeEx()初始化，否则，会有音频资源被抢占的问题；
   （已完成）学生端 => 发现多个SDL窗口进行显示时，每个线程都必须使用CoInitializeEx()初始化，SDL_Init()初始化SDL，否则无法正常显示；
   （不处理）学生端 => 发现多次来回开启SDL，会引发SDL播放线程的卡死问题，SDL内部线程互斥发生互锁问题，需要考虑使用新的播放机制，不能采用目前的SDL，需要参考libobs，采用d3d或opengl的播放；
   （不处理）学生端 => 整个视频显示机制需要花时间进行重新调整，采用libobs的d3d或opengl的方式，不用担心来回切换造成的不稳定，SDL在处理方式上不太稳定；
   （已完成）学生端 => 戴浦的IPC通过RTSP获取的音频时间戳会有很多相同时间戳的数据块，在本地回放时，需要使用multimap，处理重复时间戳的AVPacket
   （已完成）讲师端 => win-rtp的UDPPlayThread.cpp当中，也用multimap，避免时间戳重复造成的潜在问题；
   （不处理）学生端 => 回声啸叫的问题只有在话筒的灵敏度很高的时候才会发生，普通话筒灵敏度不高，通常不会啸叫；
   （不处理）学生端 => 通常监控摄像头的本地回放很容易发生啸叫问题，灵敏度太高，需要尝试使用webrtc的ns功能进行抑制处理；
   （不处理）学生端 => 左侧显示区的每个摄像头通道在声音回放时，需要处理震荡回音啸叫的问题；
   （不处理）https://blog.csdn.net/qq_30948113/article/details/68928549?utm_source=blogxgwz1 => webrtc ns|vad
             https://blog.csdn.net/shichaog/article/details/52514816 => webrtc ns
   （已完成）libwebrtc-aec => 这个代码库当中新增了噪声抑制模块的代码，但实际并没有使用，还没有完全搞清楚ns的使用方法；

11.（已完成）学生端 => 在10月31日的演示当中发现：戴浦的UV20针对rtsp的延时处理非常差，只能用在HDMI的视频信号输出，不能用在网络信号的输出；
   （已完成）学生端 => 网络信号输出只能用海康的IPC设备，延时低大概在100毫秒左右；
   （已完成）学生端 => 拉取海康设备的rtsp进行本地音频回放时，有音箱的状态下很容易发生共振啸叫；本地预览时，默认处于静音状态；
   （已完成）学生端 => 针对大教室，需要用专门的一拖二或一拖四无线麦克风，还要用功放连接，需要用到连接器；
             转换头 => https://detail.tmall.com/item.htm?id=564114858640 => 6.5mm两公一母；
             孔对孔 => https://item.taobao.com/item.htm?id=553128199928 => 6.5mm孔对孔连接头；
             连接器 => https://item.taobao.com/item.htm?id=562626914864 => 连接IPC音频黑白输入连接线；
             连接头 => https://detail.tmall.com/item.htm?id=530486770623 => 6.5mm连接头；
             话筒线 => https://detail.tmall.com/item.htm?id=534480749238 => 话筒音频线；
             参考图 => 具体查看 E:\GitHub\HaoYiYun\Document\云教室\直播教室.vsd => 学生端IPC外接音频；
   （已完成）实测结果 => 麦克风一分三，输出给功放，效果不好，而且功放再输出给电脑音箱会很费劲，杂音很重；
   （已完成）实测结果 => 最终，还是让电脑回放麦克风声音，将无线麦克风的声音一分二，一路输出给讲师端电脑，一路输出给海康IPC即可；

12.（已完成）发现海康官网有专门的针对教育行业的摄像头方案，对应戴浦的产品，而且还比戴浦的相对便宜；
   （已完成）iDS-2DF5220S-DE4/W/JY => https://www.hikvision.com/cn/prgs_1149_i9644.html，POE+DVI+SDI+RJ45，3.5音频输入；20倍光学变焦，16倍数字变焦；
   （已完成）支持教育智能专用功能，实现对老师授课和学生回答问题的分析跟踪，用户手册里面有专门的配置详情页面设置；
   （已完成）这个型号的摄像头既可以用在讲师端(SDI或DVI转HDMI)又可以用在学生端(RJ45网口)；
   （已完成）这款型号应用场景特殊，淘宝上比较少，海康北京分公司电话：010-82961818，18969186087(张经理)
   （已完成）淘宝上的北京实体店的联系电话：15600252591，报价3500左右，含税的话另加12个点；需要预定，没有现货；
   （已完成）https://item.taobao.com/item.htm?id=42176667777，报价3270，带POE的报价4800，教育的报价5000，带票另加10个点；
   （已完成）学生端 => 专用 4倍光学摄像头型号 => DS-2DC2204-DE3/W => https://item.taobao.com/item.htm?id=569374065995
   （已完成）学生端 => 专用23倍光学摄像头型号 => DS-2DE4223IW-DE  => https://item.taobao.com/item.htm?id=545023878676
   （已完成）短壁装支架 => https://item.taobao.com/item.htm?id=553278291503
   （已完成）长壁装支架 => https://item.taobao.com/item.htm?id=536431689376
   （已完成）DS-2DE4220IW-DE => 200万像素，支持光学20倍变焦，POE，云台，支持音频输入，需要外接音频；
   （已完成）DS-2DE4420IW-DE => 400万像素，支持光学20倍变焦，POE，云台，支持音频输入，需要外接音频；
   （已完成）这类高变焦的IPC统称为E系列高清网络球形摄像机；从200万到500万都有，主要是分辨率得到提高；
   （已完成）https://item.taobao.com/item.htm?id=535998839527 => DS-2DC4223IW-D替4220IW-D 200万网络星光智能球机H.265，这款不带音频，仅-E型号才带音频；
   （已完成）https://item.taobao.com/item.htm?id=587918063470 => DS-2DC2204-DE3/W 半球摄像头吊装伸缩支架铝合金 => 伸缩尺寸0.6m - 1.2m
   （已完成）https://item.jd.com/28822729487.html => 汇博士C10-1080H
   （已完成）https://item.taobao.com/item.htm?id=574879398567 => 汇博士C10-1080H，吊装支架 => 锁中间孔位；
   （已完成）https://item.taobao.com/item.htm?id=567327119920 => 电脑蓝牙无线耳机耳挂式 => USB转蓝牙 => 电脑耳机孔插USB
   （已完成）https://item.jd.com/50564396876.html => 汇博士 教学镜头+悬臂装支架
   （已完成）https://item.jd.com/29125565924.html => 汇博士 1080高倍变焦

13.（已完成）讲师端 => 第二排待选窗口，点击右键，可以将任意窗口进行浮动操作，放置到第一排窗口的任意区域，范围不要超出第一排窗口的区域；
   （已完成）讲师端 => 右键新增“开启浮动数据源”“关闭浮动数据源”功能，从而实现讲师头像数据源的叠加绘制功能；
   （已完成）学生端 => 通道处于运行状态下，也可以对通道进行编辑修改操作，而不是必须在停止状态下才能修改；
   （已完成）学生端 => 由于重载了QT的QTranslator，所有的跟翻译相关的信息都可以通过data目录下的zh-CN.ini；
   （已完成）学生端 => 包括系统控件的右键菜单，都可以通过修改配置来处理，只是新增了&符号，而且添加的顺序还不是固定的；

14.（已完成）学生端 => 新增 组播转发功能，设定两种模式，组播探测模式、互联网接入模式，一旦发现有组播数据，自动切换到组播模式；
   （已完成）学生端 => 组播探测地址是写死在学生端，分为数据发送地址234.5.6.7，丢包重传地址235.6.7.8，教室房间编号就是组播端口的探测编号；
   （已完成）学生端 => 每次启动直接从服务器上获取终端类型，分为3种类型(0外网接收者，1组播接收者，2组播发送者)，不要进行自动探测；
   （不处理）学生端 => 互联网连接成功之后，也要开启一个线程不断进行组播探测，一旦有组播数据，立即中断互联网连接，直接用组播数据；
   （已完成）学生端 => 学生端组播模式的开启与关闭，可以由网站后台进行控制，目前不支持学生端自己进行配置；
   （已完成）学生端 => 组播发送者必须每隔1秒就要重复发送音视频序列头数据包，以便后来加入组播的终端能够正常播放音视频；
   （已完成）学生端 => 解决组播重传的方案，所有的组播接收终端会加入另一个组播组，专门发送丢包命令，组播发送者专门接收这个丢包命令，进行丢包重传；
   （已完成）学生端 => 学生端有三种角色，外网接收者|组播接收者|组播发送者，默认都是外网接收者，组播接收者|组播发送者都是由后台网站指定；
   （已完成）网站端 => educate|wk_gather新增字段role_type，学生端角色类型由后台网站指定，学生端自己不能修改；默认都是外网接收者；
   （已完成）学生端 => 组播数据发送地址 => 234.5.6.7:房间号，组播丢包重传地址 => 235.6.7.8:房间号
   （已完成）学生端 => 尽量使用目前已有的机制进行组播数据包的接收和处理过程，避免重复编码；
   （已完成）学生端 => 先完成组播发送者的数据转发工作，改造 UDPRecvThread.cpp
   （已完成）学生端 => 新增组播转发类 => CUDPMultiSendThread，新增组播接收类 => CUDPMultiRecvThread
   （已完成）学生端 => 组播发送者停止时，会发送停止命令包；组播接收者有4秒接收超时判断，一旦超时自动停止组播接收；
   （已完成）学生端 => 根据不同角色，需要在标题栏，讲师端画面显示栏，标明终端角色的名称；
   （已完成）学生端 => 新增 关于对话框，加入学生端的基本状态信息，可以显示版本名称，显示唯一编号等等；
   （已完成）学生端 => 新增 组播发送接口字段ip_send，用来记录组播发送接口地址，默认是0 => INADDR_ANY
   （已完成）学生端 => 在多网卡模式下，组播发送接口的容错性很强，设定的发送接口无效时，会自动切换到默认接口，直接当设定的接口有效但网络配置错误时，才会造成问题；
   （已完成）学生端 => 组播发送者角色需要配置组播发送接口，默认是INADDR_ANY，在多网卡的情况下，需要可以选择指定的发送接口；组播数据发送和丢包数据发送都要修改；
   （已完成）学生端 => 组播发送者，可以设定发送者组播的发送接口；组播接收者，可以设定丢包发送组播的发送接口；
   （已完成）学生端 => 新增 系统配置，可以修改组播发送接口，并保存到网站数据库ip_send字段当中；
   （已完成）学生端 => 多网卡的学生端，在服务器上由于网卡的启动顺序，会造成在网站服务器端形成多个记录，因此，在进行组播发送端配置时，需要特别注意，每个网卡记录都要配置成发送者模式；
   （已完成）学生端 => 新增 系统配置，显示网卡的MD5标识信息，跟关于对话框保持一致，方便比对；
   （已完成）学生端 => 新增 系统配置，显示学生端角色类型，外网接收者|组播接收者|组播发送者；
   （已完成）学生端 => 注意：同一个网络内，可能有多个个学生终端在进行网络组播，经过实测发现，没有出问题，只是网络中会有重复包出现，并不影响终端接收观看；
   （已完成）学生端 => 注意：目前，学生端可以自由配置终端角色身份，有可能会造成同一网络内部会有多个组播发送者，造成外网和内网的流量压力，后期需要通过后台网站纠正；
   （不处理）学生端 => 注意：后续还需要进一步优化，可以通过后台网站直接控制终端角色身份，让那些错误配置的终端，可以通过远程进行错误纠正；

15.（已完成）工控机的 AppData\Roaming\Microsoft\Common\Shared\dis.dll 文件会造成 资源管理器 时常CPU占用很高，它是FileMon.dll的别名，监视文件系统用的；
   （已完成）需要判断到底是系统自动的还是其它应用程序附加安装的，这个需要屏蔽掉，否则，莫名会造成系统CPU占用很高；
   （已完成）这是由于工控机厂家装的系统带有流氓软件，或者它所ghost的系统本身就带有流氓软件造成的，解决办法是重装系统系统，重新ghost备份全新系统；
   （已完成）OneKeyGhost这个软件就是雨林木风做的，OneKey_V8.2.3.exe做出的.gho文件比OneKey_V6.5.11.168_32bit.exe要大很多；
   （已完成）目前使用OneKey_V6.5.11.168_32bit.exe进行系统的备份、还原，还没发现有流氓软件的存在，备份和还原都能正常进行操作；

16.（已完成）跟中关村老李的讲师端软件测试非常不理想，软件的系统匹配度还有很长的路要走；
   （已完成）讲师端对Win10系统匹配有严重问题，对Win10的64位系统匹配问题严重；
   （不处理）针对Win7的奔腾电脑匹配容易死机，死机之后的崩溃日志的汇报问题；
   （已完成）在itellyou上下载最新x64的win10专业版1809更新版本，由于超过4.7G，无法刻录光盘，通过本地硬盘安装；
   （已完成）通过日志分析发现，头一天晚上的测试，有两个问题，一个是老李的系统资源占用太大，造成网络堵塞，发包失败；
   （已完成）第二个问题是coreaudio-encoder，这个AAC压缩和解码的库，需要Apple的公共库CoreAudioToolbox.dll的支持，加载失败才会用ffmpeg的AAC库；
   （已完成）由于老李的机器估计刚好有CoreAudioToolbox.dll，造成音频的解码和压缩都会使用coreaudio-encoder，造成解码和压缩都出现问题；
   （已完成）解决的办法是在工程中删除coreaudio-encoder，不打包coreaudio-encoder插件，重新打包Teacher，更新发行版本；
   （已完成）中关村老李提出的toC方案，不错，直接通过微信扫码收费，这样带来的利润会更大更广；

17.（已完成）有关udpcenter的更多基础细节，查看 2018.08.31 第10条记录：
   （已完成）udpserver => 需要对生产环境和调试环境的服务器做区分，生产环境与调试环境的服务器通过启动参数进行区分，默认不带参数的为生产环境；
   （已完成）udpserver => udpserver -d -r => -d 表示调试模式 => -r 表示生产模式，默认是release模式；
   （已完成）讲师端和学生端也可以通过命令行，进行运行模式的设定，同样的命令行参数 -d 或 -r ，默认是release模式；
   （已完成）udpcenter => 服务器的分配在中心服务器进行，相同模式的讲师端、学生端、服务器才能匹配，具体是由学生端或讲师端的登录过程匹配；
   （已完成）讲师端|学生端|udpserver => 需要增加命令解析功能 => -d 或 -r ，默认release模式，新增 -s 终止服务，完全退出进程；
   （已完成）linux下自带 getopt.h 与 getopt() 接口函数，在windows下需要自己编写；
   （已完成）udpserver => 需要向udpcenter汇报直播服务器的运行模式，并在网站的后台显示出来；
   （已完成）学生端|讲师端 => loginLiveRoom，会携带参数 debug_mode=0 或 debug_mode=1，告诉中心服务器，挂载的直播服务器类型；

18.（已完成）udpserver => tcpthread.cpp:317，发生了TCP线程退出事件，但是没有找到具体退出的原因，其它两个线程还是依然存在；
   （已完成）udpserver => tcpthread 默认退出，造成了udpserver假死状态，无法连接udpcenter，无法对外提供直播服务；
   （已完成）udpserver => tcpthread.cpp:317，发生 EINTR 错误之后，就发生了线程退出事件，如何造成的无法得知；
   （已完成）udpserver => tcpthread.cpp:309, epoll_wait(...max_event)必须大于0，否则会发生errno=22的错误；
   （已完成）udpserver => tcpthread.cpp，始终有2个活动套接字 => listen|tcpcenter，新增 doIncreaseClient|doDecreaseClient，便于跟踪终端个数的变化；

19.（已完成）udpserver => [tcpclient.cpp:542][trace] parse json data error
   （已完成）udpserver => json解析失败的问题是由于TCP数据的粘滞，即过个TCP数据命令包粘合在一起，造成json在字符串解析时无法找到结束符号\0
   （已完成）udpserver => 具体解决办法详见tcpclient.cpp:112，将包含命令数据包的请求，进行数据转移，始终保证有效的结束符号\0，这样json解析就不会错误；
   （已完成）udpserver => 新增只能运行一个进程检测功能，通过读取pid文件进行检测，多个进程运行会带来混乱；

20.（已完成）https://www.freepascal.org/docs-html/rtl/baseunix/index-8.html#SECTIONS => linux 常量说明文档
   （已完成）https://blog.csdn.net/wangcg123/article/details/51218408 => linux 常见错误号码
   （已完成）https://blog.csdn.net/qq562029186/article/details/70132719 => SIGINT,SIGQUIT,SIGTERM等终止进程信号的区别
   （已完成）nginx里面是通过外部命令触发内部调用shell指令来进行对进程的操作，SIGQUIT|SIGTERM|SIGHUP
   （已完成）srs简化了过程，直接通过外部shell指令进行命令发送，详见 srs-2.0.243\etc\srs 这个脚本；
             kill -s SIGTERM {pid}| kill -s SIGKILL {pid} => stop
             kill -s SIGHUP {pid} => reopen
   （已完成）需要在udpserver当中生成一个udpserver.pid的文件，记录运行时pid，进程退出是删除；
   （已完成）删除pid文件的操作不能放到CApp的析构函数当中，因为激发删除的退出命令也会调用CApp析构，会造成重复删除问题；
   （已完成）删除pid文件的操作放在了主线程退出的时候，详见 CApp::doWaitUdpSocket()
   （已完成）采用nginx的方法，调用kill函数进行指令发送，udpserver注册SIG相关函数进行指令接收和处理；sigaction()
   （已完成）doRegisterSignal()=>do_sig_catcher()=>onSignalQuit()=>关闭UDP阻塞套接字，设置线程退出标志；
   （已完成）CApp主线程退出后，删除TCP线程，删除UDP线程；必须先删除终端对象，再删除房间对象；否则会发生野指针访问问题；
   （已完成）CTCPRoom和CUDPRoom在正常流程当中，只有被创建没有被删除；除非整个线程都退出了才在析构函数当中被删除；
   （已完成）CApp当中，TCP与UDP线程间的数据通知或切换，都加上了IsSignalQuit()状态保护功能；
   （已完成）强制退出进程时，处理不好，会造成内存非法访问，提示glibc发现重复free内存的问题；

21.（已完成）udpserver 当中，三个线程的协同有问题，会造成死锁或崩溃，需要改进成信号模式，线程之间只是相互设置状态，而不是直接操作另一个线程的内容，让线程根据状态自己去执行操作；
   （已完成）app.cpp当中管理3个线程 => 主线程|UDP线程|TCP线程，udpserver.c进行主线程的初始化，最终主线程在app.cpp:doWaitUdpSocket()当中进行UDP阻塞等待网络数据到达；
   （已完成）app.cpp主线程主要使用阻塞式UDP套接字接收网络数据包，收到后立即投递给UDP线程udpthread.cpp，这样最大限度的利用网络又不耽误网络效率；
   （已完成）app.cpp将所有与udp线程有关的操作，都转移到udpthread.cpp当中进行统一处理；从而简化app.cpp，让主核心更轻便；
   （已完成）udpthread.cpp:onRecvEvent()接收到udp网络数据包之后，连带地址信息存入环形队列，HostAddr|HostPort|Size|Data
   （已完成）udpthread.cpp:Entry()当中使用信号量进行线程等待，每秒发送网络探测，每10秒检测网络超时，立即处理网络数据包，立即发送老师端补包，立即发送学生端丢包；
   （已完成）udpthread.cpp加入了两个互斥保护，一个是环形队列互斥保护，一个是房间互斥保护；
   （已完成）tcpthread.cpp:Entry()当中epoll超时设定为1秒钟，重新调整了max_event计数器，始终保持大于等于2(监听连接和中心连接)
   （已完成）tcpthread.cpp资源释放顺序很重要；房间创建后直到线程退出才删除，终端有超时检测机制；
   （已完成）tcpclient.cpp当中还需要处理命令数据包粘滞的情况，需要将每个命令的数据包单独拷贝使用，解决结尾符号的问题；
   （已完成）udpthread和tcpthread之间可以相互进行访问，主要是通过app.cpp作为中间转换过度，相互都用了互斥保护；
   （已完成）新增了外部命令激发退出机制，可以在任意时候发送-s命令退出进程，并能保证所有资源成功完全释放，没有内存泄漏等非法调用，为下一步新增热加载打下基础；
   （不处理）有关线程的进一步优化使用，可以参考srs针对线程的处理过程，它是参考nginx的线程使用，可以形成一套思路为优化线程调用做技术储备和参考；

22.（已完成）udpserver => 学生端网络延时大，自动断开重连，会造成服务器崩溃退出；
   （已完成）udpserver => 需要在linux的系统周期表中增加udpserver的判断，句柄无效自动重启；
   （已完成）udpserver => E:\GitHub\HaoYiYun\Document\远程\启迪\udpserver\udpserver-crash.log
   （已完成）需要新增linux下应用程序的崩溃捕捉问题研究，当应用程序崩溃时，知道崩溃的位置很重要；通过 ulimit -c unlimited 开启coredump文件；
   （不处理）学生端和讲师端都需要增加崩溃捕捉问题研究，但是，相对没有服务器udpserver的崩溃检测那么迫切，udpserver崩溃会影响很多终端；

23.（已完成）https://blog.csdn.net/beginning1126/article/details/8680757 => signal和sigaction详解
             https://blog.csdn.net/weixin_37098881/article/details/81412693 => 崩溃捕获和处理过程
             https://blog.csdn.net/chengangdzzd/article/details/51243878 => 崩溃捕获和处理过程
             https://blog.csdn.net/u012256258/article/details/54983326 => 崩溃捕获和处理过程
             http://www.cnblogs.com/xuewangkai/p/7920358.html => 有关core文件的查看和开关
   （已完成）https://bbs.csdn.net/topics/360016090 => 加上#include <execinfo.h> 编译时要加上-rdynamic选项，可以使用backtrace()捕获崩溃堆栈；
   （已完成）udpserver.c:do_err_crasher()，崩溃堆栈捕捉函数，发现崩溃信息不全面，没有core.xxx来的丰富，记录的信息很少，只能作为善后和删除pid使用；
   （已完成）虽然可以通过 ulimit -c unlimited 打开崩溃文件生成，但这种方式并不能进行崩溃的善后处理，因此，还要进行崩溃信号的注册执行，并做必要的善后处理；
             ulimit -c => 查看coredump允许的文件尺寸，如果是0，表示崩溃时不产生core文件；
             ulimit -c unlimited => 表示不限制coredump产生的文件的大小，崩溃时会自动产生core文件；
   （已完成）udpserver => 故意产生崩溃，产生core崩溃文件，并通过gdb进行调试 => gdb udpserver core.xxx

24.（已完成）BM-K-5（烽火拾音器）和谱悦电声的拾音器效果对比；谱悦电声只能开16个点的增专票，收12个点；
   （已完成）BM-K-5 双12价格168元，平时210元，谱悦电声的价格是300元加12个点的增专票税点；
   （已完成）https://item.taobao.com/item.htm?id=546013352193 => DS-2FP2020 海康拾音器，价格在85左右；
   （已完成）https://item.taobao.com/item.htm?id=523261695288 => 辉声乐22HA双咪头 => 128元，已购买，带票
   （已完成）https://item.taobao.com/item.htm?id=574813790551 => 烽火BM-K-5       => 173元，已购买，带票
   （已完成）青岛谱悦电声的拾音器还是走传统渠道，价格不透明，不能把地线与屏蔽层粘合在一起，会影响音频信号，甚至无信号；
   （已完成）辉声乐22HA双咪头拾音器，重量轻，易安装，价格便宜，带发票，3个点，默认灵敏度最低(降噪效果最好)，5米外都能拾音，海康摄像头音量为85%，效果很好！

2018.09.25 - 2018.10.13
===============================================================================================
1.（已完成）回音消除部分，彻底放弃Speex，全面转向webrtc的AEC，E:\obs-studio\libwebrtc-aec，做成了一个静态lib库；
  （已完成）webrtc-aec，有两种延时计算方式，一种是固定的系统延时，一种是动态的计算延迟，对于网络视频，肯定用计算延时；
  （已完成）WebRtcAec_enable_delay_agnostic()，控制计算延时的开关，必须在WebRtcAec_Create()之后调用；
  （已完成）使用计算延时配置之后，大概在采样15秒之后，开始回音消除，消除达到99%以上，现在要解决的是如何在各种状态下优化参数，快速对齐，快速消除；
  （已完成）enable_delay_agnostic模式下，WebRtcAec_Process接口设置声卡延时为0，及不使用声卡计算延时；（老师端停止推流再开启、学生端停止通道再开启）
            结果 => 同样的，大概15秒之后，自动对齐，开始回音消除，消除率达到99%；
  （已完成）enable_delay_agnostic模式下，IPC固定延时设置0，之前一直有一个固定延时150毫秒；（老师端停止推流再开启、学生端停止通道再开启）
            结果 => 同样的，大概15秒之后，自动对齐，开始回音消除，消除率达到99%；
  （已完成）enable_delay_agnostic模式下，CAudioThread::doDisplaySDL()，声卡缓存超过指定毫秒数(300毫秒或400毫秒)，丢弃音频数据，是否能再次自动对齐；（设定的码率超过服务器的承载能力就会发生丢弃音频）
  （已完成）将声卡丢弃的音频重置，投递给回音消除队列 => 当出现声卡丢弃音频数据时，只要不是持续很长时间，回音消除能够立即恢复，持续时间较长时，恢复时间也较长，但仍然能够恢复消除状态；
            注意：重置是指全部将数据设置为0，相当于静音，既跟上时间戳，又没有造成数据混乱，这是最好的结果，实验结果也是如此；
  （有问题）将声卡丢弃的音频原样，投递给回音消除队列 => 当出现声卡丢弃音频数据时，会再次进行波形对齐，会有15秒时间没有回音消除，之后又自动对齐，消除率达到99%；
            注意：这种丢弃的声卡音频，原样投递给回音消除队列的方案，肯定不能采用，因为，没有投递声卡，注定在麦克风当中没有数据，造成麦克风对应数据混乱并延长对齐时间，给消除队列静音数据是最好选择；
  （有问题）将声卡丢弃的音频数据，不投递回音消除队列 => 这种做法会导致麦克风数据与声卡数据严重错位，回音消除算法应该能预测波形状态，如果丢弃一段数据会造成永远无法对齐，从而造成后续永远无法消除回音；
            注意：这种做法会造成麦克风和扬声器的音频落差会越来越大，永远无法对齐，永远无法进行回音消除；
  （已完成）根据以上的测试情况，需要对webrtc的回音消除进行重新调整，完全采用最快速数据投递的方式，不进行任何的对齐操作，因为，外部对齐始终没有波形对齐准确；
  （已完成）在向webrtc做数据投递时，不要做任何等待，只要有扬声器数据就投递，只要有麦克风数据就进行消除；
            结果 => 这种方式，消除不理想，不能将扬声器数据和麦克风数据分开投递，必须同时投递，才能达到消除效果；
  （已完成）发现enable_delay_agnostic模式下，总是要消耗开头的15秒进行对齐工作，无论这个15秒之内有没有有效音频，超过15秒才开始进行音频消除工作；
            下一步要做的就是尽量缩短这个前期自适应延迟的计算等待时间长度，提高收敛速度；
            webrtc的回音消除，在双讲模式下，对近端的声音伤害特别大，几乎听不清楚，单讲模式下，效果还不错，损害不大；
  （已完成）aec_core.cpp:kDelayCorrectionStart => 修改为0，之前是1500个10ms，刚好15秒时间；
            修改完毕之后，仍然会有4秒左右的收敛时间，这个就需要进一步测试，看看是怎么引起的；
  （已完成）webrtc回音消除对象保持不变，讲师端的声音，从有声音变成无声音，再从无声音变成有声音，回音消除对象是否会重新预估延时，重新计算收敛时间？
            结果 => 延时评估只会进行一次，DA-AEC做了波形对齐记录，从有声到无声，再从无声到有声，波形对齐位置没有大的变化，就不会引发重新延时评估；
  （已放弃）在麦克风投递数据时，故意延时200毫秒投递，及前200毫秒不要做回声消除，而是直接投递给上层，也就是让扬声器数据做一个缓存，等待麦克风数据；
            结果 => 会造成延时评估无法收敛，无法进行回音消除工作，直接影响了算法计算，需要从其它地方入手解决这个算法收敛速度；
  （不处理）webrtc回音消除对象是否需要开启logging功能？如果logging有效，是否要做一个唯一的全局回音消除对象，专门用来回音消除，直到学生端退出，这样就不用由于来回创建回音消除对象造成的误差问题？
  （已完成）在目前DA-AEC模式下，让网络发生拥塞，丢弃音频的情况下，看看是否会影响回音消除，或者，是否会引发重新计算延时评估；
            结果 => 如果丢弃音频数据太多、太长，会引发延时评估重新计算，造成产生无法消除的片段，如果丢弃数据不多，不影响波形，消除不会受到影响；
  （已完成）通过参数调整之后，3秒~5秒就能延时评估收敛，不用考虑麦克风和扬声器的数据对齐问题，webrtc的DA-AEC会自动对齐，大概在3到5秒就能自动对齐；
            SignalBasedDelayCorrection() => 这个函数里面有收敛成功的信息确认；
  （已完成）讲师端 => 改造回音消除，使用webrtc的DA-AEC，代替Speex的回音消除，主要改造 E:\obs-studio\plugins\win-wasapi 模块
  （不处理）讲师端 => 回音消除，需要遍历所有数据源，判断 monitoring_type，只要有一个不是 OBS_MONITORING_TYPE_NONE，就认为有音频回放，麦克风需要等待扬声器数据；
  （不处理）讲师端 => 回音消除，还有一个隐患：同时多路音频监视输出时，需要对多路音频进行混音处理，然后才能进行回音消除，目前没有处理，造成扬声器和麦克风数据不一致，无法消除；
  （不处理）讲师端 => 目前对多路音频的混音算法不太了解，暂时放弃这个操作；目前都是只针对学生端一路音频进行回放交流，没有多路监视混音的问题；
  （已完成）讲师端 => 折中的方案 => wasapi-output.c::on_audio_playback()，只针对rtp_source的音频数据进行回音消除投递处理，其它音频不进行回音投递；
  （已完成）讲师端 => WASAPISource::doEchoCancel()，采用麦克风数据优先的方式；
  （已完成）学生端 => CWebrtcAEC::doEchoCancel()，采用麦克风和扬声器都要同时有数据的方式；
  （已完成）学生端 => 回音消除，讲师端第一次启动时，回音消除效果很好，讲师端停止推流，再开始推流，这时学生端回音消除效果大打折扣，反复开启、关闭之后也会无法再次消除；
  （已完成）学生端 => 尝试过换成麦克风优先的方式，仍然是这个问题：第二次开始推流之后，回音消除效果很差，没有第一次推流的效果好；
  （已完成）学生端 => 发现，通过切换摄像头通道能够再次触发回音消除重建并再次快速收敛，之前的停止推流并没有重建回音消除对象，这就是问题所在；
  （已完成）学生端 => 需要在停止推流之后，触发重建当前通道的回音消除对象，否则，再次推流的时候无法快速收敛，还是使用的上次推流的回音消除对象；
  （已完成）学生端 => 讲师端停止推流之后，互动教室的摄像头通道并没有发生变化，造成回音消除对象一直存在，造成下次推流时的回音消除出现无法收敛的问题；
  （已完成）学生端 => 讲师端停止推流之后，触发停止拉流通知，需要重建正在推流通道的回音消除对象，并且重新初始化扬声器缓存，这样才能解决下次回音消除重新对齐的问题；
  （已完成）学生端 => webrtc-aec.cpp的回音消除，采用的是麦克风和扬声器同时存在数据才进行回音消除的方式，同时，没有扬声器数据不消除；
  （不处理）讲师端 => win-wasapi.cpp的回音消除，还有一种方案，扬声器数据直接使用WASAPI接口获取；（这种方案太过复杂混乱，暂时放弃）
  （已完成）讲师端 => win-wasapi.cpp的回音消除，需要改进，跟学生端保持一致，都是采用麦克风和扬声器同时存在数据时才进行回音消除操作；
  （已完成）讲师端 => 声音数据源发生变化时的回音消除处理改进，只要静音一下，再开启，回音消除就会出现问题，无法对齐，无法消除；
  （已完成）讲师端 => 必须用rtp_source严格限制测试，讲师端本地播放视频，回放声音，被学生端IPC捕获，讲师端互动教室回放，再进入讲师端的麦克风，这样才能完成测试；
  （已完成）讲师端 => 必须要保证学生端和讲师端机器分开，讲师端处理代码是完整的、没有临时的代码，不要做为了测试的特殊处理，也就是正常使用时的只限制rtp_source资源的输入部分；
  （已完成）讲师端 => WASAPISource::doEchoCancel() => 由于麦克风与扬声器的声音延迟小，数据源采用循环处理，采用麦克风优先的消除方式，即：并不考虑扬声器数据是否足够，尽最大可能降低麦克风延时...
  （已完成）学生端 => CWebrtcAEC::doEchoCancel() => 由于麦克风与扬声器的声音延时大，采用麦克风与扬声器数据都必须达到一个处理单元之后才进行处理；

2.（已完成）多个学生端的通道切换有问题，目前只使用了一个kCmd_Camera_LiveStart命令，如果切换的通道在不同的学生端就会发生问题；
  （已完成）当发生通道切换时，讲师端，先停止本地win-rtp-source资源，再发起kCmd_Camera_LiveStop命令，通知变化前通道对应的学生端停止推流；
  （已完成）讲师端，收到学生端发出的kCmd_Camera_LiveStop反馈命令之后，再发起新的kCmd_Camera_LiveStart命令，转发给选中新通道的学生端，等待学生端推流；
  （已完成）讲师端，多个学生端进行通道切换时，讲师端和服务器端的处理不到位，讲师端本地已经停止，但是服务器没有处理停止命令，只是把命令转发给了学生端；
  （已完成）服务器，这种简单转发的操作，会造成讲师端-Looker没有删除时，学生端又会有新的推流，造成发包混乱；
  （已完成）服务器，需要处理kCmd_Camera_LiveStop命令，主动停止讲师端在服务器上的观看者对象，主动阻止服务器向讲师端继续推流，删除补包队列等等操作，不要等待讲师端来删除观看者；
  （已完成）服务器，收到讲师端发送的kCmd_Camera_LiveStop命令，不仅要删除讲师观看者对象，还要删除学生端推理者对象；同时，还要注意避免互斥死锁问题；
  （已完成）学生端，在进行通道切换时，TCP命令和UDP命令走的是同一个接口，在UDP命令后到达时，会造成混乱，需要将命令的处理函数分开来处理；
            CmdCameraLiveStart => 通道切换命令 => 先删除之前正在推流的通道，再开启当前新的通道，进行推流操作；
            CmdUdpLogout => ID_TAG_PUSHER => 学生端推流UDP停止命令 => 只是单纯的停止指定通道 => 之前的错误是调用了"通道切换命令"接口，造成混乱；

3.（已完成）学生端推流的第一个关键帧的时间戳需要调整，目前新的方式会造成延时，需要注意矫正第一个关键帧的时间戳；
  （已完成）还原成以前的处理方式 => 不记录上一个关键帧，这样不会造成花屏的情况，会有一个等待黑屏的问题，可以在讲师端在这个黑屏期放置一张图片的方式来解决；

4.（已完成）有关自动跟踪摄像头的选型问题，摄像头会自动跟踪安装在麦克风上的定位器进行跟踪；
  （已完成）经过咨询，麦克风与摄像头的定位是需要通过跟踪主机预先设定的，普通麦克风，普通摄像机，都接入跟踪主机，由跟踪主机里安装的软件预先设定固定位置，在麦克风每次开机时摄像头自动定位；
  （已完成）自动跟踪摄像头是通过软件连接摄像头，设定一定的跟踪区域进行判定和自动跟踪，设置完毕，就不需要电脑，由摄像头自己完成目标的跟踪；
  （已完成）E:\GitHub\HaoYiYun\Document\云教室\跟踪摄像头 => 使用文档，戴浦的自动跟踪摄像头，感觉是一个厂商出的OEM版本；
  （已完成）https://item.jd.com/28289502714.html => 双目跟踪摄像头
  （已完成）https://item.jd.com/4027835.html => 2手持+2领夹，无线话筒麦克风一拖四，左右两个6.35大二芯单声道输出（6.5是大三芯立体声输出）
  （已完成）https://item.jd.com/12883453727.html => 两个大二芯转3.5立体声连接线

2018.08.31 - 2018.09.25
===============================================================================================
4. （不处理）老师端 => 回音消除的进一步改进工作：
   （不处理）老师端 => 需要将回音消除过程放到obs-filters当中，专门写一个音频过滤器，而不是放到win-wasapi这个麦克风捕捉插件当中；
   （不处理）老师端 => obs-filters当中新增 echo_cancel_filter.c，将回音消除过程放到这里，仍然使用Speex进行回音消除；
   （已完成）老师端 => wasapi_input_capture 只能创建一个音频输入麦克风数据源，OBSBasicSourceSelect()构造函数判断，EnumSources() 
   （已完成）这部分对数据源的验证放到了EnumSources当中，可以遍历所有的数据源列表，main->ui->sources => 只能列举部分可见的数据源，不能列举其它不可见的数据源...
   （已完成）将回音消除过滤器附加到麦克风音频输入数据源当中；OBSBasic::ResetAudioDevice()和OBSBasicSourceSelect::on_buttonBox_accepted()都要添加；
   （不处理）老师端 => 发现win-wasapi和wasapi-output.c都需要向echo_cancel_filter.c中写入音频数据，但是过滤器数据源没有这样的接口去完成，难端复杂，暂时不处理；
   （不处理）老师端 => C:\Users\Jackey\Desktop\obs-code\回音消除-过滤器，具体屏蔽的代码存放位置；
   （已完成）老师端 => 优化wasapi-output.c和win-wasapi.cpp即可；

5. （已完成）Speex的回音消除效果一般，时好时坏，而且消除不彻底，后期需要用webrtc专门进行改进升级；
   （已完成）https://blog.csdn.net/wenzhilu/article/details/79079183 => 傅里叶变换
   （已完成）skia图片库函数，可以对各种图片编解码进行各种变换支持；
   （已完成）https://github.com/HaoYiTech/webrtc_aec_x86 => 最新版本（2018）webrtc的AEC单独编译移植，vs2015无法编译，出现很多语法问题，可能需要vs2017才能编译，泛型编程；
   （已完成）将vs2015升级到update3版本之后，再进行编译就可以通过了，现在需要对这个工程的demo做深入分析；由于在源码工程是在Linux下使用的，在windows下编译又做了一些调整；
   （已完成）E:\GitHaoYi\webrtc_aec_x86\ => Webrtc专门的回音消除实验代码放置的位置；
   （已完成）通过test.cpp代码发现：尾音延时是个动态的参数，而不是固定参数，就是投递到声卡之前计算声卡里的缓存，这个声卡里的缓存时间就是尾音长度，这个尾音长度是不断变化的；
   （已完成）在进行回音消除时，投递到声卡的每一段音频帧，都需要带上声卡里的缓存时间(尾音长度)，每一个Frame时间是固定的；麦克风的声音认为是源源不断的，投递到声卡的声音会有断续问题；
             因此，会以麦克风的声音做为基准声音，IPC麦克风的声音被采集编码压缩传输，RTSP解析，再解码，这个过程也会有一定的延时，可能会导致与声卡里的声音无法对齐，造成回音消除质量差；
   （已完成）先在学生端，使用声卡缓存时间来对Speex的回音消除算法进行修正，看看效果如何，同时，还需要计算出IPC麦克风的延时时间值；
   （已完成）发现Speex的回音消除算法，没有考虑声卡缓存的问题，尾音长度是固定不变的，不适合实际应用当中的情况，声卡会一直都有缓存存在，而且还是时长时短；
   （已完成）这就是Speex的回音消除如果网络发生抖动之后，就无法进行回音消除的原因，必须要处理声卡缓存这个变化参数；
   （已完成）现在使用webrtc的回音消除只要扬声器和麦克风数据对齐，效果非常好，而且webrtc还支持动态设定声卡缓存毫秒数，相当于每次消除都可以设定对齐位置；
   （已完成）这一点比Speex要好很多，Speex只能在初始化时一次性设定一个尾音长度，每次消除时只能使用之前设定的尾音长度，这样非常不精确，由于声卡缓存时长时短，需要动态调整回音消除时的对齐位置；
   （已完成）首先，要把CWebrtcAEC启动时，麦克风与扬声器数据对齐，只要CWebrtcAEC创建成功之后，扬声器就可以投递音频数据；
   （已完成）扬声器数据永远比麦克风数据先行到达，提前到达的时间值就是扬声器数据投递前计算获取到的声卡缓存毫秒数；
   （已完成）这个缓存时间每次投递都不一样，这是回音消除处理时的重点处理问题，如何处理好回音消除数据帧前后片段的衔接问题；
   （已完成）正式使用CWebrtcAEC进行回音消除时，左侧摄像头是会先启动，当没有扬声器数据时，会以麦克风数据为基准，解码、消除、压缩、分发；
   （已完成）每次在进行扬声器数据投递时，在环形队列中不能直接投递，而是需要对数据进行切分，组成特定的回音消除切片大小，给定声卡延时时间，不足切片部分留待下次填充使用；
   （已完成）https://blog.csdn.net/yuanchunsi/article/details/73290900 => 有关回音对齐的思考
   （已完成）https://blog.csdn.net/ffmpeg4976/article/details/52451433 => 有关webrtc的aec思考
   （已完成）https://xjsxjtu.github.io/2017-07-05/LearningWebRTC-apm_aecm/ => webrtc有关AEC/AEC3/AECM的解释
             https://m.2cto.com/kf/201609/546350.html => 对webrtc照代码进行解释
   （已完成）麦克风和扬声器的声音对齐还是要用最原始的时间戳的方式进行，每一块待消除的麦克风音频数据和扬声器数据都要打上时间戳信息；
   （已完成）麦克风环形队列 => 时间戳(毫秒)|音频数据(10毫秒) => 每个分片长度固定
   （已完成）扬声器环形队列 => 时间戳(毫秒)|声卡缓存(毫秒)|音频数据(10毫秒) => 每个分片长度固定
   （已完成）可以考虑在用webrtc进行回音消除之后，再利用webrtc的降噪功能对回音消除之后的数据进行降噪处理；

6. （已完成）将vs2015升级到update3之后，引发的新问题 => UDP数据包发生粘合效应，学生端UDP数据包粘合在一起，造成数据混乱，丢弃；
   （已完成）将vs2015升级到update3之后，内存占用增加，机器变慢，后续还是要完整重装vs2015的update3版本；通过降低讲师端画面输出来暂时解决 1120*700 => 960*600
   （已完成）老师端 => 发送数据是没有粘合的，直接发送给了服务器端；
   （已完成）服务器 => UDPServer接收来自老师端数据包是否发生了粘合，通过日志查看，也没有发现数据包异常的情况；
   （已完成）学生端 => 收到的服务器数据包有多余的大于1024字节的无规律的数据包，造成学生端解析过程中发生混乱；
             服务器怎么会发送大于812字节的冗余包，这个是关键问题，跟vs2015没有关系，数据包也没有被分裂，弄乱，而是，有多余的大于1024字节的无规律的冗余包发送到了学生端，学生端需要在数据包大小上
             需要预先做一个判断，丢弃超过812字节的冗余包；但是，服务器端为什么会发送冗余包？这个问题才是关键；
             将端口修改为15252之后，仍然发现会发送超过812字节的冗余数据包，这个冗余数据包怎么来的很奇怪；
             端口号的修改只需要修改防火墙和E:\GitHub\build\rpm_6.8\udpserver-1.0.1\rtp.h就可以了；
   （已完成）最终发现，可能是家庭带宽提供商的问题，网络突然中断重启之后，问题消失了；
   （已完成）为了保险起见，在讲师端、学生端、服务器，都在接收代码部分增加了数据报文超过最大长度的判定，以防万一；
   （不处理）进一步的优化，需要在所有的格式头前面新增一个4字节标记 => F0F0F0F0或在一定随机范围内的标记；
   （不处理）这种改动比较大，讲师端、学生端、服务器都要进行修改，很多代码都要做调整，暂时不处理；

7. （已完成）解决老师端 到 学生端的播放延时问题，目前，大概有1~2秒左右，学生端 到 老师端播放延时很低大概在500毫秒左右；
   （已完成）降低老师端音视频捕捉的缓存帧数，降低捕捉层的缓存，降低压缩层的缓存，降低学生端播放层的缓存；
   （已完成）https://blog.csdn.net/liuhongxiangm/article/details/79241125 => obs源码分析，整体工程；
   （已完成）集中精力搞清楚视频缓存到底在哪里的问题，obs底层肯定做了大量缓存，从采集、压缩入手；
   （不处理）video-io.c:video_thread() => 处理已经变换后的YUV数据，再次处理后放入压缩器；
   （不处理）video-io:obs_graphics_thread() => output_frame() => output_video_data() => video_output_lock_frame() => 产生YUV数据的过程；
   （已完成）obs-internal.h => #define NUM_TEXTURES 1 => 只用单面缓存，极大降低延时，达到500毫秒...
   （已完成）obs.c => vi->cache_size = 2; => 之前设置的是6个缓存，现在改为2个，似乎并没有有效降低延时，还需进一步测试...

8. （已完成）学生端 => SDL2.0播放音频(自己就有200毫秒的缓存)和视频，都有延时问题，后期需要使用obs的音频和视频播放体系来播放视频和音频；
   （已完成）学生端 => 音频使用WASAPI的方式进行播放；可以参考obs里面的插件和音频回放部分代码；
   （已完成）学生端 => 由于使用WASAPI播放音频，声卡层的200毫秒延时问题得到了解决，回音消除部分就可以不用处理这个延迟了 DEF_SPEEX_HORN_DELAY => 0
   （已完成）学生端 => 将回音消除尾音长度 DEF_SPEEX_FILTER_MS，由400毫秒调整为200毫秒，便于快速收敛，之前要10秒，现在只要5秒；老师端也做了调整，修改为200毫秒；
   （已完成）学生端 => 实测发现Speex设置200毫秒无法消除回音，还是要设置400毫秒才能消除大部分回音，还是有些回音残留，准备在新主机上测试webrtc的回音消除；
   （已完成）学生端 => 将之前的i3cpu升级到i5-3570，提升电脑性能，专门用来安装vs2017，用来编译测试webrtc的回音消除源代码；
             VisualStudio下载的版本，和下载地址，需要到讲师端主机上查看，上面已经下载过一个版本，未安装；
   （已完成）学生端 => speex-aec.h|speex-aec.cpp做了优化，使用libobs里面的音频格式转换封装函数，简化了音频格式转换是带来的代码复杂度；
   （已完成）学生端 => 从摄像头获取到的压缩AAC音频，回音消除之后，再发送给老师端的格式转换过程如下：
             Decoder    => AAC压缩格式，解压后，转换成PCM格式 => AV_SAMPLE_FMT_FLTP
             EchoCancel => 回音消除需要将 AV_SAMPLE_FMT_FLTP 转换成 AV_SAMPLE_FMT_S16
             Encoder    => AAC压缩器需要的格式 AV_SAMPLE_FMT_FLTP，需要将回音消除后的格式 AV_SAMPLE_FMT_S16 转换成 AV_SAMPLE_FMT_FLTP
   （已完成）学生端 => CAudioThread::doDisplaySDL()改进音频数据投递思路，之前是缓存超过500毫秒就清理声卡缓存，会造成声音卡顿，哒哒声；
             现在采用的方式是：声卡缓存超过200毫秒，不进行新数据投递，直接丢掉新数据，等待缓存小于200毫秒，再进行新数据投递；
             由于音视频各自严格按照原始时间戳进行播放控制，音视频的同步性完全不受影响，效果非常好，即使出现卡顿，也很快会自动同步；
   （不处理）学生端 => 视频部分还需要进一步的查看obs的具体播放代码；
   （已完成）学生端 => CAudioThread::doDisplaySDL() => 音量增加5个数量级，扩大音量；

9. （已完成）老师端 => 改进视频压缩采集的矩形框，目前是根据屏幕大小进行采集，经过一次缩放之后，最终输出给压缩器，压缩器是用的最终输出的尺寸；
   （已完成）老师端 => 现在需要改进的是：使用第一行实际的视频图像尺寸，进行输出尺寸的缩放，而不是用固定的整个屏幕；
   （已完成）老师端 => 这个判断标准就是在给压缩器输入之前的YUV数据进行JPG存盘测试，以前的代码已经完成，就看前面尺寸变换过程的改进；
   （不处理）学生端 => 无需对获取的图像进行裁剪，直接使用，双击全屏时，参考老师端的投影机制，进行全屏无黑边框显示机制；
   （已完成）学生端 => 由于老师端解决了0点位置的数据源定向采集压缩编码的问题，学生端可以不用进行图像裁剪显示了
   （已完成）老师端 => 视频数据采集过程 => obs_init_video => video_output_open => init_cache => video_thread 
   （已完成）老师端 => 视频图像采集过程 => obs_init_video => obs_graphics_thread => output_frame => render_video => output_video_data => video_output_lock_frame => video_output_unlock_frame
   （已完成）老师端 => 视频图像的渲染，是按source逐个渲染的 => render_video => render_main_texture => obs_view_render => obs_source_video_render => render_video(obs_source_t *source)
   （已完成）老师端 => 现在要搞清楚每个source数据源的绘制代码与绘制位置，这样才能只用source数据源进行数据压缩，而不是用整个屏幕的数据进行压缩；
             scene_video_render => 场景会话下面会有关联的一系列source数据源，目前是单场景多数据源的形式；
             https://blog.csdn.net/qq_35970739/article/details/80497437 => 视频渲染详细说明
   （已完成）老师端 => 之前的渲染流程(obs-video.c) => render_textures => output_textures => render_convert_texture => stage_output_texture(copy_surfaces)
   （已完成）这种方式是渲染全部数据源obs_view_render()，新的方式是增加 export_textures，只渲染0点位置的数据源，然后再输出到 output_textures => render_convert_texture => stage_output_texture(copy_surfaces)
   （已完成）这个过程对opengl|d3d的渲染流程有了一个大致的了解；需要给渲染环境准备参数和状态，才能执行具体的渲染过程；具体参见 obs-video.c::render_export_texture()

10.（已完成）老师端登录云教室时，需要检测教室里是否已经有老师登录，同一个云教室只能有一个老师在线；需要通过网站端的PHP接口到中转服务器获取老师登录状态？
   （已完成）需要新增一个服务器类型 => UDPCenter，专门管理UDPServer服务器，这样就能让 edu.ihaoyi.cn 形成规模效应，自动根据UDPServer的增加而自动扩容；
   （不处理）UDPServer需要用curl连接 edu.ihaoyi.cn 获取UDPCenter的地址和端口配置，然后，UDPServer会用TCP连接UDPCenter，同时，开启UDP服务，提供流媒体数据中转功能；
   （已完成）UDPServer会用单独的TCP同步套接字线程，定期向UDPCenter汇报，当前服务器运行状态信息：在线的房间号列表，每个房间的老师端、学生端情况；
   （已完成）UDPServer只需要实时的向UDPCenter汇报老师端、学生端的登录、退出状态就可以了，房间号会在登录、退出的过程中带上；
   （已完成）UDPServer会定期向UDPCenter发送在线状态，UDPCenter会检测UDPServer的超时状态，一旦超时就会删除链接，UDPServer需要自动检测，自动再次链接；
   （已完成）UDPServer尽量少使用curl，TCP用异步客户端模型，UDPCenter使用TCP的epoll模型；
   （已完成）这样的设计，可以增强edu.ihaoyi.cn的服务容量，只需要不断购买UDPServer就能不断的扩容；同时，还将一些特殊交互转移到了UDPCenter做了一层隔离，让UDPServer相对更稳定；
   （已完成）UDPCenter的TCP监听端口是26026；UDPServer的TCP监听端口是21002，UDP监听端口是5252，需要自己汇报给UDPCenter服务器；
   （已完成）UDPServer是通过 http://edu.ihaoyi.cn/wxapi.php/Gather/getUDPCenter，这个接口来获取数据库中配置的UDPCenter的地址和端口；
   （已完成）UDPCenter记录的房间信息是房间里讲师、学生TCP连接信息，当讲师和学生都为0时，会自动删除房间对象；
   （已完成）UDPServer记录的房间信息有UDP连接和TCP连接，当房间里的用户数为0时，并没有删除，而是一直保留；TCP房间里的用户发生变化时会汇报给UDPCenter服务器；
   （已完成）UDPCenter房间号是唯一的，在中心服务器当中房间号不能重复，学生端和讲师端登录的时间可以不一样，但房间号必须一样；

11.（已完成）重新梳理 老师端 => 服务器 的通讯过程，便于优化通讯机制，根据多用户、多场景、多课程，自动有效的分配服务器资源；
   （已完成）老师端 => 中心服务器 => https://www.myhaoyi.com => 没有在中心服务器注册，也不受中心服务器的管理；
   （已完成）老师端 => 节点服务器 => http://edu.ihaoyi.cn/wxapi.php/Gather/loginLiveRoom => 验证输入的登录房间号，从200000开头；
            （已完成）节点服务器需要通过PHP扩展连接UDPCenter服务器，通过RoomID找到当前房间号挂载的UDPServer的地址和端口；
            （已完成）之前的UDP地址和端口直接通过数据库获取，现在需要通过UDPCenter获取，UDPServer需要向UDPCenter汇报地址和端口；
            （已完成）mysql/data/educate/wk_system数据表，删除transmit_addr|transmit_port，修改udp_addr|udp_port => udpcenter_addr|udpcenter_port
   （已完成）老师端 => 节点服务器 => http://edu.ihaoyi.cn/wxapi.php/Gather/logoutLiveRoom => 向网站汇报，讲师端退出通知；

12.（不处理）重新梳理 学生端 => 服务器 的通讯过程，便于优化通讯机制，根据多用户、多场景、多课程，自动有效的分配服务器资源；

13.（已完成）udpcenter|udpserver => 发生讲师端、学生端无法连接udpserver的问题，必须重启udpserver才能正常连接，这个问题没有发现问题在哪里！
   （已完成）udpserver 没有按时（每隔30秒）向udpcenter发起在线命令通知，造成udpcenter超时删除，udpserver在收到删除命令之后，也没有发起重连操作；
   （已完成）udpserver 有可能已经发生线程互斥卡死在某个地方，造成无法向udpcenter发送在线命令；
   （已完成）udpserver => gdb attach pid => 可以关联已有的进程，并进行当前调试，还会自动定位到当前阻塞的位置；
   （已完成）info threads => 查看线程；thread 2 => 切换线程；bt => 线程堆栈
   （已完成）https://blog.csdn.net/zhangye3017/article/details/80382496
   （已完成）是由于学生端推流线程退出时发起了 PT_TAG_DELETE 命令，造成 udpserver 多层嵌套之后卡死，也是由于互斥引发的问题；
   （已完成）CApp::doWaitSocket() => CApp::doProcSocket() => CApp::doTagDelete() => CStudent::~CStudent() => CRoom::doDeleteStudent() => 死循环...
   （已完成）CRoom::doDeleteStudent() => while 循环没有进行算子累加，造成无限死循环；
   （已完成）CTCPRoom::doDeleteStudent() => while 循环没有进行算子累加，造成无限死循环；
   （已完成）这个问题会引发udpserver无法发送在线命令包，造成udpcenter超时删除udpserver，进一步引发讲师端、学生端无法连接服务器；
   （已完成）这种情况发生在 PT_TAG_DELETE 后到达，PT_TAG_CREATE 先到达，删除命令无法匹配学生推流对象造成的；
   （已完成）2018.12.06 => 还是这个地方CNetwork::~CNetwork() => GetApp()->doLogoutForUDP() 造成死锁；
             CApp:doWaitSocket() => CTCPThread::doLogoutForUDP() => 线程等待，都是存在线程互斥；
             CTCPThread::doHandleRead() => CApp::doDeleteForCameraLiveStop() => 线程等待，互斥等待，造成死锁；
   （已完成）解决方法1 => 基本保持原来的模型(直接强制通知)，只是打断互斥互锁的条件：
             tcpthread.cpp:311 => 将互斥保护只作用在套接字的删除操作，读写命令不进行互斥保护；
             network.cpp:26 => 新增被UDP删除标志，CApp::doDeleteForCameraLiveStop()检测标志；
             tcpthread.cpp:244 => 针对超时检测增加了互斥保护；
             tcpthread.cpp:67|tcpthread.cpp:85 => 屏蔽了房间的互斥保护；
             tcpthread.cpp:110 => 这里千万不能对房间进行互斥保护，加入就会造成死锁；因此，取消了所有的有关房间对象的互斥保护；
   （不处理）解决方法2 => 采用新的模型(异步通知)，不强制通知，让线程内部检测的方式完成通知：
             这种方式，改动太大，占时不处理；

14.（已完成）udpserver => kCmd_Teacher_Login 命令 => 当讲师端登录成功之后，异常断网，随后网络接入，会绕过udpcenter的检测，直接连接udpserver，会触发kCmd_UdpServer_AddTeacher，造成udpcenter里对应通道的讲师端计数器超过1；
   （已完成）udpserver => tcpthread.cpp:412 => 讲师端超时被删除时，没有通知udpcenter，减少对应通道上的讲师端引用计数，造成对应通道上讲师端引用计数一直大于1，其它讲师端无法登录这个房间进行直播上课；
   （已完成）udpserver => CTCPRoom::doDeleteTeacher() => 没有发送删除命令的原因是由于上一个讲师端断网后还没有被删除时，新的讲师端连接已经上线，覆盖了CTCPRoom当中的m_lpTCPTeacher对象，造成删除时不匹配，从而不触发UdpServer_DelTeacher删除命令
   （已完成）udpserver => 目前最简单的处理方法是，CTCPRoom::doCreateTeacher()，发现新的讲师端与之前的不匹配，并且m_lpTCPTeacher不为空，则不要向中心服务器发送UdpServer_AddTeacher上线命令，保持中心服务器上该通道的引用计数不变；
   （待完善）这个问题，暂时这么解决，后续需要给每个微信帐号分配和匹配房间号，只能是这个特定的唯一微信帐号才能登陆这个对应的房间号，后续跟进这个设定来重新调整中心服务器与数据服务器之间的管理关系；
   （已完成）这个问题，只要保持讲师端不关闭，然后断网，禁用网卡，再开启网卡，就能完整回显这个问题；

15.（已完成）讲师端 => 互动教室，进行通道切换的时候，会造成讲师端卡死现象 => 下面找到的问题，并不是罪魁祸首，而是将音频推送给obs播放时发生的；
   （没问题）通过日志发现：可能是在切换通道的时候，udpserver保留了上一个通道的补包记录，造成新通道仍然在补上一个通道的遗留数据包；
   （没问题）讲师端在本地删除Teacher-Looker之后，在udpserver的处理过程，看看是否有遗漏，特别是丢包队列的处理；（讲师观看端是通过命令补包，不通过服务器补包）
   （已完成）跟踪日志发现是win-rtp插件里的CAudioThread线程退出时卡死在那里，引发整个讲师端的卡死，使用libobs自带的pthread_mutex_t之后，似乎问题得到解决，还需要进一步的验证；
   （已完成）使用libobs自带的pthread_mutex_t，不要用OSMutex.h|OSMutex.cpp里的互斥体，因此，可见最好用libobs一体的函数库才能避免莫名问题；
   （已完成）尝试将Teacher端所有互斥体都改成pthread_mutex_t，而且不是全程互斥，只需要局部函数互斥就可以了，还能简化操作；
   （已完成）互斥的使用前提：先要搞清楚互斥保护的清晰对象，再使用互斥，而不是大面积的互斥保护，不仅不起作用，还会起反作用（卡死）；
   （已完成）讲师端 => 接收线程 => win-rtp => UDPRecvThread.h | UDPRecvThread.cpp => 无需使用资源互斥，全是在一个线程内部进行的操作；
   （已完成）学生端 => 接收线程 => UDPRecvThread.h | UDPRecvThread.cpp => 无需使用资源互斥，全是在一个线程内部进行的操作；
   （已完成）学生端、讲师端，所有用到OSMutex的地方都换成了libobs的互斥对象pthread_mutex_t，采用局部互斥的方式，提高互斥效率；

16.（已完成）讲师端 => 互动教室，进行通道切换的时候，会造成讲师端卡死；
   （已完成）当卡死后，利用ProcessExplore查看讲师端进程的线程列表，发现是 CAudioThread::doDisplayFrame()，一直没有退出；
   （已完成）由于播放时音视频要同步，造成视频数据也没有被消耗，在发送探测命令包时，学生端在发现视频缓存达到4秒之后，就会主动中断连接，停止向讲师端推流；
   （已完成）CAudioThread::doDisplayFrame()，这个函数里面，我们并没有使用互斥，估计是obs内部的互斥冲突造成的；
   （已完成）线程1 => CAudioThread::doDisplayFrame() => obs-source.c::obs_source_output_audio => pthread_mutex_lock(&source->filter_mutex) => obs-source.c::source_output_audio_data => obs-source.c::source_signal_audio_data => 
             wasapi-output.c::on_audio_playback => obs.c::obs_enum_sources => pthread_mutex_lock(&obs->data.sources_mutex) => 互斥在这里
             线程2 => obs-video.c::obs_graphics_thread() => obs-video.c::tick_sources() => pthread_mutex_lock(&obs->data.sources_mutex) => 互斥在这里
             线程3 => obs.c::obs_save_sources_filtered() => pthread_mutex_lock(&obs->data.sources_mutex) => obs.c::obs_save_source() => pthread_mutex_lock(&source->filter_mutex) => 互斥在这里
             分析  => 线程1|source->filter_mutex|obs->data.sources_mutex；线程3|obs->data.sources_mutex|source->filter_mutex => 发生了互锁；
             方案  => 本质上还是通道切换的处理过程不完善造成的，没有等待讲师端完全退出就向学生端发送了新通道的推送命令，造成新数据与老数据的重叠；
   （已完成）讲师端 => 通道切换时，先中断本地播放对象win-rtp.dll里面的处理过程，再进行处理；
   （已完成）讲师端 => 后来发现是音频退出与回音消除部分，始终有互斥互锁问题，wasapi-output.c::doPushEchoDataToMic()，使用音频资源列表，不要使用obs_enum_source()

17.（不处理）讲师端 => 在两路HDMI高清1080P的采样下，还是出现了一次软件卡死的情况，无法退出，不能操作，原因不明；
   （不处理）讲师端 => 重装Win7系统，拿到家里或直接远程控制，一直开启，测试讲师端的卡死状态，发生在什么时候；
   （已完成）讲师端 => 这个问题多半是由于互动教室音频回音消除时的互锁问题造成的。

18.（已完成）讲师端 => 增加录像功能，推流就录像，停止推流就停止录像；
   （已完成）OBSBasic.ui => 新增 recordButton，开始或停止录像按钮；
   （已完成）obs-app.cpp => 默认开启配置 => RecordWhenStreaming => true
   （已完成）OBSBasic::doCheckCanRecord() => 新增检测函数，当点击开始录像按钮时，必须至少要有一个视频资源存在，否则，没有图像，ffmpeg-mux会卡死，无法退出；
   （已完成）可以在设置栏进行存盘格式配置，默认是flv格式，都是通过ffmpeg-mux进行格式混合处理；
   （已完成）还可以配置 推流时录像 和 停止推流继续录像；
   （已完成）默认录像存放位置 C:/Users/xxx/Videos/时间命名的文件

19.（不处理）学生端 => 增加录像功能，有数据就录像，没数据，程序退出才停止录像，录像间隔1个小时，自动切片；
   （已完成）学生端 => 开启左侧通道自动重连机制，这样不用每次都要手动去点击通道的开启；之前没有打开，是因为rtsp直接通知会卡死，需要通过信号槽进行rtsp连接成功通知；
   （已完成）学生端 => 音频放大2.5倍播放；声卡缓存超过400毫秒就不要投递；

20.（未完成）编写田凯需要的PPT文档大纲内容填写；
   （未完成）双师软件特点、描述（核心卖点、高清、强交互、低延时）
   （未完成）应用场景（课堂、培训机构、K12远程教学、STEAM创客、文化课、艺术课）
   （未完成）软硬件配置标准（老师端和学生端主要硬件，各个硬件的工作连接示意图）
   （未完成）我们的服务器模式（核心是云服务）

2018.08.20 启迪未来双师配置
===============================================================================================
0. 最终选择的IPC型号是 => DS-2DC2204-DE3/W（200万像素）=> DS-2DC2402IW-DE3/W => https://item.taobao.com/item.htm?id=569374065995
   10.10日，去电咨询，海康的内置麦克风拾音器都是统一的没有好坏之分，都是光学4倍变焦；
   DS-2DE4220IW-DE => 200万像素，支持光学20倍变焦，POE，云台，支持音频输入，需要外接音频；
   DS-2DE4420IW-DE => 400万像素，支持光学20倍变焦，POE，云台，支持音频输入，需要外接音频；
   这类高变焦的IPC统称为E系列高清网络球形摄像机；从200万到500万都有，主要是分辨率得到提高；
   https://item.taobao.com/item.htm?id=535998839527 => DS-2DC4223IW-D替4220IW-D 200万网络星光智能球机H.265，这款不带音频，仅-E型号才带音频；
1. 将TP-Link设置成独立模式，电脑主机无线连接4G卡形成的无线网络上网，电脑主机有线连接TP-Link，访问无线连接的IPC，IPC的有线和无线IP地址一定要设置成相同（海康客服的经验，实测确实如此）；
   4G上网卡HUAWEI-9448，密码：93069113，IP地址：192.168.8.1；
   TP-Link 无线路由器，192.168.1.1，管理登录密码：admin123，无线网络(TPLINK-IPC)，无线登录密码：admin123
   DS-2CD3125D-IW2 室内200万像素IPC，有线：192.168.1.108，无线：192.168.1.108（TPLINK-IPC），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   DS-2CD3125D-IW2 室内200万像素IPC，有线：192.168.1.109，无线：192.168.1.109（TPLINK-IPC），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   DS-2CD3025D-IW2 室外200万像素IPC，有线：192.168.1.110，无线：192.168.1.110（TPLINK-IPC），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   这种方式，要解决，电脑多重网络上网的问题，不要通过网线连接本地链接上网，需要使用4G卡上网；
   https://jingyan.baidu.com/article/eae07827a109be1fec5485b0.html => 这篇文档解决了多重网络优先级的问题；
   注意：通过咨询海康客服，IPC的有线和无线IP地址必须配置成相同，网关都必须配置，DNS配置成114.114.114.114；
   注意：IPC通过无线连接后，发现PING值在1到30毫秒之间波动，连接有线始终小于1毫秒；
2. 有关多重网络合并后的网络出口顺序调整的说明文档，非常有用，学生端在用4G上网卡时，就会造成多重网络的访问问题；
   https://jingyan.baidu.com/article/eae07827a109be1fec5485b0.html => 通过修改路由表的方法来改变上网顺序；
   route delete 0.0.0.0 mask 0.0.0.0 192.168.1.1 if 17 => 删除有线的路由表记录
   route add 0.0.0.0 mask 0.0.0.0 192.168.1.1 if 17 metric 20 => 通过提升指定网卡的跃接点，走跃接点小的网络；
   这种方式，可以不用处理“多重网络”的问题，只需要改变指定网卡的跃接点，就可以了；
3. 将TP-Link设置成桥接模式，桥接到4G上网卡（HUAWEI-9448）上去，这种无论怎么连接，只要开启4G上网卡就能上网；但是，IPC的网络地址配置有问题；
   华为4G上网卡型号 => B311AS（一个网口，全网通），B315S（四个网口，三网通），每日6GB流量限制；
   4G上网卡HUAWEI-9448，密码：93069113，IP地址：192.168.8.1，4G上网卡和TP-Link的SSID都是（HUAWEI-9448），密码相同；
   TP-Link 无线路由器，192.168.8.105，管理登录密码：admin123，无线网络(HUAWEI-9448)，无线登录密码：93069113
   DS-2CD3125D-IW2 室内200万像素IPC，有线：192.168.8.108，无线：192.168.8.108（HUAWEI-9448），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   DS-2CD3125D-IW2 室内200万像素IPC，有线：192.168.8.109，无线：192.168.8.109（HUAWEI-9448），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   DS-2CD3025D-IW2 室外200万像素IPC，有线：192.168.8.110，无线：192.168.8.110（HUAWEI-9448），登录帐号：admin:admin123，无法调主码流，无法配置，开启Smart264之后可以配置；
   这种方式还有一个问题：4G卡形成的无线路由器，速度太慢，IPC通过它进行网络数据获取速度太慢；
4. 08.22，终于搞明白了家里网络一聊天就断网，一旦开启直播推拉过程，就会断网的根本原因：是由于屋里和屋外的无线桥接网络造成的，桥接无线网的信号弱；
   也可能是桥接无线路由器的质量差，一旦进行UDP的直播推拉过程，就会造成网络断线，网络抖动、跳跃非常严重；
   修改成屋里直接拉网线连接屋外的光猫，屋里的电脑用交换机模式，就能彻底改善这个频繁掉线，抖动、跳跃的问题；
   当然，也极有可能无线路由器的质量太差的缘故，MacBook上的虚拟机使用无线模式网络就非常慢，使用有线模式速度快；
5.（已完成）启迪未来远程控制帐号和密码；
  （已完成）http://www.doczj.com/doc/2bae7c6b482fb4daa48d4b38-2.html => MacMakeUp
  （已完成）1034357118:admin123 => i7主机，讲师端专用机器 => 可以通过设备管理器 网络适配器 => 属性 > 高级 > Network Address => 更改网络地址，来改变ID号
  （已完成）1259634076:admin123 => i5主机，学生端专用机器 => 可以通过设备管理器 网络适配器 => 属性 > 高级 > Network Address => 更改网络地址，来改变ID号
  （已完成）1025266224:admin123 => i7主机的TeamViewer的登录帐号和密码 => 可以通过设备管理器 网络适配器 => 属性 > 高级 > Network Address => 更改网络地址，来改变ID号
  （已完成）1030711791:admin123 => 赛扬主机TeamViewer的登录帐号和密码 => 可以通过设备管理器 网络适配器 => 属性 > 高级 > Network Address => 更改网络地址，来改变ID号
  （已完成）1259738467:admin123 => 岳朝柯家用主机的远程控制，机器有点慢，需要买些配件进行升级；
  （已完成）修改 TeamViewer ID 的方法 => https://blog.csdn.net/dongqing27/article/details/80646510
6.（已完成）摄像头选型更新，之前的EVI-D70P，拍摄大屏幕会出现曝光补偿无法调节的问题，商家推荐UV和UK系列，最终选择UV系列，能够进行曝光补偿，可以进行菜单配置；
            https://item.taobao.com/item.htm?id=545022446264 => UV系列，曝光补偿有6个等级；淘宝价比京东价便宜300多；
            https://item.taobao.com/item.htm?id=571178827900 => UK系列，曝光补偿还是有问题；
            https://item.taobao.com/item.htm?id=546751723076 => 两路HDMI高清采集卡；

7.（已完成）H.264压缩器，默认配制成veryfast|baseline|zerolatency
  （已完成）输出模式，默认设置成“高级”，比特率设置成：1024，（关键帧间隔，设置为2秒；=> 这个还是通过页面配置，强制配置在设置0时有问题）
  （不处理）右键新增“预览缩放”=> 缩放至窗口 => 缩放至背景；（经尝试之后，发现还是有问题，暂时放弃处理）
  （已完成）双击进行资源位置切换时，让资源尽量按照序号排列的方式显示，需要经过两次切换，避免资源位置来回变动，感觉混乱；
  （已完成）将http地址统一起来，避免多处引用造成的混乱；

2018.08.01 - 2018.08.30
===============================================================================================
1.（不处理）讲师端在win8系统下无法启动，报告缺少动态库，添加动态库之后，又报告pthread无法找到入口；vc_redist.x86.exe安装；
2.（不处理）老师端摄像机使用一段时间之后就会频繁的卡住，调整分辨率之后恢复一会儿有卡住，不知是机器原因还是摄像机原因；
3.（已完成）如何消除老师端、学生端音频的回声问题：
   A：（已完成）回音的本质，是麦克风与音箱靠的太近，音箱的声音进入麦克风造成的；老师端、学生端都要对麦克风输入的音频数据进行降噪、消除回声处理；
   B：（已完成）老师端 => 录音设备 => 麦克风 => 属性 => 增强 => 开启回音消除 和 开启降噪（比较新的声卡才有，老声卡没有）
   C：（已完成）老师端 => 录音设备 => 麦克风 => 属性 => 侦听 => 侦听此设备（测试时勾选，直播时千万别勾选，会造成回音）；
   D：（已完成）老师端 => 录音设备 => 麦克风 => 属性 => 级别 => 麦克风加强（0.0db，如果选择加强会造成强烈的回音问题）；
   E：（已完成）老师端 => 数据源 => 音频输入捕获 => 滤镜 => 噪声抑制（创建音频输入捕获时，自动添加）=> 抑制噪音；
      （已完成）老师端 => CreateFirstRunSources() => 讲师端第一次启动时，会自动创建输入输出的音频设备，输入(Basic.AuxDevice1|麦克风/Aux)，输出(Basic.DesktopDevice1|电脑输出声音)
      （已完成）老师端 => 默认需要将“电脑输出声音”设置为静音状态，避免发生啸叫混音引起的混乱问题；后来，直接屏蔽本地电脑输出声音，彻底避免互动时的声音啸叫；
      （已完成）讲师端如果第一次启动时刚好插入麦克风，就会自动成为输入设备，如果没有插入麦克风，就需要在程序启动后，手动加入“音频输入设备”这个音频资源；
      （已完成）因此，ResetAudioDevice()当中也要对自动加入的音频输入输出设备增加抑制噪音的过滤器；只对音频的输入设备进行过滤器的自动添加；
      （已完成）目前，只自动添加一个音频过滤器 => 噪音抑制，噪音阈值过滤器暂时不用自动添加，只添加噪音抑制就可以；
      （已完成）注意，过滤器也是资源当中的一种类型，噪声抑制都是过滤器资源，附加在输入资源当中的资源；
   F：（已完成）老师端 => 需要开启obs-filters，可以对音频和视频进行特效处理；主要是音频的抑制噪音和回声处理；
   G：（已完成）学生端 => IPC => 配置 => 音视频 => 音频 => 环境噪声过滤 => 开启
   H：（已完成）学生端 => IPC => 配置 => 音视频 => 音频 => 音频输入 => LineIn => 使用外置拾音器 => 降低环境噪声和回音问题
      （已完成）学生端为了安装简化，都用IPC内置的拾音设备，灵敏度已经足够；外置拾音器会带来安装困难，还需要额外的电源；也增加了额外的成本；
      （已完成）最关键的是，每个IPC都要增加一个外置拾音器，进一步增加了安装难度和成本，完全无法实施下去；
   I：（已完成）老师端 => 互动教室 => 高级音频属性 => 音频监测 => 仅显示器（静音输出）=> 只在老师端回放，不对外输出，避免在学生端产生回音；
   J：（已完成）老师端 => 互动教室 => 滤镜 => 噪声抑制（创建音频输入捕获时，自动添加）=> 抑制噪音；
   K：（已完成）以上在老师端加入的音频滤镜功能，只能解决噪音的问题，并不能解决回音问题，回音问题需要单独的硬件或软件来解决；
   L：（不处理）如果用硬件解决，需要在学生端加入一个音频硬件回声处理器，还需要加入一个音频分频器，老师端也需要处理回声问题，因为是小蜜蜂，相对回声不严重，
      （不处理）光一个4*4的音频回声处理器，硬件本身报价就要7000元，有的厂商报价3500元，再加上音频分频器，硬件本身的成本就很贵了，再加上实施成本也很高，而且肯定不稳定；
      （不处理）牵涉到各个硬件之间的磨合、搭配、干扰，根本无法具体实施，光供电的线路就费劲要死，肯定只可能用软件的方式去解决这个回声消除的问题；
   M：（已完成）如果用软件来解决，学生端和老师端什么设备都不用添加，可以大大节省成本；学生端的摄像头就用摄像头本身的Mic进行拾音，外置的拾音器效果差（价格高的或许好些），还要额外增加供电，增加了复杂度；
   N：（已完成）现在，最重要的问题是如何找到一个有效的回音消除开源的公共库，用在讲师端和学生端的音频采集、音频播放当中；
   P：（已完成）学生端 => 接收到的音频解码之后的声音数据与摄像头麦克风接收到的声音数据要进行比较，让麦克风的数据减去音频解码后的数据；
      （已完成）学生端 => IPC摄像头的音频是包含了扬声器的音频数据，我们的软件拉取的是压缩的AAC数据，需要先解码成PCM，与接收到的网络解码后的PCM比较处理之后，再用AAC压缩，发送给老师端回放，就能消除回音；
      （已完成）学生端 => 将网络收到的AAC音频解码成PCM，保存为文件；注意：要用二进制方式存盘；
      （已完成）学生端 => 将IPC网络收到AAC音频解码成PCM，保存为文件；注意：要用二进制方式存盘；
      （已完成）学生端 => 使用E:\GitHaoYi\WebRtcAudioAllTest例子时，发现只能消除采样率为8000的音频，而且，数据要挨的很近才能被消除；
      （已完成）学生端 => 需要将老师端解压后的数据(speaker)，与IPC解压后的数据(mic)进行同采样率转换成8K，声道降为1；
      （已完成）学生端 => https://www.cnblogs.com/wangguchangqing/p/5851490.html => 详细的音频格式转换，之前的方法有问题；
                https://blog.csdn.net/lanxiaziyi/article/details/52390448 => 关于音频重采样的进一步思考；
                swr_convert()这个函数可能返回更多数据，里面缓存了之前没有返回的样本，swr_get_delay()返回缓存的样本数；
                swr_convert()必须用它返回的样本数，重新计算转换后的缓存大小，因此，每个数据帧大小都不一定相同，不能用之前固定长度的思路；
      （已完成）学生端 => 老师端声音(speaker)，IPC声音(mic)，都转换成单声道，8K采样率之后，更重要的就是回声消除的比对时间点选择了；
                时间点越接近，消除效果越好，偏移越大消除效果越差 => https://blog.csdn.net/haima1998/article/details/72681807
                在外围整体设置为音频统一出口：16位，8k采样率，单声道，每个样本2个字节(short)，AAC压缩器每次采集固定样本数1024个，2048字节；
                16位， 8k，单声道，AAC(1024个样本)，单帧持续128毫秒；16位，  16k，单声道，AAC(1024个样本)，单帧持续64.0毫秒；
                16位，32k，单声道，AAC(1024个样本)，单帧持续 32毫秒；16位，44.1k，单声道，AAC(1024个样本)，单帧持续23.2毫秒；
      （已完成）学生端 => 延时对齐算法 => T1(声卡延时) + T2(录音延时)，声卡延时人为设定为200毫秒，录音延时忽略，加长尾音时间来对冲；
      （不处理）学生端 => 环形队列只存储连续的解码后的音频数据，麦克风音频要记录PTS起点(用在AAC压缩后的处理)，记录系统时间起点(用在与扬声器系统时间比对，需要合适的比对数据起点）
      （已完成）学生端 => 使用Speex回声消除接口对IPC的音频PCM进行回音消除；效果比WebRtc要好很多，就是速度有点慢；转换成8k单声道，速度快；
      （已完成）学生端 => 对IPC的已经被回音消除的音频进行AAC压缩，再通过udp打包转发音频数据；
      （已完成）需要找到一个PCM的波形查看对比显示的工具，能够直观的查看声波信息；Audacity，一个开源免费的音频处理器；
      （已完成）https://blog.csdn.net/lbaihao/article/details/52138804 => 声音处理文档
      （已完成）https://blog.csdn.net/leixiaohua1020/article/details/25430449 => PCM编码成AAC
      （已完成）最终，Speex回音消除的参数配置：统一转换成16k采样率，单声道，每次处理16毫秒数据，尾音长度400毫秒，声卡延时200毫秒，录音延时忽略；
                实测的情况：8k采样率，单声道，回声消除效果最好，大概从5秒开始回音消除；16k采样率时，大概从8秒开始回音消除；
   R：（已完成）https://blog.csdn.net/haima1998/article/details/72681807 => Speex => obs已经自带了这个库，用的噪音抑制功能；
   S：（已完成）https://blog.csdn.net/chinabinlang/article/details/8086014 => Speex => obs已经自带了这个库，用的噪音抑制功能；
   T：（已完成）http://www.cnblogs.com/mod109/p/5827918.html#top => 这篇介绍了有关webrtc的回声消除的使用过程；
                https://blog.csdn.net/lichen18848950451/article/details/73927814 => 针对上面文章的更新和补充
                https://blog.csdn.net/liulina603/article/details/19831495 => webrtc针对回声消除的算法简介
                https://www.cnblogs.com/gaoyaguo/p/7858025.html => 回音消除时间同步的探讨文章
                https://blog.csdn.net/u013249042/article/details/18757859 => 回音消除总结性文章，使用speexdsp
                https://blog.csdn.net/yjjat1989/article/details/18953751 => 有关libspeexdsp中对抖动缓存的用法，我们用不上，我们已经做了网络抖动的优化处理了；
   U：（不处理）E:\GitHaoYi\WebRtcAudioAllTest，这个目录下的工程包含 => WebRtc开源的回声消除处理实现，以及例子，很不错，这是2012年的版本，需要找到最新的
       webrtc\modules\audio_processing\aec => 回音消除算法的webrtc实现；
       webrtc\modules\audio_processing\agc => 声音增益放大的webrtc实现；
       webrtc\modules\audio_processing\ns  => 电流噪音消除的webrtc实现；
       WebRtcAudioAllTest\WebRtcAudioTest  => 如何使用的例子代码
       speaker.pcm(扬声器声音) micin.pcm(麦克风混合声音) out.pcm(消除扬声器之后的声音)
       ffplay.exe -ar 8000 -channels 1 -f s16le -i out.pcm => 8k单声道，16位
   V：（已完成）将webrtc单独的音频处理移植出来的工程，放在github上了。
       https://github.com/HaoYiTech/WebRtcAudioAllTest => （2014）上传到了github，可以更新维护；
       https://github.com/HaoYiTech/webrtc_aec_x86 => 最新版本（2018）webrtc的AEC单独编译移植，vs2015无法编译，出现很多语法问题，可能需要vs2017才能编译，泛型编程；
   W：（已完成）发现obs-studio里面的noise_suppress_filter，使用的是speexdsp.lib，就是那个开源的音频处理工具库，里面就有AEC的处理；
       E:\obs-deps\win32\include\speex\speex_echo.h => 回声消除接口；这样就可以在老师端添加filter来处理回声，学生单独用speexdsp.lib来处理回声；

4.（已完成）回声与混响的进一步研究：
   A：（已完成）https://blog.csdn.net/voice_dsw/article/details/52016846 => 技术文档，对回声消除的原理做了比较详细的说明；
                https://www.cnblogs.com/ldjrl2013/p/3687938.html => 对回声消除的延时计算做了比较纤细的说明；
                https://blog.csdn.net/audio_algorithm/article/details/78773212 => 回声消除的总结性文章，也用的是Speex，延时对齐模块对整个系统的性能影响非常大
   B：（已完成）回声，是指喇叭播放声音，再次进入麦克风；混响是指声波遇到障碍物反弹来回进入人耳的延时声音；
   C：（已完成）回声消除拾音器，可以配合有源音箱，配合网络摄像机，实现远程双向语音对讲。
   D：（已完成）回声消除音频模块，可以接入有源音箱和普通拾音器，实现远程双向语音对讲。
   E：（已完成）回声消除有源音箱，可接入普通拾音器，实现跟远程的对讲。
   F：（已完成）跟淘宝上的商家交流，烽火拾音器，bm-k-5带ANC环境噪音消除的210左右，不带电源和线材；
                还有更高级的hd_32b数字拾音器，带电源和拾音器700左右，电源上可以输出mic，应该可以接电脑声卡，这样就可以在老师端使用，就不用购买领夹麦克风了；
                具体要看实验的结果而定，商家说可以免费试用，不满意可以退货，hd_32b是目前比较高级的数字拾音器了，配的电源除了供电还能提供4种输出音频信号；
                目前在淘宝上能找到hd-32k，大概在1000多一个；
   G：（已完成）http://www.peakfire.cn，直接致电烽火科技厂商，咨询：
       1、老师说话通过领夹麦克风捕获后，经网络传递给教室里的学生端通过音箱播放出来；
       2、教室里的拾音器，会收到音箱播放出来的老师声音，通过IPC采集之后，借助学生端软件经网络到达老师端，从老师端的音箱当中播放出来；
       3、这样就会造成，老师说完话之后，老师端的音箱会听到老师刚才自己的讲话声音，发生一次回声播放，会感到不舒服；
       4、如果老师端的音箱声音，再被老师的领夹麦克风采集，经网络到达学生端，再被播放出来，就会形成反复回声，不停循环下去；
       5、因此，要设法阻断音箱的声音进入拾音器，或者拾音器能够屏蔽掉音箱里的声音；
       6、如果，拾音器能够屏蔽音箱里的声音，再加上拾音器能够输出3.5mm的mic信号，就能用在电脑的声卡上，就能免去使用领夹麦克风的麻烦；
   H：（已完成）http://www.topyeah.cn/，直接致电青岛谱悦电声科技，基本把回声处理这个问题搞清楚了：
       1、需要一个专门的声音处理设备，电脑声卡的声音输出和拾音器采集声音都接入这个声音处理设备，进行声音的判断和消除处理；
       2、然后，这个声音处理设备，会输出老师声音给音箱，输出拾音器声音给网络摄像机的外置音频接入口；
       3、声音处理设备，支持两路拾音器输入，如果要支持多路采集音频输出估计要用到音频分频器，相同的声音输入给不同的摄像头；
       4、目前，他的报价是3500元左右，包括声音处理设备和两个拾音器，不包括音箱和线材；
       5、另外，全向麦克风本身就是做这个处理的，只不过，距离有限，几个人围坐在一起，教室里范围大的情况不太适合，效果达不到；
       6、还有，老师端也可以用全向麦克风，但没有领夹麦克风那种移动性和效果好，因此，老师端用领夹麦克风效果更好；
   I：（已完成）http://www.systemzone.cn/product/?1.html，这家更专业一些：
       1、很专业的回声消除设备，4进4出，8进8出，12进8出，各种型号都有；两天后，4*4的报价是7000元，实际采购时可优惠；
       2、我们需要的是3进2出，1路声卡输入，2个拾音器输入；1路音箱输出，1路音频输出（接IPC）；
       3、我们现在遇到的问题是：1路音频输出需要分出多路音频，供给不同的IPC使用；
       4、http://www.xunwei.tm/splitter/ad0116.html，这是一个1进16出的音频分配放大器；报价 => 1进16出1800元；1进8出1100元，接口总类比较多；
       5、http://www.xunwei.tm/，成都迅维，专门做音视频矩阵、解码器；
       6、广州震憾力电子科技有限公司，13128287588，陈先生，报价 => 1进10出，380元；接口上好像有点问题，只有卡农口，需要购买时确认；
   J：（已完成）Speex开源系统，能够处理回音消除功能；但作者实测效果不好；
   K：（已完成）E:\GitHub\HaoYiYun\Document\云教室\回音消除SDK，找了一些SDK，但是很难用上；
   L：（已完成）目前，最简单的还是用硬件模式，用回声处理设备来解决这个问题；
   M：（已完成）已经找到webrtc单独分离出来的AEC回音消除代码库 => E:\GitHaoYi\WebRtcAudioAllTest
5.（已完成）老师端与学生端的交互问题，主要是针对互动教室的操作：
   A：（已完成）老师端 => 互动教室 => 尽量不要切换到输出画面，而是要全屏投影到第二个显示屏幕当中，这样老师就能监视学生端的情况；
   B：（已完成）老师端 => 互动教室 => 高级音频属性 => 音频监测 => 仅显示器（静音输出）=> 只在老师端回放，不对外输出，避免在学生端产生回音；
   C：（已完成）老师端 => 互动教室 => 滤镜 => 噪声抑制（创建音频输入捕获时，自动添加）=> 抑制噪音；
6. （已完成）老师端也要做回音消除处理，因为在学生端很明显的听得到自己发出的声音，说明在老师端麦克风的声音进入了话筒，又回到了学生端；
   （已完成）老师端 => 所有进入扬声器之前的音频数据（包括麦克风数据），要交给麦克风的音频进行回声处理之后，麦克风音频数据才能进行下一步的投递工作；
   （已完成）老师端 => 找到麦克风音频数据，进行存盘保存；注意：要用二进制方式存盘；
   （已完成）老师端 => 找到所有投递给声卡的音频数据，进行存盘保存；注意：要用二进制方式存盘；
   （已完成）老师端 => obs.c::obs_reset_audio()，这里对音频输出格式进行了统一设定AUDIO_FORMAT_FLOAT_PLANAR，采样率，声道都是配置界面设定；
   （已完成）老师端 => obs-source.c::reset_resampler()，将所有的音频资源都要统一转换成obs设定的AUDIO_FORMAT_FLOAT_PLANAR，采样率，声道；
   （已完成）老师端 => wasapi-output.c::audio_monitor_init()，将所有需要用声卡监视的音频资源统一从AUDIO_FORMAT_FLOAT_PLANAR转换成AUDIO_FORMAT_FLOAT
   （已完成）老师端 => audio-resampler-ffmpeg.c::audio_resampler_create()创建音频转换器；音频资源->obs标准设定，obs标准设定->监视器标准设定；
   （已完成）老师端 => wasapi-output.c::on_audio_playback()，音频数据格式是AUDIO_FORMAT_FLOAT（float），这个需要查看设置位置，都是默认固定的格式；
   （已完成）老师端 => wasapi-output.c::on_audio_playback():205行，将投递到声卡的数据进行存盘操作，32位float格式；
   （已完成）老师端 => WASAPI is always float，WASAPI的输入(麦克风)，输出(扬声器)，数据格式都是统一的32位float格式；
   （已完成）老师端 => Speex-AEC只支持16位音频格式的消除，单声道，8000或16000采样率效果最好；需要将扬声器和麦克风音频数据直接转换成8k或16k采样率，16位有符号，单声道；
   （已完成）老师端 => 扬声器数据是一个拷贝，投递之后再转换，音箱扬声器的播放；麦克风音频数据会影响麦克风的采集处理，需要在obs音频处理转换前进行回音消除，回音消除之后再进行一些列的音频变换；
   （不处理）老师端 => 麦克风回音消除时，需要注意排除麦克风自己的回放数据，就是在扬声器音频数据投递之前，要排除掉麦克风的数据，不要投递给麦克风线程进行回音消除；
   （已完成）老师端 => 有三种音频样本格式 => 麦克风录音设备样本格式、扬声器播放设备样本格式、obs软件配置输出样本格式；
   （已完成）老师端 => WASAPISource::AudioEchoCancelFilter()，在麦克风没有插入电脑时，投递扬声器数据会造成老师端崩溃，需要判定麦克风捕捉设备是否启动成功，才能进行扬声器数据填充；
7. （已完成）服务器端(udpserver)增加日志回滚分片功能，避免日志文件一直增加的问题，当日志大于40M字节时，新建日志文件；
8. （已完成）编写汕头需要的反馈文档内容；
   （已完成）请列明讲师端需要的硬件配置明细，硬件搭配示意图；
   （已完成）请列明学校学生端需要的硬件配置明细，硬件搭配示意图；
   （已完成）请给出一个建议的讲师端和学生端的配置；
   （已完成）讲师端、学生端软件的操作手册；
   （已完成）多个学校参与课程一起学习时，是否可以达到学校与学校学生之间的互动
   （已完成）有关排课的问题，留在后期添加新功能；
   （已完成）目前支持多房间授课，多课程管理，入口需要后期添加新功能；
   （已完成）E:\GitHub\HaoYiYun\Document\云教室\使用手册\《使用手册 - 讲师端.doc》和《使用手册 - 学生端.doc》

2018.07.06 - 2018.07.31 开始推流端、观看端分离工作
===============================================================================================
1.（已完成）将观看端更新到Teacher端，替换ffmpeg的文件播放部分，推流端一直推流，观看端临时接入；
2.（已完成）推流端被动按需推流，当观看端触发时才推流，而不是一开始就推流；
3.（未完成）不要用本地录像，用服务器端录像的方案，只录制老师端推流数据，就是全局数据，这样，课程一结束，马上就能看到录像，还不影响推流端网络；
4.（已完成）obs的推流过程分析如下：
   A：video_output_cur_frame() => 未压缩的视频数据帧；
   B：obs-encoder.c:receive_video() => 接收未压缩数据帧，进行压缩；
   C：send_first_video_packet | new_packet | interleave_packets | send_interleaved | rtmp_stream_data | add_video_packet | add_packet | circlebuf(stream->packets => struct encoder_packet) => 投递压缩后的数据包，存放到环形队列当中；
   D：send_thread | send_packet | 
   E：obs-outputs.dll => rtmp_output | flv_output | null_output
5.（已完成）媒体源obs_data内存泄漏分析 => 只要打开配置页面，点击确定就会发生obs_data没有删除的泄漏，通过bmem.c分析查找到原因；
   A：终于找到原因 => 在线通道检测时，读取资源配置结构，obs_source_get_settings()，里面自动进行引用计数增加；
   B：OBSApp::doLoginSuccess()，屏蔽掉在线时钟检测，这是rtmp模式的方式，新模式可能会有变化，等插件打通之后再细化；
   C：经过这么一通折腾，获得后续改进方案，还找到了查找内存泄露的终极办法bmem.c里面的方法，一旦有内存问题，打开 DEBUG_LEAK 宏；
6.（已完成）profile_start | profile_end 的作用分析：
   A：主要作用是记录每个函数的启动顺序，持续时间，逻辑关系；
   B：为了简化去掉了profile的存盘操作，只保留日志信息，逻辑更清晰；
   C：obs-studio\logs => 记录了每一次软件运行时的完整日志信息；
7.（已完成）有关整个Teacher端拉流、推流的思考：
   A：拉流 => 需要用C++实现一个resource插件 => 根据obs的插件规范 => rtp-recv.dll
   B：推流 => 需要用C++实现一个output插件 => 根据obs的插件规范 => rtp-send.dll
   C：通过观看obs-outputs.dll|rtmp-stream.c里面的线程，可以通过信号量的方式来改进收发包机制，而不是用一个固定的时间去等待，这样就能降低sleep误差；
   D：这种机制会造成收包和发包线程分离，调度复杂度加大，需要完全重新改变处理流程，得不偿失，放弃这种方式；
   E：尝试将obs-ffmpeg-source恢复成文件和网络模式，不要用自定义的模式，自定义过程将全部用新的C++插件去实现；
8.（已完成）拉流、推流的C++插件整合到一个插件当中 => win-rtp.dll => win-rtp-source | win-rtp-output
   A：（已完成）进行 win-rtp.dll 工程的搭建工作；
   B：（已完成）开始 win-rtp-source 的搭建工作；
   C：（已完成）拥塞判断，需要在有拉流用户接入之后进行，用户没有接入之前，只是简单的丢包，而不进行拥塞累加判定；
   E：（已完成）开始尝试解码抽取的数据帧，并尝试投递到obs的展示层，关键是时间戳的计算；
   F：（已完成）因为是交给obs上层去完成音视频的同步，只要解码之后，填充obs数据帧，相对比自己用SDL处理要简单很多；
   G：（已完成）需要进一步优化播放过程，适配obs的需要，与单独SDL处理不同，简化了很多操作；
   H：（已完成）由于音视频的处理大部分都是相同的，但是考虑到没必要再次重构已经验证的思路，做进一步优化就可以了；
9.（已完成）开始 win-rtp-output 的搭建工作；
   A：（已完成）Teacher-Pusher => 老师端推流开始搭建 => CUDPSendThread => 具体实现
   C：（已完成）obs-ffmpeg-audio-encoders.c:enc_properties()设置音频的比特率最小值和最大值；最小值调整为32kbps；新增16khz|32khz两个采样率；
   D：（已完成）由于老师推流端会被多个学生端观看，在缓存清理时，不能采用以前的靠探测反馈，只能靠定期清理的方案；
   E：（已完成）老师推流 => 学生观看的特殊性，需要调整数据包处理思路，服务器需要向老师端探测，确认网络质量来决定补包时刻点；
   F：（已完成）服务器端暂时不必向学生端探测，学生端只是向服务器端探测，用来确定补包时刻点；
   G：（已完成）需要先处理老师端推流到服务器的处理过程，完成数据缓存、补包、丢包的处理过程；
   H：（已完成）老师推流端的拥塞丢包处理过程，不是靠服务器的探测指令，目前采用缓存时间量的方式来丢包；
   I：（已完成）学生推流端的拥塞处理是靠丢视频数据帧来解决的，判断拥塞的缓存数据量来判断的；
   J：（已完成）学生推流 => 老师观看的过程是P2P过程，服务器只是做为中转服务器，没有缓存数据包；
   K：（已完成）老师推流 => 学生观看的过程是一对多过程，服务器不仅要中转，还要缓存数据包，进行多点分发过程；
   L：（已完成）服务器端补包，如果要补的包号，比最小包号还要小，直接丢弃，已经过期了；
   M：（已完成）Linux下面的 %lu 可能会是64位的，因此，需要用 %u 代替，否则，可能会出现信息打印错误；
   N：（已完成）服务器端，使用信号量解决补包延时问题，利用信号量的等待超时功能；
10.（已完成）Student-Looker => 学生端观看开始搭建 => CUDPRecvThread => 具体实现
   A：（已完成）然后，再完成学生观看端与服务器端的数据交互过程；
   B：（已完成）学生观看端，一开始就要被创建，每隔500毫秒发送创建命令包，请求老师推流端的数据内容；
   C：（已完成）老师推流 => 学生观看的过程是不需要学生发送准备就绪命令的，因为不需要进行P2P穿透操作，都是通过服务器中转，太多用户时推流端P2P模式根本无法应付；
   D：（已完成）学生观看端，目前只有一个服务器的发包路线，后期可以改进利用多个观看端进行P2P补包，但是效率不一定高，还是通过服务器靠谱；
   E：（已完成）学生观看端根本就不需要处理拥塞问题，每次解析完数据帧之后，就从环形队列当中删除了；
   F：（已完成）找到一个推流端补包的潜在问题 => 补包发送后没有设置m_bNeedSleep=false标志，可能会导致补包延时；
   G：（已完成）学生观看端需要在探测命令中收到服务器反馈的服务器目前最小的有效数据包号，这个包号之前的数据都无效了，需要清理观看端的补包队列，避免一直等待，造成延时（服务器会缓存3秒数据）
   H：（已完成）解决了学生观看端在服务器的丢包补包机制，解决了老师推流端在服务器的丢包补包机制，都使用信号量的方式解决；
   I：（已完成）老师推流端在服务器端发生的丢包，老师推流端补包后，服务器会原样转发给所有的学生观看端，必须转发，服务器丢包必然造成观看端丢包；
   J：（已完成）学生观看端发送的补包命令到达服务器端后，服务器会挨个查看丢包序号，如果这个丢包号正在服务器上要补的包号，不要加入补包队列当中；
   K：（已完成）服务器端在发送学生端的丢包时，也进行了丢包类型的判断，如果本身就是 PT_TAG_LOSE ，也不能补包，上一条就是避免出现 PT_TAG_LOSE的丢包；
   L：（已完成）观看端、推流端，创建命令发包周期都使用100毫秒（改大了对延时有影响？），只有，学生观看端不断尝试连接的周期改为500毫秒；
   M：（已完成）学生观看端，会发生严重丢包，造成无法持续观看的问题；是由于服务器中断造成的？
   N：（已完成）老师推流端，音视频缓存量，由原来的缓存3秒增加到缓存5秒，服务器端缓存的老师推流端数据量；
   O：（已完成）老师推流端，不要缓存已发送数据包，由服务器探测来进行缓冲区的删除操作，老师推流端的缓存不用来观看端补包，只用来服务器端补包；
   P：（已完成）学生推流端 => 老师观看端 => 延时0.4秒到0.5秒，老师推流端 => 学生观看端 => 延时0.4秒到0.5秒，学生推流端往返延时在1秒左右；网络状况良好情况下；
11.（已完成）开始用vs2015搭建全新的学生端界面，使用QT，完成登录，界面控制，云台控制界面等等；
   A：（已完成）完成了登录界面的搭建工作，能够登录验证房间号码的有效性；
   B：（已完成）学生端配置目录统一修改为obs-student，老师端配置目录统一修改为obs-teacher，这样便于区分和查找；
   C：（已完成）开始进行主界面的绘制工作，分左右两侧，左侧为本地摄像头列表，右侧为老师端拉流图像；
   D：（已完成）https://blog.csdn.net/LG1259156776/article/details/52469244 => 有关QSplitter的一些实用技巧；
   E：（已完成）窗口系统不要使用OBSDisplay的显示方式，它是用直接的D3D和OpenGL的方式；为了简化，第一期先用SDL2.0简化实现；
   F：（已完成）https://www.cnblogs.com/wiessharling/p/3750461.html => 有关子窗口全屏的文章
   G：（已完成）绘制老师窗口的标题栏和显示边框，参考以前的采集端窗口绘制；https://blog.csdn.net/liang19890820/article/details/51227894
   H：（已放弃）解决QString显示中文乱码问题 => #pragma execution_character_set("utf-8")，这种方式问题多；还是用QStringLiteral()思路更清晰；
   I：（已完成）绘制学生端通道窗口，通道标题，思路与老师窗口一致，背景色、字体、高度，都一致；
   J：（已完成）有关QString中文的相互转换：
       QStringLiteral("讲师端画面") => 静态中文字符串转换成本地格式，不一定是UTF8
       QString::fromLocal8Bit("讲师端画面") => 静态中文字符串转换成本地格式，不一定是UTF8
       QString::fromLocal8Bit(strLocal) => 字符串变量转换成本地格式，不一定是UTF8
   K：（已完成）学生端和讲师端的主进程都是Unicode字符集（WCHAR），UTF8和ANSI都是CHAR
      （已完成）与服务器通讯都用UTF8格式，我们自己的API都是转换成UTF8格式，因为使用string(char)；
      （已完成）在显示和主App当中存放，都用QString（WCHAR）格式，这样就能解决乱码问题；
      （已完成）只要不显示，都用UTF8保存与服务器通讯的字符串数据，只有显示时才进行转换；
      （已完成）qobject_cast => 强制转换更有效的方法，不要只是简单的用()进行转换；
   L：（已完成）开始进行学生端的登录改造过程：
      （已完成）学生端与讲师端都有一个初始的登录服务器房间号的过程，这个过程不做限制，后续再进行调整；
      （已完成）学生端登录房间号之后，再进行节点服务器、中心服务器的验证确认，与之前的采集端保持一致，进行判断；
      （已完成）学生端的libcurl要用到https，obs提供的libcurl不支持https，将student与teacher的编译结果分离，student使用自己的一套libcurl支持https；
   M：（已完成）完成了通道的添加、修改、删除、开始、停止等操作；
   N：（已完成）进行“断开重连”的具体操作实现，方便快速重连操作；
   O：（已完成）开始尝试将中转服务器合并到udp服务器当中，端口号确定为21002，学生端、老师端都链接这个端口，进行命令交互和数据交互；
      （未完成）学生端的动态截图也通过这个交互通道完成，学生端和讲师端都有一个登录过程，都通过房间号来进行相互关联；PHP网站端只是完成网站与服务器的数据内容交互；
      （已完成）需要改造edu.ihaoyi.cn的房间登录验证过程，网站端这时不用链接中转服务器；
      （已完成）修改讲师端登录流程，使用新的中转服务器的处理流程；同时，优化了讲师端变量和文字；简化讲师端与网站端的交互流程，获取中转服务器地址和端口；
      （已完成）只限制学生端使用时间，讲师端不限制使用时间，但都需要登录服务器，验证房间号，验证房间密码；
      （已完成）学生端和讲师端都需要从网站获取到系统配置的udp服务器的地址和端口，讲师端通过网站接口获取，学生端通过注册时获取；
      （已完成）需要在网站端的系统配置表wk_system当中，新增两个字段udp_addr和udp_port，用来记录udp服务器的地址和端口；
       QString::fromUtf8 => 将UTF8转换成Unicode的QString
       QString::toUtf8   => 将Unicode的QString转存成UTF8格式
   P：（已完成）学生端开始加入连接udp服务器，启动后就不断尝试接入；
      （已完成）学生端由于使用的SDL，必须用一个完整窗口进行显示，需要在CViewTeacher当中增加一个专门用来显示的窗口CViewRender
      （已完成）QT当中，目前使用的全屏方案有点问题：如果全屏窗口有子窗口，好像不能全屏，只有当窗口是单独子窗口时才能全屏；
      （已完成）SDL的QT窗口不能用QT的接口show进行显示，必须使用API接口ShowWindow()，可能是SDL通过API进行隐藏的原因；
      （已完成）SDL2在使用D3D进行画面绘制时，是锁定窗口状态，这时如果进行全屏操作，就会改变窗口属性，造成冲突崩溃；用变量标识：全屏过程中，不能重建SDL句柄；
      （已完成）当渲染窗口的矩形大小发生变化时，没有采用之前的直接重建的方式，而是在渲染窗口设置标志，让播放层自己检测标志进行重建，这样简化了操作，重建的次数也会减少；
      （已完成）优化渲染窗口的重绘问题，设置播放状态，在播放状态下，不要重绘背景，通过获取播放层状态进行必要的文字信息显示；
      （已完成）https://blog.csdn.net/u013255206/article/details/70312818 => 解决边框闪烁的问题；
      （未完成）还有一个闪烁问题 => 拖动Splitter造成 CViewRight|CViewTeacher|CViewRender 发生变化时的闪烁问题，可以参考obs里面的处理过程；
      （已完成）学生端、讲师端只要登录房间成功之后，就立即连接中转服务器，等待交互命令，而不是等待5秒之后；都有30秒汇报机制，避免服务器端超时删除；
      （已完成）学生端观看线程是否启动，要看讲师端是否在线，学生端可以通过中转服务器获得所在房间内是否有讲师登录，讲师端登录也会登录状态转发给在线的学生端，学生端再启动观看线程。
      （已完成）学生端登录中转服务器之后，服务器会反馈房间里是否已经有讲师端存在，学生端就会根据反馈启动接收线程CUDPRecvThread，进行UDP数据拉取；
      （已完成）讲师端登录中转服务器之后，会遍历所在房间里有效的在线学生端，向他们转发讲师端上线通知，学生端会启动接收线程CUDPRecvThread，进行UDP数据拉取；
      （已完成）讲师端退出或被中转服务器删除之后，会遍历所有在房间里有效的在线学生端，向他们转发讲师端下线通知，有两种状态：TCP连接对象|UDP连接对象；
      （未完成）尝试降低udp数据包的大小来测试目前上传对网络影响，目前是800字节，可以在100~1400字节之间尝试；
   Q：（已完成）需要去掉服务器端的Reload的命令，作用不大，但是会造成服务器和连接者都会发生混乱；
      （已完成）重建的发生是由于UDP讲师端或UDP学生端被服务器删除之后，终端并不知道造成的，现在有了TCP长连接，可以进行这个删除通知操作；
      （已完成）讲师端TCP连接和学生端TCP连接都必须先于UDP启动，每个UDP连接在创建命令当中都要带上与TCP的关联套接字编号，进行相互关联；
      （已完成）这样，当UDP连接在退出时，就能依靠TCP连接进行事件通知，达到精确控制的目的，UDP连接在服务器和终端当中都只保留套接字编号，每次使用时通过编号去查找对象，避免保存指针造成的问题；
      （已完成）rtp_create_t 结构中新增一个字段 => tcpSock，用来跟TCP连接进行关联；彻底删除与Reload相关的结构和代码；
      （已完成）学生端TCP连接和讲师端TCP连接登录成功之后，服务器都要返回TCP套接字给终端，以便建立UDP时在rtp_create_t当中使用；
      （已完成）讲师端在启动时rtp_source注定将无法启动，因为一定会参数不足，这个需要特别注意；（更改了服务器端的处理流程：触发学生端推流）
      （已完成）obs-teacher里面有两个输出类AdvancedOutput|SimpleOutput，需要在两个地方都需要进行输出配置；
      （已完成）讲师端的rtp_output插件当中，create|update, start|stop|destroy 过程都是有差异的，stop时只删除了推流线程，配置对象并没有删除，destroy是才删除配置对象；
      （已完成）讲师端的rtp_output插件当中，AdvancedOutput::StartStreaming|SimpleOutput::StartStreaming，每次启动都重新设置了配置信息；
      （已完成）讲师端的rtp_output和rtp_source插件当中，由于udp_addr和udp_port都是从网络配置当中获取，不是硬编码了，可以去掉 DEF_UDP_HOME|DEF_UDP_PORT 的定义了；
      （已完成）讲师端、学生端在收到 kCmd_UDP_Logout 命令时，需要注意重复删除的问题，同时，需要通过强烈的网络阻塞才能进行超时删除测试验证；
      （已完成）讲师端 on_streamButton_clicked 可以进行推流的开启或关闭；
      （不处理）学生推流端，在网络先拥塞只发音频，当网络恢复正常之后，需要再发送视频，不要永远都不发视频了；（采用了新的模式：严重拥塞，学生端主动中断推流）
   R：（已完成）讲师端通过创建rtp_source只拉取一路房间里的学生端摄像头，通过中转服务器告诉学生端可以推流了；
      （已完成）讲师端 => 服务器 => 学生端 的交互流程改进，通过中转服务器而不是通过curl网站服务器；
      （已完成）学生端 通道的启动和停止，不但要向网站服务器汇报，还要向中转服务器汇报，讲师端只从中转服务器获取在线通道的列表信息；
      （已完成）学生端、讲师端 登录命令中，需要加入学生端的名称字段UTF8格式，便于讲师端查看使用；
      （已完成）RemoteSession当中使用临时动态缓存，发送命令数据包，如果用固定的缓存可能在多线程发送时造成命令被冲掉的可能性；
      （已完成）讲师端 通过中转服务器获取所在房间里的所有在线的摄像头通道列表，并通过界面显示出来，供用户进行拉流通道选择；
      （已完成）学生端、讲师端、中转服务器，发送数据的代码做了统一优化，调用统一的通用接口，而不是每次都重复代码 => doSendCommonCmd
      （已完成）中转服务器端每一个摄像头通道的Create(启动)和Delete(关闭)，都是讲师端触发造成的，因此，都需要在中转服务器转发给房间里的老师端对象；
      （已完成）老师端成功发起Camera_LiveStart命令之后，不要启动rtp_source拉流线程，中转服务器会触发学生端开始通过UDP推流；学生端推流Create触发中转服务器转发给讲师端，学生端推流Delete触发中转服务器转发给讲师端；这样形成一个完整的命令闭环；
      （已完成）老师端登录成功之后，也跟学生端一样，会带着rtp_source里的摄像头通道编号，获取是否能够创建rtp_source的反馈，就能避免讲师端每次重启不能播放的问题；
      （已完成）学生端和老师端在中转服务器当中的特性现在正在趋同，过程都逐渐向相同特质靠拢，这样维护起来就会好很多，稳定性也会加强；
      （已完成）老师端发起的Camera_LiveStart命令，不仅需要发送摄像头通道编号，还要使用场景资源编号，这样才能在讲师端精确定位资源；
      （已完成）老师端动态改变拉取的摄像头通道的处理，需要进一步的完善，便于用户任意调整：反复选择相同的摄像头通道；两个通道来回切换；
      （已完成）老师端需要在rtp_source当中根据摄像头通道的在线标志进行特殊处理，学生端需要先停止正在推流的所有通道（不包括与新通道编号一致的通道），再启动新通道的推流线程；
      （已完成）老师端需要在界面层限制：只能有一个rtp_source数据源的存在，如果有多个，目前在逻辑上和服务器上会发生混乱；（一个可以克隆多个，目前是支持的，虽然支持，还是屏蔽了）
      （已完成）老师端需要在启动时，rtp_source资源的create过程，不要尝试创建拉流线程，在得到rtp_source资源的 场景资源编号 和 摄像头通道编号之后，通过登录命令发送给服务器；
      （已完成）老师端OBSBasic::OBSInit()虽然先执行，但是OBSBasic::DeferredLoad()信号槽是异步的，导致后执行的OBSApp::doCheckRemote()会先于资源装入前加载，CRemoteSession的创建必须等待OBSBasic::DeferredLoad()加载完毕之后才能进行；
      （已完成）老师端OBSBasic::DeferredLoad()加载完毕之后，立即调用App()->doCheckRemote()，启动远程连接，防止rtp_source的启动延时；
      （已完成）中转服务器在当UDP连接中断时发送的kCmd_UDP_Logout当中，需要带上nDBCameraID，便于学生端进行删除操作；
      （已完成）老师端在登录是，发送的kCmd_Teacher_Login登录命令，服务器端还是要立即发送反馈命令，目的是得到关联的TCPSockFD；
      （已完成）老师端在登录时，发送的kCmd_Teacher_Login登录命令，在服务器端会根据SceneItemID和DBCameraID触发学生端的kCmd_Camera_LiveStart命令，然后再有学生端通过中转服务器回应kCmd_Teacher_Login反馈给老师端；
      （已完成）老师端停止拉流或老师端退出时，需要通知学生端推流者，停止推流，或者，当学生推流者缓存的数据超过4秒，就直接停止推流，而不是现在只发音频的处理模式，长时间没有老师观看端回应，就需要自动被删除；
      （已完成）学生端在推流时，如果发现缓存超过4秒，就发起停止推流指令，迫使服务器端通知老师端中断拉流线程；这样就能简化学生端对网络拥塞的处理过程；
      （已完成）老师端相对应的，会用一个时钟检测rtp_source资源的健康情况，发现中断，可以主动发起kCmd_Camera_LiveStart命令，触发学生端再次推流，接着触发老师端的rtp_source主动连接服务器再次拉流；
      （已完成）学生端先于中转服务器启动，通道启动后，在中转服务器中没有形成CTCPCamera对象；讲师端无法获取在线通道列表；
      （已完成）学生端远程连接被超时删除之后，已经启动的通道没有重新更新到中转服务器，在中转服务器中没有形成CTCPCamera对象，讲师端无法获取在线通道列表；
      （不处理）针对以上两个问题：学生端在启动时，遍历通道状态，把在线通道编号附加到登录命令当中，在服务器端进行CTCPCamera对象的更新处理；
      （不处理）针对以上两个问题：学生端在启动后，发送kCmd_Student_OnLine在线汇报命令时，需要附带上当前在线的通道编号，在服务器端进行CTCPCamera对象的更新处理；
      （已完成）以上的思路还是有问题：太过复杂，需要简化；学生端远程对象登录成功之后，会遍历所有摄像头通道，重新发送kCmd_Camera_PullStart命令，避免服务器端没有摄像头通道对象的问题；
      （已完成）学生端正在推流的在线状态信息显示，正在推流的图标信息显示；
      （已完成）通道编辑对话框的QLineText在进行粘贴复制时，报告剪贴板不可用的错误；CoInitializeEx()初始化的位置不要放在main()，应该放在doLoginSuccess()登录成功之后；
      （已完成）SDL2.0的初始化不能放在CoInitializeEx()之后，而是应该放在CPlayThread()当中，也不用重复调用COM的初始化；
      （不处理）发现：IPC动态改变码率之后，不用断开连接，就能动态根据变化的码流拉取数据，跟之前的测试有点不同，这个需要后期进一步确认；
   S：（已完成）讲师端的数据源窗口布局进行调整，按照固定的第一行一个大窗口，第二行多个小窗口排列；
      （已完成）只有一个窗口时，默认按比例填充屏幕；有第二个窗口时，自动排列两行：第一行一个大窗口，第二行多个小窗口；
      （已完成）双击第二行的小窗口，自动跟第一行的大窗口进行显示位置切换，需要记录第一个大窗口的窗口对象指针或代号，便于查找定位；
      （已完成）双击进行窗口位置交换时，无需记录位置，而是根据scene_item的特征进行计算判断，避免记录带来的还原问题，pos坐标为(0,0)的就是第一行大窗口；
      （不处理）讲师端在推流时，只编码压缩第一个大窗口的图像，不要对整个整个显示画布进行编码；在压缩前就进行了数据的变换处理，学生端就可以不做处理了；
      （不处理）讲师端在进行YUV原始数据输出时，可以预先进行图像的缩放工作，整个画布1680*1050，整体输出1120*700，我们实际需要的是1680*840，因此，变换区间是1680*840 => 1120*700；
      （不处理）video-io.c:video_thread() => 处理已经变换后的YUV数据，再次处理后放入压缩器；
      （不处理）video-io:obs_graphics_thread() => output_frame() => output_video_data() => video_output_lock_frame() => 产生YUV数据的过程；
      （已完成）尝试在讲师端对原始画面进行裁剪压缩的工作失败了；尝试在学生端在回放时对解码后的数据进行裁剪显示，成功了，具体参见 => CVideoThread::doDisplaySDL()
      （已完成）https://obsproject.com/docs/ => 开发文档 => 作用并不大；
      （已完成）obs_load_sources => scene_load => scene_load_item => obs_scene_add => 创建 obs_sceneitem_t 对象的地方；
      （已完成）obs_scene->id_counter是在obs_scene_item读取完毕之后从配置当中更改的，obs_scene_item->id是在obs_scene_add之后从配置当中更改的；
      （已完成）所有的obs_scene_item都是以链表的形式，存放在obs_scene当中，id序号是根据链表递增排列，id会不断累加；永不重复；
      （已完成）obs_sceneitem_remove => obs_sceneitem_release => obs_sceneitem_destroy
      （已完成）OBSBasic::DeferredLoad() => Load() => 成功之后，需要调用场景资源位置重排接口OBSBasic::doSceneItemLayout()；两行（1行1列，1行5列）
      （已完成）window-basic-source-select.cpp:AddSource() => 成功之后，需要调用场景资源位置重排接口OBSBasic::doSceneItemLayout()；两行（1行1列，1行5列）
      （不处理）直接对预览窗口进行全屏，而不是新建一个投影窗口进行全屏预览，增加一个菜单和快捷键盘，比如：F5和F键；（尝试之后，效果不好，暂时不处理）
      （已完成）行与行之间增减显示间距，列与列之间增加显示间距，不要让显示窗口看起来那么拥挤；
      （已完成）进行scene_item的删除操作时不进行显示位置的窗口重排；
      （已完成）在对场景资源进行重排显示时，只输出第一行大窗口资源的音频+其它没有界面的全局音频资源；屏蔽其它资源的音频输出；
      （已完成）默认都采用“关闭监视”的方式：讲师端不回放声音，只保留最大窗口的音频输出，其它带视频窗口的音频都屏蔽掉，不输出；
      （已完成）Teacher与Student，全新整体打包输出，安装、测试、发布；
      （已完成）Teacher、Student，32位Release编译、打包、输出；
      （已完成）讲师端、学生端在新系统中主窗口图标没有显示出来；this->setWindowIcon()使用png图片可以解决这个问题，某些机器不认ico；
      （已完成）SDL_OpenAudio()启动报错，是由于一个进程只能打开一个SDL2.0音频，因此，讲师端、学生端都需要禁止启动多个进程，使用互斥的方式，参考“讲师端”的实现；讲师端已经有专门的处理重复加载的代码；
      （已完成）SDL_OpenAudio()失败的问题，是由于某些硬件设备必须插入耳机才会启用，因此，代码需要修正，避免没有音频对象时，还在一直灌音频数据；
      （已完成）某些主机的声卡显示耳机未插入，可以设置：禁用前面板检测来解决，这样就不用非要插入耳机才能使用扬声器，SDL_OpenAudio()加载就能成功；

12.（已完成）发现obs在显示层有1秒左右缓存延时，这个要想办法去掉 => obs_source_set_async_unbuffered
   A：（已完成）win-rtp已经把解码好的数据丢给了obs显示层，网络层没有任何的缓存数据包，缓存应该累积在了obs的显示层；
   B：（已完成）win-rtp当中针对数据帧的处理有点问题，跟obs的机制有关，obs是会严格安装音视频同步，win-rtp在寻找关键帧的过程中，没有丢掉音频，造成同步延时；
   C：（已完成）win-rtp改进方案 => 始终用视频做为同步机制，使用视频的第一个关键帧的时间戳做为播放0点时钟，第一个关键帧之前的音频都扔掉，这样就不会造成obs的同步延时；
   D：（已完成）win-dshow数据采集层和obs显示层，看看是否有缓存延时，需要尽量少的缓存，否则有延时，目前obs采集到学生端播放，互联网延时在0.5秒左右；
   E：（已完成）win-dshow里面设置了obs_source_set_async_unbuffered，播放层补缓存，直接播放；win-rtp当中也设置补缓存，但是有点卡顿；
   F：（已完成）发现目前移动的家庭网络，只要有推有拉，网络就不会有大的波动，只会偶尔波动；
   G：（已完成）需要进一步优化win-rtp当中rtp-source的延迟问题，现在确定就是播放层的问题，如何达到低延时不卡顿是个问题；
   H：（未完成）win-rtp的rtp-output也有延时，obs在压缩层是否也有缓存问题，需要进一步的分析；

13.（已完成）还需要新增个win-rtp-service用来配置链接服务器的地址信息，目前是硬编码写死，obs有一套service机制来解决；
  A：（已完成）目前采用的是在服务器网站端进行udp地址和端口配置，来解决地址问题，暂时不用写obs的service机制；

14.（已完成）云教室 需要将中转服务器与UDP转发服务器整合到一起去，修改中转端口；这种方式可以简化很多复杂的交互操作；
   A：（已完成）观看端尝试连接通道，需要向中转服务器汇报，否则，一直尝试连接失败；
   B：（已完成）观看端主动退出之后，推流端没有收到通知，继续推流，需要改进；

15.（已完成）电子白板 => 就是把投影仪和幕布融为一体，HDMI或VGA连接电子白板(投影仪)和电脑，USB连接电脑和电子白板，完成交互识别；电子白板已经产品化，价格便宜；
16.（已完成）网站参考页面 => https://www.yuanfudao.com/
17.（已完成）AWS据说带宽流量免费？直播服务器自己搭建最好用aws，抖音都是用的aws => https://aws.amazon.com/cn/

2018.06.26 - 低延时学生端推流，服务器转发，讲师端接收，讲师端音视频同步播放，开发总结：
===============================================================================================
1.（已完成）交互命令与数据结构定义：
   A：每一个命令的第一个字节都由三部分组成：TM(Terminate Type，7-8位)，ID(Identify Type，5-6位)，PT(Payload Type，1-4位)，详见rtp.h命令结构体定义；
   B：TM(终端类型)，目前有 3种：0x01（学生端），0x02（讲师端），0x03（服务器）
   C：ID(终端身份)，目前有 3种：0x01（推流者），0x02（观看者），0x03（服务器）
   D：形成四种交互终端：学生推流者、学生观看者、讲师推流者、讲师观看者；
   E：PT(载荷命令)，目前有10种：0x01（探测），0x02（创建），0x03（删除），0x04（补包），0x05（序列头），0x06（准备就绪），0x07（重建），0x08（音频包），0x09（视频包），0x0A（丢失包）
   F：UDP数据载荷固定为800字节，UDP命令结构体按4字节整数倍定义。音视频数据包结构体rtp_hdr_t长度为12字节；
   G：推流端和观看端都使用环形队列(circlebuf.h)来管理音视频数据包，为了便于快速定位，环形队列每一个数据包长度800+12，音视频载荷不足800字节的，用0填充；
2.（已完成）UDP服务器架构与房间定义：
   A：UDP服务器监听端口5252，使用UDP阻塞套接字模型，收到网络命令数据之后，解析第一个字节，获得TM(终端类型)，ID(身份类型)，PT(载荷命令)，进行分发处理；
   B：所有向5252发送数据的终端，都会自动创建一个CNetwork对象，通过nHostPort来定位CNetwork，最终只有两种终端CStudent和CTeacher，都从CNetwork继承；
   C：在edu.ihaoyi.cn会预先建立虚拟房间，产生房间号，学生端软件和讲师端软件需要预先通过房间号登录虚拟房间；
   D：学生端软件和讲师端软件通过Create命令告诉UDP服务器已登录的房间信息，并在UDP服务器创建CRoom对象；
   E：CRoom对象包含一个推流CStudent（会变化），一个推流CTeacher（不变），一个观看Teacher（不变），多个观看CStudent（变化）；
3.（已完成）学生推流端基本流程：
   A：初始化视频格式头 H264（SPS+PPS+Width+Height+FPS），如果推流线程未启动，启动之；
   B：初始化音频格式头  AAC（采样率索引号+声道数），如果推流线程未启动，启动之；
   C：初始化线程当中设置初始的命令为发送创建命令，创建UDP异步套接字；
   D：如果状态是发送创建命令，每隔100毫秒向服务器的5252端口发送创建命令包，当收到服务器确认收到创建命令之后，设置状态为发送序列头命令；
   E：如果状态是发送序列头命令，每隔100毫秒向服务器的5252端口发送序列头命令包，当收到服务器确认收到序列头命令之后，设置状态为等待状态（等待观看端发送准备就绪命令）
   F：推流线程每隔1秒钟，向服务器的5252端口发送网络探测命令包，服务器转发给房间里的讲师观看者，讲师观看者收到之后，再返回给服务器，服务器再返回给学生推流端；
   G：讲师观看端登录服务器之后，服务器会转发学生推流端的播放序列头给讲师观看端，讲师观看端收到播放序列头之后，每隔100毫秒发送准备就绪命令包；
   H：学生推流端收到服务器转发的来自讲师观看端发送的准备就绪命令之后，设置状态为发送音视频数据包命令，并回复讲师观看者一个准备就绪包，告诉它不要再发送准备就绪包了；
   I：音视频数据线程，发现推流线程是发送数据包状态后，开始将获取到音视频数据帧投递到推流线程，并安装800字节进行封装，依次放入推流环形队列，形成打包序号；
   J：推流线程会检测环形队列当中有没有打包好的音视频数据包，有包立即发送出去，按照序号发送，形成发送序号；
   K：推流线程会收到讲师观看端发送的补包命令，将需要补包的序号放入一个map队列；
   L：推流线程会检测丢包队列，取出一个丢包号，找到丢包数据立即发送出去；
   M：推流线程收到讲师观看端发送的网络探测命令，会附带一个观看端已经成功接收到的连续最大播放包序号，用这个序号删除发送环形队列当中的过期数据包；
   N：推流线程只要有任何的发送数据或接收数据，就不能休息，既没有发送也没有接收时，才进行sleep休息，最大休息15毫秒，如果休息太短，CPU会上升，后期可以考虑用QT异步优化；
   O：推流线程退出时，会主动发送删除命令，删除服务器端的学生端推流对象，服务器端也会定期（每隔10秒）检测并删除长时间（15秒）没有数据交互的终端；
4.（已完成）讲师接收端基本流程：
   A：初始化接收线程，创建UDP异步套接字，设置初始的发送创建命令状态；
   B：如果状态是发送创建命令，每隔100毫秒向服务器发送创建命令包，服务器收到之后，会回复服务器收到的来自学生推流端上传的播放序列头，接收线程收到播放序列头之后，设置为准备就绪状态；
   C：如果状态是准备就绪命令，每隔100毫秒向服务器发送准备就绪命令包，服务器收到之后，会回复服务器收到的来自学生推流端的映射端口和地址，接收线程收到服务器回复之后，设置为接收音视频数据包状态；
   D：接收线程每隔1秒钟，向服务器的5252端口发送网络探测命令包，服务器转发给房间里的学生推流者，学生推流者收到之后，再返回给服务器，服务器再返回给讲师观看端；
   E：接收线程收到音视频数据包之后，会按照序号放入接收环形队列，丢失包做标记，数据区用0填充，同时，将丢失包放入补包队列；
   F：接收线程会检测补包队列，将需要补包的序号组合在一起发送给学生推流端；
   G：接收线程收到学生推流端发送的补包之后，才将补包队列里的丢包号删除掉；
   H：接收线程会从环形队列抽取完整一帧数据，放入播放器；
   I：接收线程只要有任何的发送数据或接收数据，就不能休息，没有任何操作时，踩进行sleep休息，最大休息15毫秒；
   J：接收线程退出时，会主动发送删除命令，删除服务器端的讲师观看者对象，服务器端也会定期（每隔10秒）检测并删除长时间（15秒）没有数据交互的终端；
5.（已完成）遇到的问题与解决方法汇总：
   A：服务器端正常运转的前提：学生端和讲师端连接服务器的UDP映射端口保持不变，如果是那种每次发送UDP数据包都会造成端口变化的复杂网络就无法进行数据的中转操作；
   B：目前采用的异步socket方式，sleep时间会造成探测包、收发数据包 延时误差，如果设置过小的sleep值，会造成CPU上升，目前设置为15毫秒；后期可以考虑用QT异步优化；
   C：H.264的视频帧前4字节要改成00 00 00 01，第一帧必须带上SPS和PPS，直接使用avcodec_decode_video2解码，got_picture为0时，设置has_b_frames = 0，非常重要，避免错误帧缓存造成延时；
   D：目前从海康IPC获取到的H.264数据帧只有I帧和P帧，没有B帧，这样延时相对较小；
   E：avcodec_decode_video2得到的AVFrame一定要用av_frame_clone拷贝走，H264的解码帧是相互关联的，解码器会保留AVFrame地址，后续帧会一直影响前面帧的数据，造成画面抖动；
   F：解决了AVFrame解码后数据相互影响，以及解码失败的延时问题，就能根据时间戳任意控制音视频的播放，采用系统0点计时方式，音视频播放帧的时间戳只需要跟系统时间比对，无需相互比对，就能自动同步，同步是由音视频时间戳决定的。
   G：环形队列的使用非常重要，千万不能用指针操作，只能通过接口方式操作，因为是环形队列循环使用，会有start_pos > end_pos的情况，这是用指针就会发生错误；每次操作都用一个临时缓冲去拷贝数据，这样就最安全。
   H：环形队列在抽帧时，别全部抽取之后，新到达的序号包要进行丢包处理，有可能691先到达，690后到达，就需要给690预留位置，设置丢包标记；
   I：https://www.cnblogs.com/lidabo/p/6857616.html => 非常重要的低延时理论实践文章；
   J：http://bbs.chinaunix.net/thread-4096315-3-1.html => 不要加锁. 不要弄复杂, 程序先写出来, 你就会发现UDP处理高并发实在太简单了.
   K：https://blog.csdn.net/wuxinyanzi/article/details/52300960 => MTU探测思路 => 设置socket为不分片，发送一系列不同大小的包到server，超过MTU的包自然会被丢弃。这样可以得到路径MTU值。
   L：https://www.cnblogs.com/fsw-blog/p/4788036.html => tc 详细用法 (ln -s /usr/lib64/tc /usr/lib/tc)
      https://blog.csdn.net/duanbeibei/article/details/41250029/ => tc 详细用法
      tc qdisc add dev eth0 root netem delay 200ms 70ms 30% loss 10% corrupt 0.1% => 延时200ms，抖动70ms，丢包10%，0.1包损坏；
      tc qdisc del dev eth0 root netem delay 100ms 30ms 30% loss 1% corrupt 0.1%
      tc qdisc replace dev eth0 root netem delay 200ms 70ms 30% loss 10% corrupt 0.1%

6.（已完成）发现一个更为重要的问题：每一帧都有发包延时，这个需要精确的计算出每一帧的发包延时，这个非常重要，目前只做了0点偏移，并没有计算发包延时；
   A：首先，要解决系统0点时刻问题：系统认为的第一帧应该已经准备好的系统时刻点，取系统时间的纳秒时间值。
   B：在观看端收到第一个数据包 或 收到服务器反馈的播放序列头信息时，都是设置系统0点时刻的位置；谁先到就用谁设置；
   C：播放器的第一帧0点时间戳：观看端收集好完整第一帧音视频数据的PTS时间戳，越快设置第一帧时间戳，播放延时越小，至于能否播放，不用管，这里只管设定启动时间戳...
   D：千万不能想当然的在收到完整第一帧时间戳的时候才设置系统0点时刻，因为，第一帧从推流端被传输到观看端，一定存在网络延时，还有切片组帧过程，如果第一帧来的太慢，这个延时永远无法消除；
   E：系统0点时刻与第一帧0点时间戳，是两个完全不相干的东西，各自有自己的时间轴，帧的时间戳在帧被推流端创建时就已经确定了，是一个相对时间；
   F：系统0点时刻相当于推流端第一帧时间戳在观看端的系统绝对时间映射点，也就是把推流端的播放时间点映射到观看端的播放时间轴的计时起点；
   G：我们可以通过操纵系统0点时刻来灵活的控制延时，因为，音视频播放器都是使用系统时间轴来控制播放的，我们可以人为的添加一个系统时间Delta来控制延时；
   H：通过人为改变系统0点时刻来控制播放延时，而不是通过控制缓冲区，这样相对最简单；实验已经通过，可以明显的看到解码缓冲[0,30]之间匀速波动；
   I：在观看端进行第一个视频关键帧查找时，不要扔掉音频，也不要在找到关键帧之后才设置第一帧0点时间戳，必须在收到第一帧就设置0点时间戳；
   J：注意：观看端收到的所有音视频数据帧都是落后于推流端的，都是相对推流端延时的，只是延时大或延时小的问题；只要控制在0.3秒以下就不会有感觉；
   K：发现：在没有补包的情况下，观看端会收到重复的UDP数据包，UDP会被路由器重复发包，出现 Supply Unknown 事件...

7.（已完成）推流端在准备好视频头之后，就立即完成了创建命令和序列头命令，然后，才到达音频头信息，造成音频头信息无法汇报给观看端，观看端无法处理音频；
   A：需要在音视频都准备好之后，才进行推流线程的启动工作，就能避免这个问题；
   B：音频播放缓存优化 => 使用环形队列处理解码后的音频数据 => 每个音频解码后的数据包长度是固定的 => 忽略时间戳乱序问题，认为后面的时间戳一定比前面的大；
   C：视频播放缓存优化 => 使用环形队列处理解码后的视频数据 => 每个视频解码后的数据包长度是固定的 => 忽略时间戳乱序问题，认为后面的时间戳一定比前面的大；
   D：使用环形队列优化 => 有一个潜在风险 => 数据帧根据PTS排序问题，始终假设后面数据的PTS一定比前面数据的PTS大 => 因为始终全力追赶播放，缓冲个数相对较小；
   E：由于视频播放使用环形队列太过复杂，已经放弃，只在音频播放里面使用环形队列；

8.（已完成）视频在没有丢包的情况还是会出现解码失败，需要尝试对解码后的AVFrame进行队列管理，P帧也需要关联数据；也可能与网络抖动有关系；
   A：尝试给解码后的AVFrame设置一个缓存列表，2倍gop_size，仍然会出现解码失败的问题，有可能跟时间戳的混乱有关系，即时间戳大的先到，导致无法解码；需要增加一个解码前缓存；
   B：尝试发送和接收端进行存盘验证音视频数据帧的解码正确性，目前即使完整数据帧也会发生解码失败问题，这个需要进一步验证。在保证网络畅通的情况下；
   C：发现，网络流畅的情况下视频解码出错的可能性很小，这个就很奇怪了。
   D：这个问题可能是之前修改的解码方式有关，后来，还原后，即使网络差的情况下解码也没有出错。
   E：只要网络上有人进行微信视频通话，就会造成本地无线网络卡死，造成获取无线IPC数据失败，无法进行数据交互。
   F：只要网络数据不丢失的情况下，是不会造成解码失败的，解码失败一定是数据错误造成的。
   G：看阿里云的帮助文档：购买的带宽都是下行带宽，用户上行带宽没有限制；
   H：通过海康的后台页面动态设置码率信息，并不能及时反馈到压缩器当中，接收端还是要停止重连之后才能更新码率；相当于IPC保留了原始链接，等没有用户链接了才关闭原来压缩器；
   I：后来，在使用海康的rtsp输出连接时，通过海康网页后台进行动态码率调整，rtsp码率立即就进行了调整；之前可能是用的SDK模式？

9.（放弃）音频是按采样率匀速播放的，一旦出现卡顿，一定会出现数据堆积，因为数据并没有丢失只是慢了，音频播放并不知道，只会仍然按采样率速度匀速播放下去，这样必然发生堆积，延时增大；
   A：（放弃）也就是说，网络抖动的累计延时都会体现在音频上面，因此，必须要保证音频数据的匀速到达，所以，必须在发送端建立两个环形队列，音视频分开处理，优先发声音，优先补声音；
   B：（放弃）尽量让音频有一个匀速的播放空间，不要像弹簧一样来回波动，任何的波动，音频延时都会被累加，不清理就会延时不断增大，清理就会造成音频卡顿频繁，体验变差；
   C：（放弃）丢包进入之后立即解码，音频线程去掉，使用回调模式；
   D：（放弃）视频线程去掉，使用接收线程定期显示画面；
   E：（放弃）网络接收过程不要一次只接收一次，接收多次，直到发生错误为止，这样可以快速获取网络数据；
   F：（放弃）https://blog.csdn.net/abcSunl/article/details/77196788 => 有关音频变速不变调的思路
   G：（已完成）为什么音频播放总是会跟不上，总是会发生数据堆积？（有可能是声卡硬件的问题？）
   H：（已完成）经测试发现，网络抖动之后，后面数据一下子就被灌入，但是，音频播放并不会因此加速播放，卡顿时间被累积，音频被拉长，
       后续数据就发生堆积，累积延时增大，引发音频清理，造成咔哒声音，因此，需要找到能够精确控制音频播放的工具，不能只是扔给硬件了事。
       可以考虑自己使用DirectSound，直接细粒度的控制音频播放缓冲区；
       https://blog.csdn.net/disadministrator/article/details/43966017 => 有关音频解码后格式
       https://blog.csdn.net/leixiaohua1020/article/details/40540147 => 雷神出品，有关DSound
       https://blog.csdn.net/williamaiden/article/details/72799761 => 有DSound的详细说明
   I： http://www.yunliaoim.com/im/2516.html => 有关延时的详细说明 => 没啥作用
   J：目前看来，对于音频的处理，只能采用增大缓存的方法进行处理，即：音频出现清理之后，就需要增大延时；一旦增大延迟之后，音频抗抖动就很强了，延迟设定在500毫秒；
   K：最终，采用计算出来的 缓冲评估时间 做为 播放延时时间，来控制播放层的延时问题，网络好时延时低，网络差时延时大，自动动态调节；
   L：也不能来的那么陡，也要用一种遗忘衰减算法，进行播放延时控制；new_delay = (7 * delay + keep_delay) / 8

10.（已完成）需要处理网络拥塞造成的发送端数据拥塞，形成发送端延时，这个需要定期清理，利用观看端的探测机制进行处理；
   A：（已放弃）要解决发包太快造成的网络拥塞问题；前几秒可以用设定码流的2倍发包，后面逐渐降低；按音视频总体码流计算，这样处理后，才能保证音频优先到达；
   B：（已完成）因为是直播，根本没有那么多数据被发送，数据的产生是由压缩器决定的，想快速发包都不可能；
   B：（已完成）码流平滑的前提是获取精确有效的音视频码流数据信息，即：音视频每秒设定的码流信息；
   C：（已完成）如何动态判断网络拥塞，然后动态调整 m_zero_delay_ms，调整音视频播放延时，也要采用平滑调整的方式进行；
   D：（已放弃）目前可能方法有：通过 rtt 探测结果来判断，通过动态视频帧率计算（每秒实际播放帧数）与系统初始化的帧率比较，小于初始帧率，说明出现卡顿，增大延时；
   E：（已完成）动态延时控制，通过缓存评估时间来解决，通过每次探测结果进行播放延时修正；
   F：（已完成）之前就完成了观看端通过探测命令向推流端汇报观看端已播放的音视频序列号，便于推流端删除过期数据；
   G：（已完成）现在需要反过来，让推流端通过探测命令向观看端汇报推流端当前音视频最小序号包的值，便于观看端及时清理缓存，删除已过期的补包序号；
   H：（已完成）这个过程是推流端的拥塞丢帧过程，推流端丢弃的不是一个包而是整个GOP视频数据，音频也要做丢包处理，以视频的丢包时间戳为基准；
   I：（已完成）推流端在每次进行探测发包时，需要进行视频环形队列检测：只要有两个GOP视频视频数据就扔掉最前面那个，并同步到观看端，进行播放控制和丢包清理；
   J：（已完成）发现目前的拥塞处理有问题，每次通过探测命令进行拥塞同步，但是，观看端在收到拥塞同步之前，就发出了一个观看端的最大播放包探测命令，推流端收到后对缓存清理，
       这时，观看端又发现丢包了，请求推流端重传丢包，推流端发现丢包已经被清理了，造成无法补包，观看端图像静止不动；这种已经发生拥塞的时候进行同步操作是不可能的，网络已经出问题了。
   K：（已完成）需要尝试新的办法，不要进行拥塞同步，也不要进行丢包处理，采用在打包之前丢视频帧的方案，超过3秒缓存就只播关键帧，如果连续超过5次都只能播关键帧，就只播放音频；
   L：（已完成）这种方案很好的解决了网络拥塞问题，没有丢包造成混乱的问题，效果很好，后续再继续优化；
   M：（已完成）拥塞判断，需要在有拉流用户接入之后进行，用户没有接入之前，只是简单的丢包，而不进行拥塞累加判定；

11.（已完成）视频也有拥塞延时问题，即网络拥塞之后，再恢复，就会有些数据包滞留在已解码队列当中，这个延时是否是sleep造成的呢？
   A：如果视频播放时，发现有已解码AVFrame拥塞，说明AVFrame的时间戳落后了，这个落后的时间差是怎么来的？不是数据帧时间戳有偏差了，就是系统时间戳有偏差了。
   B：有时候的测试又是精确的，网络拥塞产生延时，网络畅通，延时消失；
   C：这个问题最终是通过系统0点时刻来解决的，观看端收到的第一个数据包就认为是第一帧数据，设定为0点时刻，其实还是有延迟落差，但相对较小；
   D：通过系统0点时刻与第一帧0点时间戳共同配合解决，同时，还找到了控制卡顿的方法（使用缓存评估时间）
   E：修正系统0点时刻，尝试在观看端在发出每一个Create命令的时候进行更新系统0点时刻，因为，如果观看端接收服务器反馈的Create命令有延时，就会累加到播放层，永远无法清除；
   F：目前有三个地方在设置系统0点时刻：发生Create命令、收到Create命令、收到第一个数据包，经过一定实验之后，只保留一个；
   G：最终采用发送Create命令更新系统0点时刻的方法 => 发出创建命令就认为是第一帧数据已经准备好可以播放的时刻点，这样受网络波动延时的影响最小；
   H：这种方案是根据实际情况 => 观看端必然落后推流端，观看端接入的瞬间一定认为推流端已经准备好了，这样就会做到延时最低；（实际推流端是否准备好不太重要）

12.（已完成）新增P2P探测，比对P2P的rtt与服务器端的rtt，谁小向谁发数据；
   A：（已完成）学生推流端 => 音视频数据包和补包都可以进行线路选择，选最快路线；
   B：（已完成）讲师观看端 => 只有补包需要进行线路选择，选最快路线；
   C：（已完成）在同一个内网里的推流端和观看端无法进行P2P探测，只能通过服务器中转模式；

13.（放弃）新增服务器推流缓存，便于给观看端快速补包，而不是只能到推流端补包，加快补包过程，降低延时；
   A：经测试发现：效果非常差，带来了额外的复杂度，因为有乱序存在，在服务器补包就会引发混乱，效果非常差；
   B：使用P2P模型直接进行补包操作，效果非常好，应该尝试这种最直接简单的方式，还能减轻服务器的带宽压力；

14.（已完成）跟阿里云客服电话沟通之后，总结如下：
   A：经典网络相对没有专有网络安全，但是自由度更高，没有那么多限制，目前最好不要升级，阿里云后期会全部升级为专有网络；
   B：1Mbps抖动特别剧烈，目前没有找到好的解释和原因，尝试临时升级到5Mbps试试情况，如果还是抖动很大的话，就需要提交工单排查；
   C：顺便询问了有关CDN的问题，南北方需要CDN专线做桥接，如果用CDN的话只需要购买一台服务器就可以了，我们这种私有的UDP协议需要看CDN厂商是否支持自定义私有协议；
   D：否则，只能在南北方购买服务器，再通过专线链接通讯；
   E：临时升级到5Mbps之后，依然网络抖动非常大；从他们那里进行网络探测的结果是否依然抖动很大？
   F：将软件放到另外的地方，同样进行推流、观看，1Mbps带宽，网络稳定，没有问题；
   G：这么看来，应该是家里移动宽带的问题，不能同时上行下行传递UDP数据包，现在需要把上行和下行进行分离，看看这样分开是否同样会有影响；

15.（已完成）联系了移动宽带运营商，上门看看为什么在码流很小的UDP上传都会发生网络拥堵的问题？
   A：到家查看网络状态，截图之后，上报后台，过几天给结果；

16.（已完成）将推流和观看分离之后，遇到的新问题：
   A：（已完成）视频解码之后获取的高宽，与SPS序列头里的高宽不一样，需要修改视频播放代码，在图像转换时，使用预设的高宽进行格式转换，用一个固定的转换空间，而不是动态分配；
   B：（已完成）推流端已启动，一直推流，观看端后接入，没有确定第一个包的包号，造成观看端从1开始期待收取数据包，造成图像无法观看；将第一个包号减1设置成最大播放包号；
   C：（已完成）播放窗口的任何变化，都要通知播放器，更新播放窗口，否则，会出现画面无法显示的问题 => 重建SDL窗口、渲染、纹理，来解决D3D页面丢失问题；
   D：（已完成）人为的将启动延时缩小了100毫秒，如果有问题，后期再调整；
   E：（已完成）修正了重复设定第一个数据包序号的问题；
   F：（已完成）推流线程、观看线程退出缓慢的问题 => 先停止数据产生的源，再停止数据处理线程；

2018.06.01 - 2018.06.30
===============================================================================================
1.（已完成）要完成双向低延时的交互回放，需要完成下面四项低延时功能：
   A：（已完成）06.11 确定时间戳状态下，使用SDL2.0完成音视频播放的低延时功能，音频缓存超过300毫秒主动清理音频缓存。
   B：（已完成）06.26 学生端将音视频数据通过单独线程用UDP发送给Linux服务器，用最快的速度，尽量少留缓存，保留一秒缓存，供丢包回传使用；
       https://www.cnblogs.com/lidabo/p/6857616.html => 有关低延时的技术案例
       https://www.cnblogs.com/li0803/archive/2010/11/20/1882792.html => RTP/RTCP协议详解
       https://blog.csdn.net/bytxl/article/details/50400987 => RTP/RTCP协议详解
       https://www.cnblogs.com/foxmin/archive/2012/03/13/2393349.html => RTP/RTCP协议详解
       https://blog.csdn.net/machh/article/details/51868569 => RTP/RTCP协议详解
       https://blog.csdn.net/fishmai/article/details/53676194 => RTP 打包实例
       为了简化操作，所有的 Payload 都统一成固定大小，放入环形队列当中，这样可以直接通过序号就能定位到；
       需要解决有空隙的环形队列问题，网络包到达的先后顺序不一致，会有空隙，circlebuf要解决这个问题；
       接收端，需要对circlebuf进行封装，可以根据网络包序号，进行缓冲的自由伸缩，判断，插入，这样可以避免网络层获取到的缓冲干扰；
       综合比较之后，选择单进程多线程进行UDP服务器的开发，用主线程阻塞等待接收数据，收到之后，放到另一个线程进行数据处理；
       针对学生端推流时 => 发送端和接收端都要各自进行延时探测，各自使用自己的探测结果进行计算；
       针对老师端推流时 => 很多处理过程都要调整，需要单独处理；
       进入最复杂的阶段 => 丢包检测，丢包补充，缓冲区控制；
       已收到最大连续包号 = 最小丢包号 - 1
       解决了UDPSendThread当中数据帧打包问题：帧总长度刚好是800整数倍（分片大小），打包错误会导致psize为0；
       现在重点解决视频帧解码无法得到got_picture的问题，参考文档如下 => 这些文档的方法都不能解决最终问题 => 最终发现是由于AVFrame的缓冲区受后面解码帧的影响；
       实验发现：只要不释放AVFrame空间，即使缓存上百帧，后面解码的数据帧也会影响前面的上百帧数据，因此，解码完毕，需要立刻将解码后的数据拷走，原来AVFrame不要释放，为后续待解码AVPacket提供解码参考源，这也能解释为什么不丢包也会解码失败的问题；
       终于解决了延时播放，自由控制时间戳，解码后的数据混乱问题，解码后无法得到picture等等一系列头疼问题，主要是对ffmpeg的解码机制不了解；
       RTSP的时间戳计算目前看没有问题，网络解析出来的压缩数据帧也没有问题，就是目前的方法：构造AVPacket，投递给直接解码就可以了；
       https://bbs.csdn.net/topics/392059669 => 只有I帧和P帧 => 没有解决
       https://blog.csdn.net/u013898698/article/details/61433612 => 编码延时 => superfast => zerolatency
       https://blog.csdn.net/leixiaohua1020/article/details/14215833 => CODEC_CAP_DELAY
       https://blog.csdn.net/h514434485/article/details/52164087
       https://blog.csdn.net/huyinguo/article/details/4725326 => CODEC_FLAG_LOW_DELAY
       https://bbs.csdn.net/topics/390692774

       解码成功，got_picture为0，说明需要后续的数据帧，会造成解码器内部的数据帧堆积，需要让解码器把堆积数据吐出来 has_b_frames
       https://blog.csdn.net/u013506600/article/details/22329403 => 有关AVFrame当中picture解码问题；
       需要解决解码失败之后，造成解码器内部会缓存数据帧，后续再解码时，永远有延时，需要将解码器内部缓存的数据帧快速取出来，避免延时；
       需要配合best_effort_timestamp时间戳，而不能用AVPacket里面的时间戳，只有解码器知道已缓存的数据帧的真正时间戳是什么；
       然而，以上的实验并不成功，还会造成反复卡顿现象，需要另外寻找新的方法；
       同时，增大了AVFrame解码缓冲的块数，仍然无法解决解码失败后的延时问题；
       https://blog.csdn.net/leixiaohua1020/article/details/19016109
       http://blog.jianchihu.net/avcodec_decode_video2-no-pic.html

       H.264在只有I帧和P帧的时候，解码失败造成视频数据帧堆积的问题，这个文档有说明 => 吐出所有的坏帧...
       在没有B帧的情况下，误码可能会导致视频帧在这里堆积，所以要在这个判断之前将s->avctx->has_b_frames强制设为0。
       https://blog.csdn.net/quanben/article/details/4400336

       （已完成）CUDPSendThread => CPU占用过高 => 需要优化 => 可以考虑使用QT的套接字模型来解决
       （已完成）CUDPRecvThread => CPU占用过高 => 需要优化 => 可以考虑使用QT的套接字模型来解决
       （已完成）丢包问题得到解决，在 doParseFrame() 当中不能将环形队列中的数据包抽干，抽干会导致新包无法写入环形队列？
       （已完成）支持环形队列被抽干，这样可以快速将有效帧投递，降低延时；但是对环形队列为空时，有新包到达后需要提前预判是否有丢包，并做丢包处理；
       （已完成）千万不能在环形队列当中进行指针操作，当start_pos > end_pos时，可能会有越界情况，必须用接口，不能用指针偏移，环形队列可能会回还...
       （已完成）终于解决了发送端和接收端数据包内容不一样的问题，其实是对环形队列的使用错误造成的问题，环形队列千万不能用指针，只能用接口，防止队列回还造成的错误；

   C：（已完成）学生端使用单独线程用UDP从Linux服务器，用最快的速度，拉取音视频数据，组成数据帧，使用SDL2.0播放出来；
   D：（已完成）将学生端数据拉取、组包、解码过程封装起来，移植到讲师端；整个过程控制在1秒以内；
   E：（已完成）改造讲师端推流机制，使用UDP推流到Linux服务器；不使用rtmp推流；
   F：（已完成）学生端从Linux服务器，拉取讲师端推流数据，组成数据帧，使用SDL2.0播放出来，整个过程控制在1秒以内；
   G：（已完成）对错误日志进行了优化，统一存放在用户临时工作目录下面；
2.（已完成）需要解决Teacher端交互时的高延时问题，需要解决的问题如下：
   A：（已完成）采集端推流到服务器，讲师端从服务器获取流，讲师端组包还原音视频数据帧，讲师端解码H264+AAC，讲师端播放；
   B：（已完成）讲师端推流到服务器，采集端从服务器获取流，采集端组包还原音视频数据帧，采集端解码H264+AAC，采集端播放；
   C：（已完成）需要在网上找找有关低延时视频会议系统的解决方案；
   D：（已完成）需要重新编写采集端，专门处理多路RTSP输入，一路讲师端网络输入，选择一路RTSP网络输出；
   E：（已完成）需要重新编写讲师端，专门处理多路摄像头输入+多路窗口输入+1路麦克风输入+1路采集端网络流输入，输出讲师端网络流；
   F：（已完成）有关RTMP延时的分析文章收集：
                http://blog.chinaunix.net/uid-26000296-id-4932817.html
                https://blog.csdn.net/qq_38810947/article/details/74199967
                https://blog.csdn.net/zhiboshequ/article/details/79955433
                https://blog.csdn.net/king457757706/article/details/51004253
                https://www.cnblogs.com/lidabo/p/6857616.html => 更全的低延时文章
                https://blog.csdn.net/mandagod/article/details/52559053 => 比较详细
                https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653547697&idx=1&sn=acc748b7fcf0058b58e244970e51eabc => 微信原始地址
   G：（已完成）简单UDP服务器（Linux）：
                https://blog.csdn.net/u011922698/article/details/55218313
                https://blog.csdn.net/yueguanghaidao/article/details/7055985
                https://blog.csdn.net/aa120515692/article/details/47294335 => UDP并发服务器
                https://blog.csdn.net/aa120515692/article/details/47299529 => UDP并发服务器Select机制
                https://www.cnblogs.com/skyfsm/p/6287787.html?utm_source=itdadao&utm_medium=referral => 比较好的Linux下的UDP基础文章
                https://blog.csdn.net/yang_rong_yong/article/details/49818249
                https://blog.csdn.net/u010643777/article/details/72190891 => UDP下的epoll并发框架 => 有人测试epoll效率低，越简单越好
                https://blog.csdn.net/dog250/article/details/50557570 => UDP的epoll并发框架 => 有人测试epoll效率低，越简单越好
                http://bbs.chinaunix.net/thread-4175621-1-3.html => UDP服务器性能测试 => 很重要的一篇模型实验总结文章，越简单越好
                http://bbs.chinaunix.net/thread-4096315-3-1.html => 不要加锁. 不要弄复杂, 程序先写出来, 你就会发现UDP处理高并发实在太简单了.
                https://blog.csdn.net/libinbin_1014/article/details/50096211
3.（已完成）先用ffmpeg解析H.264视频帧，再用SDL2.0绘制到窗口上；
   A：（已完成）尝试使用SDL2.0解码音频，并回放出来；
   B：（已完成）https://blog.csdn.net/jay100500/article/details/52955232 => AAC帧头格式 => ADTS
   C：（已完成）两路音频同时播放时，只有一路有声音，关闭时还会卡死在界面；
   D：（已完成）需要解决音视频自主播放时的同步问题；
   E：（已完成）进一步研究发现：SDL2.0不支持多路音频播放，支持起来麻烦，还要解决音视频同步问题；
   F：（已完成）需要将目前的实验代码，转移到NO_DELAY分支，研究obs里面针对网络流的数据播放，它是音视频同步的，而且支持多路；
   G：（已完成）将需要的模块单独整理出来，进行符合自己要求的封装；
   H：（已完成）这样可以将所有的精力都投入到obs的研究当中，利用obs的输出库，来完成绝大部分工作，除了服务器之外；
   I：（已完成）目前，单向的学生端推老师端的延时在3.5秒~4.0秒，根本没发进行实际应用；
   J：（已完成）还是要使用SDL2.0播放音频，这种方式最快速也最容易，用obs的库非常麻烦，它是专门服务obs使用的，属于整个obs体系当中；
   K：（已完成）解决了音频单声道的问题，现在需要对音频进行优化处理，不要产生硬编码或哒哒声；（采用解码后的缓冲，而不是固定缓冲）
       https://blog.csdn.net/beiliufangdegezhe/article/details/41623579
       https://blog.csdn.net/u012853439/article/details/53218662
   L：（已完成）进行音视频同步处理过程：
       https://www.cnblogs.com/wangguchangqing/p/5900426.html => 比较好的基础文章 => 通常来说只有在流中含有B帧的时候，PTS和DTS才会不同。
       https://www.cnblogs.com/jiayayao/p/6890882.html
       https://blog.csdn.net/i_scream_/article/details/52760033 => SDL2.0的音视频同步文章
       https://blog.csdn.net/leixiaohua1020/article/details/42181571 => 裸流解码，
       https://blog.csdn.net/nine_locks/article/details/48007055
       https://blog.csdn.net/u010289908/article/details/46507643 => 非常重要的PTS计算方法；
       https://blog.csdn.net/leixiaohua1020/article/details/11800877
       https://blog.csdn.net/leixiaohua1020/article/details/14215821 => AVStream
       https://blog.csdn.net/chenchong_219/article/details/13161509 => 时间戳详解
       https://blog.csdn.net/leixiaohua1020/article/details/12678577 => av_read_frame 详解
   M：（已完成）mp_media_next_video 很关键，计算解码后的时间戳，投递到obs显示系统；
   N：（已完成）我们处理的数据已经是数据帧了，可以直接构造AVPacket来进行解码，而不需要调用av_parser_parse2，AVPacket的结构如下：
       https://www.cnblogs.com/xiacaojun/p/6638800.html => AVPacket详解
       https://blog.csdn.net/qq_27727131/article/details/51799663 => sps计算帧率
       https://blog.csdn.net/caoshangpa/article/details/53083410 => sps计算帧率 => 替换原有的计算方式，这种更精确。
       https://blog.csdn.net/leixiaohua1020/article/details/44084321 => 读取数据给音视频流对象赋值 => AVStream
       pts => 显示时间，就是帧时间戳
       dts => 解码时间，与显示时间相同
       pos => 在缓冲区的位置，可忽略
       data  => 数据区指针
       size  => 数据区大小
       flags => 0（普通帧）1（关键帧）2（坏帧）
       duration => 视频 => 1000/帧率 => 毫秒 => 根据time_base(1,1000)和帧率的计算值，不能用（下一帧pts减去当前帧pts）
       duration => 音频 => 采样点/采样率*1000 => AAC => 1024/采样率*1000 => 毫秒
       stream_index => 流编号，区分音视频标记
   O：（已完成）AVStream->start_time是怎么计算出来的？没有找到相关代码，就默认为0；
   P：（已完成）AVPacket的字段研究完毕，开始研究音视频解码后的时间戳的计算问题；
       AVPacket的时间戳是可以通过数据帧直接赋值，单位是毫秒，这是解码前的时间戳；
       AVStream的时间戳是解码后的时间戳，是跟系统本身是相互关联的；
       mp_media_next_video => decode_packet => 解码数据帧 => AVStream的时间戳是以纳秒为单位的 => time_base(1,1000000000)
       将解码后的pts和duration都需要转换成纳秒形式保存起来 => os_gettime_ns => 取得当前时间的纳秒值
       interrupt_callback => 是为了防止avformat_open_input在解析网络数据卡死时做的检测机制；
       mp_media_reset => 在这里进行时间戳的重置 => obs里面的ffmpeg网络播放机制，延时非常大，需要改进；
       base_sys_ts => 全局，只要source不删除，只初始化一次；
       m->play_sys_ts => 播放系统开始时间戳 => 在mp_media_reset中被重置 => os_gettime_ns()
       m->start_ts => 第一帧开始时间戳（纳秒），取音视频第一帧最小的时间戳 => mp_media_reset 中初始化一次
       m->next_pts_ns => 下一帧的PTS（纳秒），先初始化为音视频第一帧最小时间戳 => 每次检查音视频队里中最小时间戳赋值给next_pts_ns => mp_media_calc_next_ns
       m->next_ns => 下一帧播放时的时刻点（纳秒），mp_media_calc_next_ns 和 mp_media_sleepto 用到，每次最多sleep 20毫秒，等待下一帧播放的时间不要超过3秒；
   Q：（已完成）当视频中有B帧时，需要处理 composition time => RenderOffset
       http://www.cocoachina.com/bbs/read.php?tid=71131
       http://www.likecode.com/2014/11/21/111
       将obs设置成文件模式，对比AVPacket时间戳，发现一些规律，但无法应用在libmp4v2当中，后来即使强制将时间戳调整一致，还是无法在498样本大小位置解码出第一个关键帧
       后续，需要编译ffmpeg，与obs对比跟踪调试avcodec_decode_video2，看看到底哪里不一样，目前这种直接调用解码器的方式可能存在一定的问题，需要编译ffmpeg才能调试清楚；
   R：（已完成）时间戳的计算可能还是存在问题：
       时间戳的计算没有问题，avcodec_decode_video2 也没有问题，是由于模拟延时造成的问题；
       没有B帧的情况下，目前的处理方式没有问题，通常 BaseLine 压缩模式就没有B帧，只有I和P帧；
       模拟丢帧的情况也没有问题，就是出现花屏；
       模拟延时问题一直没有成功，总是造成丢帧，混乱；
       视频延时帧不能丢弃，有可能是过期的落后帧，会造成花屏，视频缓冲很快就会消耗光，难点在音频；
       视频超前帧，不能立即播放，需要等待最大20毫秒时间；
       音频延时200毫秒，清空缓存，等待新数据帧，超前100毫秒以上，等待下次填充；
       音频为什么会出现来不及播放的问题？这个需要深入研究，研究SDL2.0例子，有关音频的播放问题；(估计还是要将音视频单独用线程处理）
       SDL2.0升级到2.0.8，需要调用CoInitializeEx()，http://wiki.libsdl.org/SDL_AudioSpec，2.0.4开始，可以不用callback，用SDL_QueueAudio()代替；
       https://blog.csdn.net/kiazhu/article/details/54744486 => 比较全面的SDL音频API详解；
       音视频单独使用播放线程，因为是以本地时间做为基准时间，音视频的时间戳可以相互不干扰，为了最大限定的降低延时，音视频相互干扰的概率越小越好。

4.（已完成）重新设计采集端的音视频播放流程：
   A：（已完成）音视频的解码、播放，都放在一个线程当中；
   B：（已完成）第二版：发现放在同一个线程，造成播放时有延时干扰，在使用SDL2.0的音频时，采用主动投递方式；

5.（已完成）本地拉取RTSP数据流，进行最快速度的解码显示，也有900毫秒左右的延时，因此，学生端不能用IPC模式，需要对方案进行调整：
   A：（已完成）海康IPC的SDK回显模式，延时在200毫秒左右，比RTSP拉流的延时要低很多；
   B：（已完成）ffmpeg解码器配置参数之后，RTSP延时又变成了300毫秒左右，很奇怪，屏蔽参数之后延时也没有变大；
   C：（已完成）学生端，使用vs2015，利用libobs的函数库，读取USB-Camera的数据，用x264进行压缩编码，去掉B帧模式；最大限度的降低延时；
   D：（已完成）学生端，使用vs2015，利用UDP获取讲师端推流数据，组合成音视频帧，调用ffmpeg解码，SDL2.0回显；
   E：（已完成）学生端，还是用vs2010，改造采集端代码，放到B_NO_DELAY分支，完成了播放层面的低延时回放功能；

6.（已完成）obs里面直接拉取本地rtsp流的延时在2.5秒左右，音视频同步，将obs里面播放网络音视频的部分抽取出来，进行直接的音视频数据帧的播放；
   A：（已完成）由于用SDL2.0直接播放音视频数据帧，存在音频问题，存在音视频不同步问题，这是第一个目标，使用采集端的NO_DELAY分支进行测试；
   B：（已完成）直接拉流延时控制在300毫秒以下，才能在网络上达到1000毫秒以下的目标；重点研究obs-ffmpeg如何播放和音视频同步的方法；
   C：（已完成）ffmpeg相关的代码其实没有感觉中的那么费劲，需要静下心来慢慢体会，某种程度上比c++还要简单一些，思维方式不同。
       av_find_best_stream
       avcodec_find_decoder => 查找 codec
       avcodec_alloc_context3 => 分配 codecContext
       avcodec_parameters_to_context => 设置参数
       avcodec_open2 => 打开解码器
       av_frame_alloc => 分配帧缓冲区

2018.05.01 - 2018.05.31
=========================================================================
1.（已完成）海康人脸系统分为三种层次：
    A：人脸检测 => IPC检测到人脸会通过报警回调接口反馈信息；http://www.hikvision.com/cn/prlb_841.html
    B：人脸抓拍 => IPC检测到人脸不仅报警还会抓拍图像一起反馈；http://www.hikvision.com/cn/prlb_1608.html
    C：人脸比对 => IPC检测到人脸不仅抓拍还要跟已有的人脸库进行比对，然后一并进行回调反馈通知；http://www.hikvision.com/cn/prlb_1609.html
    D：因此，三种形式的IPC是不同的类型，处理的复杂度是不一样的；人脸比对的IPC淘宝价在4500元左右；
2.（未完成）DS-2CD2432F-I/W，300万像素，无线卡片式IPC，音频格式需要转换成AAC格式；12V移动电源可用；英文版，不带电源适配器；
    A：（未完成）由于是WIFI模式，开启预览再拉流，感觉有时网络会不稳定，需要降低视频大小，降低至1280*720；或直接关闭预览；
    B：（未完成）某些自动配置无法执行，后续需要进一步的优化，详情查看 CCamera::onDeviceLoginSuccess() 函数；
    C：（已完成）不要使用这款设备，音频和配置都有问题，可以用“小企鹅”完全代替；
3.（已完成）DS-2CV3Q21FD-IW，200万像素，无线小企鹅IPC，目前测试结果如下，有线地址 => 192.168.1.63
    A：（已完成）购买链接 => https://item.taobao.com/item.htm?id=550673095750 => 3Q21FD-IW|1080P|2.8mm|245元
    A：（已完成）可以用组播探测软件访问配置，IP地址 => 192.168.1.24，登录密码 => adminBBORSE，在摄像头底部的六位验证码；
    B：（已完成）自动链接萤石云，不能用网页访问，iVMS-4200可以远程配置；http://www.hikvision.com/cn/download_more_390.html
    C：（已完成）支持 H264+AAC 方式，开启声音的降噪功能，效果很好 => I:\工具软件\海康插件\iVMS-4200(V2.8.2.2_CN).exe
    D：（已完成）时间戳不能使用PC的时间戳，必须使用硬件本身的时间戳，否则，音视频不同，画面卡顿严重；在Chrome控制台能看到黄色警告信息；
    E：（已完成）目前看来最大的问题是延时比较大，采集端、服务器、播放终端都有可能造成较大的延时问题，这个需要后续专门进行优化处理；
    F：（已完成）音频开启环境噪声过滤、关闭移动侦测、固定无线IP地址(192.168.1.24)；小企鹅完全能满足需求；
    G：（已完成）主码流 => STD_H264 | 1280*720 | 变码率 | 1024kbps | 复合流 | I帧间隔20 | 视频帧率15fps | AAC | 音频32kbps | 采样率16kHz
    H：（已完成）子码流 => STD_H264 | 704*576 | 定码率 | 512kbps | 复合流 | I帧间隔20 | 视频帧率15fps | AAC | 音频32kbps | 采样率16kHz
    I：（已完成）先用“设备网络搜索”修改IP地址，再用iVMS-4200配置无线、音视频参数；后期直接通过SDK配置想要的音视频参数；工具只是配网络；
    J：（已完成）无线模式，本地回放延时在200毫秒左右，低码流下清晰度比较高；开启降噪模式声音效果好。

4.（已完成）DS-2DE2402IW-D3/W，400万像素，无线IPC，目前测试结果如下，有线地址 => 192.168.1.64
    A：（已完成）组播探测方式改动了，使用标准的ONVIF模式，不是通过组播回应的方式，需要在采集端加入标准的ONVIF协议；使用第三方SDK来完成ONVIF；
       （新情况）在无线模式下无法完成自动探测，在有线模式下，能够探测到无线地址，这样一个IPC就会有两个通道64（有线），29（无线），有一个多播搜索开关。
    B：（已完成）可以用网页进行配置管理，登录IP地址 => 192.168.1.29，登录帐号 => admin:admin123
    C：（已完成）主码流 => STD_H264 | 1920*1080 | 变码率 | 1536kbps | 图像质量 最高 | 复杂度 较高 | 25fps | AAC | 
    D：（已完成）主码流 => 音量80 | 开启过滤环境噪音 | 数字降噪60 | 亮度60| 曝光时间 自动x2(80000us)
    E：（已完成）音频开启环境噪音过滤功能，可以有效解决环境杂音；
    F：（已完成）1M码流的效果，感觉和“小企鹅”的效果差不多；
    G：（已完成）先用“设备网络搜索”修改IP地址，再用浏览器修改无线、音视频参数；后期直接通过SDK配置想要的音视频参数；工具只是配网络；
    H：（已完成）无线模式，本地回放延时在150毫秒左右，比之前的设备要好一些；开启降噪模式声音效果好。
    J：（已完成）300k低码流模式下效果差，可以考虑开启smart264试试。经测试320k低码流开启smart264效果好很多。
    K：（已完成）无论是smart264还是普通264，都只有I帧和P帧，没有B帧，目的是降低延时。
    L：（已完成）smart264模式下，延时在300毫秒，如果是普通264，延时在900毫秒；
    M：（已完成）smart264模式下，关键帧间隔不能设置，实测的结果是大概10秒以上；关键帧少，码流就会低，同等码流下质量就会好很多。
    N：（已完成）DE3/W => 支持POE供电，支持无线；D3/W => 支持无线；D3 => 不支持POE，不支持无线；
    O：（已完成）https://mp.weixin.qq.com/s/6nF1_wZXYk8whkGyU267qQ => 海康摄像头命名规则；
                 https://mp.weixin.qq.com/s/mI1Bp5DhcAZ8OreHFL5onA => 海康摄像头命名规则；
                 http://square.ys7.com/play/index?videoId=0726476690a027ad4d6daeea00c640426408 => 视频说明
    P：（已完成）https://item.taobao.com/item.htm?id=562101732517 => 200万像素WIFI只要229元；

5.（已完成）采集端 IPC 时间戳不能使用PC端时间，必须使用RTSP传递时间，否则，会造成图像卡顿，Chrome的控制台提示音视频的时间戳有问题；上次Tim提到的卡顿也是这个原因；
    A：（未完成）如果这样修改之后，需要考虑RTSP时间戳发生跳变的问题，现有的摄像头就能测试；

6.（已完成）赞|踩|评，有关“删除”界面的显示有问题，任何已登录都可以删除评论，只有创建者才能删除评论；
    A：（已完成）修正 云录播|云监控的评论删除页面鼠标滑过时是否显示删除按钮的问题；
    B：（已完成）修正 云录播|云监控在IE8下添加|删除 评论时的等待样式错位问题；

7.（已完成）云教室的播放器，需要处理三种类型的视频：
   A：wk_camera => 采集端按需推流的直播视频，编号为 1~200000   => live/live1 - live/live200000
   B：wk_live   => 教室端直接推流的直播视频，编号为 200001~... => live/live200001 - live/liveXXXXXXXX
   C：wk_record => 录像记录视频；

8.（已完成）有关在线教育的学习平台升级改造，可以参考 http://study.163.com/，整个用户体验、使用流程、交互界面 都可以参考；

9.（已完成）直播教室的呈现页面进行调整，加入房间号的功能，在醒目的地方加入直播间号码，并对开播时间显示位置进行调整；
   A：（已完成）将课程名称放在最上面，将时间与讲师并列，新增 教室（显示直播房间号）；
   B：（已完成）这个教室号（直播房间号）就是与采集端|教师端关联的唯一关键号码；

10.（已完成）采集端|教师端 可以考虑采用输入房间号的形式，来完成直播间的加入，参考目前主流的直播网站的方式，需要进一步的分析与思考，看看怎样才更好一些；
    A：（已完成）研究了一下斗鱼直播，斗鱼直播伴侣和obs是一样的功能，界面不同，内核有些差异，主播大多用obs，因为换平台不用换软件，虽然伴侣用起来更简单，连直播地址都不用输入；
    B：（已完成）每一个主播都需要申请一个房间，分配一个房间号，http://www.douyu.com/xxxx，直接可以进入主播的直播间，观看直播；
    C：（已完成）ios手机直播可以直接通过投屏到PC端，PC端再通过捕屏直播，也可以使用app通过获取镜像模式，直接直播；安卓也可以通过手机投屏的方式进行直播；
    D：（已完成）因此，房间号很重要，是链接 采集端+老师端+网页端 的核心纽带；采集端和教师端都需要加入同一个房间才能进行交互；

11：（已完成）通过云教室后台，将 采集端 加入到 直播间，而不是通过 采集端 自己加入，这样就能简化采集端软件的操作流程，将复杂度留给网站处理；
    A：（已完成）采集端 也要新增一个操作按钮 => 绑定直播间 => 将采集端挂在某个wk_live上面；这样两边都可以自主操作；
    B：（已完成）采集端 点击“绑定直播间”，弹出已有的直播间列表，选择一个加入其中；
    C：（已完成）采集端 在“绑定小程序”右侧，新增“绑定直播间”按钮；
    D：（已完成）采集端 新增 CDlgRoom 对话框，可以列出所有的直播间，并选择一个直播间加入其中；

12.（已完成）改造 媒体源 为 学生互动 => 枚举所有当前教室里的采集端上的有效IPC列表，
    A：（已完成）改造媒体源的界面，只留下一个ListView控件，专门显示讲师端登录的云教室上，已经挂载的采集端上的IPC列表；
    B：（已完成）网站端只查询采集端上正在运行的通道列表，采集端上没有运行的通道不显示；
    C：（已完成）显示在线摄像头列表，选择一个，获取rtmp地址，在主窗口中显示出来；
    D：（已完成）需要让“互动教室”保持在线状态；
    E：（不处理）需要对ffmpeg_source访问失败时的处理 => 将camera_id和player_id复位 => media_stopped()
    F：（已完成）ffmpeg_source属性框双击关闭属性框，属性窗打开后，自动定位到当前正在运行的记录行；

13.（已完成）新增 LoginWindow 窗口，处理 loginLiveRoom 和 logoutLiveRoom 事件。
    A：（已完成）Teacher端必须先加入一个直播间Room之后，才能开始直播，没有加入房间之前不能开始直播，一个房间只能有一个Teacher端在线；
    B：（已完成）Teacher端必须在主界面启动前就要选择房间；使用curl机制，跟采集端机制保持一致；
    C：（已完成）Teacher端尝试了QT搭建漂亮界面的功能，确实比MFC创建界面方便多了，而且效果比MFC强100倍；
    D：（已完成）绘制圆角窗口，需要在paintEvent()中创建圆角矩形addRoundedRect()，再用QBrush填充；使用样式表设置圆角矩形不起作用；
    E：（已完成）还有一种办法是：用png的透明作用，来设置圆角矩形；设置窗口或控件的字体、颜色，使用样式表比较方便；
    F：（已完成）obs-studio/global.ini中新增配置 General:LiveRoomID|LiveRoomKey|LiveRoomServer，保存已登录的云教室号码与直播地址，做为中转；
    G：（已完成）obs-studio/basic/profiles/default/service.json中更新云教室直播地址配置，在主窗口创建过程中；
    H：（已完成）wk_live当中新增讲师端在线标志status，讲师端登录或退出都需要更新这个标志；
    I：（已完成）登录成功，自动获取直播地址，自动更新配置文件service.json

14.（已完成）云教室老师端动态截图功能有点问题，NV12不能存盘，需要转换成YUV420，但是图片清晰度失真，I420输出，系统提示有转码问题，后续还要调整；(格式参数输入问题)
    A：（已完成）使用ffmpeg的sws_getContext()|sws_scale()，输入源需要格式AVPixelFormat，不能写成video_format，否则会造成的格式错位问题...
    B：（已完成）改成 libyuv 转换后，也能正确转换，但是需要自己判断不同像素调用不同接口，还是太麻烦，最终还是使用sws来转换；
    C：（已完成）修改 jpg 的保存质量 => qcompress => https://blog.csdn.net/zhoubotong2012/article/details/79342116
    D：（已完成）总算彻底、完美的解决了NV12格式直接生成jpg文件的问题，详见 => libobs\media-io\video-io.c

15.（已完成）开始推流之后，直播通道每隔2分钟自动截图并自动上传；
    A：（已完成）将截图自动存放在 obs-studio 目录下面 => os_get_config_path()
    B：（已完成）自动每隔2分钟覆盖截图，命名为 live_2000XX.jpg
    C：（已完成）创建自动上传线程，自动连接存储服务器；

16.（已完成）进行编译、发行、打包 等外围工作；
    A：（已完成）完成 老师端 的打包工作；
    B：（已完成）完成 采集端 的打包工作；
    C：（已完成）修正 采集端 配置存放位置，与 Teacher 端一致；
    D：（未完成）后续 采集端 还有一些本地写入的文件Logger.txt，mplayer启动运行时需要写入的文件；

17.（已完成）Teacher端在64位独立主机上运行的问题；
    A：（已完成）jpg背景图无法显示的问题，估计是缺少组件 => imageformats/qjpeg.dll
    B：（已完成）gif背景图无法显示的问题，估计是缺少组件 => imageformats/qgif.dll
    C：（已完成）为什么没有默认的电脑输出声音这个数据源，是由于电脑的默认音频输出有关；
    D：（已完成）为什么窗口捕获永远是针对桌面，不能针对单独的窗口进行 => load_graphics_offsets: Failed to start 'get-graphics-offsets64.exe'
    E：（已完成）64位系统要调用64位的钩子函数，否则，无法捕捉窗口；尝试编译一个64bit的版本；_WIN64是在系统默认的配置，不是在工程设置当中；
    F：（已完成）64位系统安装32位的Teacher没有问题，是由于跟TeamViewer混用之后，截屏递归造成的 => init_hooks 调用get-graphics-offsets32.exe和get-graphics-offsets64.exe，两个进程；
    F：（未完成）如何解决Teacher端的内存泄漏问题？

18.（已完成）开始尝试在win32系统下，编译obs的64bit版本，使用msvs2015，在 192.168.1.19 I3主机上安装
    A：msvs2015 => F:\迅雷下载\VisualStudio，安装 QT VS Tools 
    B：qt5.8.0  => E:\Qt\qt-opensource-windows-x86-msvc2015_64-5.8.0.exe
    C：cmake    => E:\cmake\cmake-3.11.2-win64-x64.zip
    D：obs-deps => E:\obs-deps\dependencies2015.zip

2018.04.01 - 2018.04.30
=========================================================================
1.（已完成）有关“采集端”与“节点网站”的注册说明：
   A：（已完成）“采集端”由于有唯一的MAC地址做标记，无论怎么删除重装，在myhaoyi.com当中都只有一条记录；
   B：（已完成）“节点网站”由于没有硬件标记，而是自己生成的标记，因此，只要数据库删除重装，又会生成一条新的节点记录。
2.（已完成）在寻找演示视频的时候发现jwplayer的演示栏有很多值得参考的东西：
   A：（已完成）要做一些全方位的展示功能，参考jwplayer的操作方式去实现；
   B：（已完成）全部演示 => https://developer.jwplayer.com/jw-player/demos/
   C：（已完成）电视墙   => https://developer.jwplayer.com/jw-player/demos/innovation/click-to-play/
3.（已完成）云录播、云监控的“实时栏”修改成“在线巡查”或“在线巡课”，可以多分屏显示；并能控制每个分屏的显示；
   A：（已完成）在“直播”栏后面，新增“巡课”栏；
   B：（已完成）“巡课”栏界面完全参考jwplayer的电视墙模式，按照交错规律排列直播通道墙；
   C：（已完成）“巡课”排列顺序按照直播通道创建时间倒序排列，不要改变顺序，否则，就要记录顺序；
   D：（已完成）“巡课”页面，鼠标放上去显示通道详细信息，点击播放之后，右上角显示关闭按钮；再次点击其它任意通道，本通道关闭，播放当前点击通道；
   E：（已完成）云录播当中的名称是“巡课”，云监控当中的名称是“巡查”；
   F：（已完成）云录播当中的更改应用到云监控当中；
   G：（已完成）由于IE8不支持flex模式，电视墙模式不兼容IE8（已经兼容IE8）；
   H：（已完成）在图片懒加载过程中，可以支持background-image模式，具体参见页面；
   I：（已完成）在图片懒加载过程中，可以支持加载前等待，加载后关闭等待，具体参见页面；
4.（已完成）chrome浏览器被劫持，在某些网站上会注入脚本，总是会点击广告，后来将chrome整个卸载，并将AppData\Local\Google整个删除，重新安装才解决了。
   A：（已完成）后来又发生了一次，这次发现DNS被串改，应该是木马修改的，木马可能是漏洞未修复造成的，用360修补了144个漏洞。
5.（已完成）采集端的通道控制是通过网站端来控制的，目前是默认256路，估计要改成默认9路；
6.（已完成）后台可以设定录像回滚周期，即：只保留多少天的视频录像；
   A：（已完成）后台统一配置，自动应用到每个通道的录像当中；
   B：（已完成）事件触发设置在采集端上传视频之后，自动检测设定的间隔周期，删除该通道下所有超过周期的录像。
   C：（已完成）数据库 haoyi|monitor 的 wk_system 表中新增 web_save_days 字段；
   D：（已完成）系统设置，新增“录像保留”天数，默认0永久保留；
7.（已完成）“巡课”、“巡查”在IE8当中的显示兼容性问题。
   A：（已完成）不采用flex，使用layui的栅格模式，IE8兼容background-size
8.（已完成）直播管理 新增 查看播放地址功能；
9.（已完成）后台导航栏新增 跳转前台 功能；
10.（已完成）播放页面video-js，双击全屏；
   A：（已完成）https://github.com/ctd1500/videojs-hotkeys，这是videojs的一个插件，支持双击全屏；
   B：（已完成）利用这个插件的源码进行单独的双击全屏修改；player.on('dblclick', function(event){});
   C：（已完成）flash模式下，无法响应dblclick只能响应mousedown，详见 => http://stackoverflow.com/questions/1444562/javascript-onclick-event-over-flash-object
   D：（已完成）flash模式下，IE8的全屏功能无效，目前没有好的解决办法；
11.（已完成）云录播的系统设置 新增 “教学管理”、“学校”、“科目”、“年级”、“教师”、“职称”可修改名称；
   A.（已完成）教学管理 新增"职称"栏；新增"职称"数据表；
   B.（已完成）新增直播墙名称自定义字段name_tour；
   C.（已完成）优化wk_system内容，只留一份代码；
12.（已完成）完成了《直播教室-设计.docx》，目录 => E:\GitHub\HaoYiYun\Document\方案
   A：（已完成）就是一种直播课堂方案，老师在北京上课，学生通过网络投影观看学习；
   B：（已完成）开源的obs能够完全满足要求，需要改进，涉及到 VS2015|QT|cmake；在itellyou上下载vs2015安装；professional_2015_x86_x64 => F:\迅雷下载\VisualStudio
   C：（已完成）有关obs的详细编译过程，https://blog.csdn.net/gengxt2003/article/details/79070741
   D：（已完成）清华大学开源软件镜像站，https://mirrors.tuna.tsinghua.edu.cn/
13.（已完成）云录播 网站升级注释写成了 云监控 的升级注释；
14.（已完成）采集端 新增了世纪葵花的400电话；
15.（已完成）前端播放页面，新增 评论、分享、点赞功能，参考YouTube的页面设计；
   A：（已完成）评论、录像、通道，三种内容会有 赞、踩 次数；
   B：（已完成）新增 wk_zan|wk_comment 表，评论记录有父节点；
   C：（已完成）添加平路、评论回复、评论删除、回复删除；
   D：（已完成）直播没启动，评论区无法触发刷新事件，在error_page当中做特殊处理；
   E：（已完成）云监控 播放页面的录像按日期选择功能还没有完成；
16.（已完成）升级版本为1.3.3
17.（已完成）有关USB高清摄像机的信息记录：
   A：优点 => 免驱、免采集卡、模拟COM口（免云台控制线），给的软件据说是为了模拟COM口用的；
   B：缺点 => 对机器的配置要求较高，CPU占用高；
   C：云台控制标准协议 => VISCA、PELCO-D、PELCO-P，都是通过RS232串口通讯；USB可以模拟串口，也能实现云台控制，可以免去串口线；会议摄像机里面用的多；
   D：还有一种云台控制协议 PTZ，通常通过 ONVIF 协议控制，目前在海康监控摄像头里面用的多；PTZ应该是网络协议，其它的是串口通讯协议；
   E：这样，就能通过自己的软件实现全部的云台操作，所以，使用USB模式的摄像机非常有必要，完全没有必要采用HDMI+高清采集卡的方式；
   F：实物展台可以采用定焦摄像头，没有必要采用20倍变焦的摄像头；
18.（已完成）obs的源码分析文章：
   A：（已完成）第一篇 => https://cloud.tencent.com/developer/article/1004548
   B：（已完成）第二篇 => https://cloud.tencent.com/developer/news/51525
   C：（已完成）第三篇 => https://blog.csdn.net/laohuangniu/article/details/70313303
19.（已完成）obs调试过程中的问题总结：
   A：需要将vsbuild\rundir\Debug\bin\32bit的内容全部拷贝到vsbuild\UI\Debug，才能调试，修改编译目录的方式无法设置调试断点；（这种方式调试起来麻烦，后面改进了）
   B：https://blog.csdn.net/laohuangniu/article/details/70313303，这篇文章讲解了test工程运行中的问题，这个工程很重要，通过它来不断改进，将obs的功能体现出来，但不用obs的界面；
   C：现在的关键是完成界面和数据采集功能；
   D：调试win-test成功，现在需要建立一个vs2015的工程，对话框的形式，建立场景、显示窗口等等，搭建雏形；
   E：调试模式需要设定特殊的模块目录，obs-windows.c:module_data:"../../data/obs-plugins/%module%"
   F：需要利用obs实验出虚拟画布功能，不要显示黑色的画布，然后，隐藏屏幕流，就能实现最初的设想；
   G：需要改变思路，不要违背obs的核心思想，顺着obs的思想走，对界面进行调整；固定数据源；不断优化使用体验；
20.（已完成）根据对obs的全新认识，顺着obs的思路，重新调整方案：
   A：（不完成）使用左侧设定一个基于桌面的画布窗口，右侧仍然是对话框形式的浮动界面，所有的操作都针对左侧画布窗口；（对obs改动太多，得不偿失）
   B：（不执行）需要解决显示器隐藏的情况下，仍然捕获桌面内容，进行压缩、上传、录像；现在的obs只要预览不显示，就不会处理数据；（这种思路不现实）
   C：（已完成）使用QT搭建界面，有利于直接将obs的界面使用到自己的软件当中；（直接在obs里面进行界面代码和内核代码调整）
   D：（已完成）画布大小就是显示器桌面大小，锁定显示器捕获，画布窗口里的元素：最底层是一个显示器捕获+老师摄像头+展台摄像头+互动学生摄像头；
   E：（已完成）第一步是需要解决当前obs编译调试的问题，而不是每次编译相关dll都需要拷贝到UI/Debug目录下；
   F：（已完成）直接在rundir/Debug/bin/32bit下运行，应该是编译目录设定有问题，造成无法设置调试断点；
       C:\Users\Jackey\AppData\Roaming\obs-studio
       Output Directory => E:\obs-studio\vsbuild\rundir\Debug\bin\32bit
       Intermediate Directory => E:\obs-studio\vsbuild\UI\obs.dir\Debug
       Debug Command => E:\obs-studio\vsbuild\rundir\Debug\bin\32bit\obs32.exe
       Working Directory => E:\obs-studio\vsbuild\rundir\Debug\bin\32bit\
       注意：调试目录与工作目录保持一致，否则dll无法加载；
       注意：obs本身在编译完成之后会执行post脚本，会把obs32bit.exe发送到vsbuild\rundir\Debug\bin\32bit，因此Output Directory可以不动，Teacher工程才需要修改；
   G：（已完成）重点研究obs-ui，使用QT重组界面，完全不用以前的代码，就是将obs界面代码进行简单重组，现在的obs编译版本全部达到了预期的需要。就是对界面进行重组。
   H：（已完成）obs的目录结构：
      bin -> 32bit -> obs32.exe     => 界面和模块编译后的动态库
      data -> libos|obs-plugins     => 模块和插件用到的数据
      obs-plugins -> 32bit -> *.dll => 插件编译后的动态库
   I：（已完成）VS2015需要安装扩展组件，新建一个QT界面的工程，obs是利用cmake外挂编译了QT模块，可以直接调试，新建的工程，必须与QT绑定，重新绑定编译才行；
      Tools => Extensions and Updates => Online => QT VS Tools
   J：（已完成）.ui是QT生成的页面配置文件，可直接编辑，编译时会自动生成ui_xxx.h文件，.qrc是资源配置文件；QT工程会新增一些配置项，会提前预编译一些文件，然后供vs2015使用；
   K：（已完成）成功将Teacher用obs的界面编译完成，现在需要进一步对界面进行调整；
   L：（已完成）重新在E:/obs-studio创建目录，从https://github.com/HaoYiTech/obs-studio上拉取数据；
   M：（已完成）需要对QT的界面设计器进行系统学习，要不然后续针对obs界面改造会非常费劲；
      https://blog.csdn.net/a10929/article/details/78114261
      https://blog.csdn.net/GoForwardToStep/article/details/53792702 => QQ风格窗口
      https://blog.csdn.net/goforwardtostep/article/details/53494800 => 自定义窗口
      https://blog.csdn.net/goforwardtostep/article/details/77825598 => 有关布局的
      https://blog.csdn.net/goforwardtostep/article/details/52085030 => 有关信号槽
      https://blog.csdn.net/zhuyingqingfen/article/details/44019915  => QT小技巧
      https://blog.csdn.net/iaccepted/article/details/24426875
      https://www.cnblogs.com/sfy5848/p/4835458.html
   N：（已完成）可以参考的obs界面，陆续增加中：
      https://github.com/Bilibili/biliobs
      https://github.com/alibaba/tblive
21.（已完成）对obs界面的修改操作：
   A：（已完成）隐藏scenesDock|transitionsDock，设置sourcesDock|mixerDock最小尺寸为(300,200)
   B：（已完成）修复预览开启与关闭菜单项，修改图标，修改标题名称；setStyleSheet("QListView::item:selected {background: #4FC3F7;}")，设置选中条背景色；
   C：（已完成）修改 默认语言环境从 en-US => zh-CN；优化右键菜单，删除一些无用的，去掉“滤镜”“交互”，保留“属性”；
   D：（已完成）修改 来源 => 数据源 - 将多种图层混合输出，混音器 - 将所有音频混合输出，通过修改UI\data\locale\zh-CN.ini => data\obs-studio\locale\zh-CN.ini 完成；
   E：（已完成）修改 添加 => 添加(源)，重命名 => 重命名(源)，移除 => 移除(源)；
   F：（已完成）修正 右键菜单 重命名 对来源名称的修改错误；SourceItemNameEdited()当中currentItem有可能不是selectedItems
   G：（已完成）去掉 自动更新升级功能；EnableAutoUpdates，去掉自动日志上传功能；UploadLog()；profile_data没有去掉，可以跟踪运行状态；
   H：（已完成）开启 状态栏，显示在窗口底部；预览窗口的缩放方式有问题，没有安装配置的方式显示，造成操作问题；fixedScaling强制锁定；
   I：（已完成）解决停靠栏右键菜单显示问题；选择CustomContextMenu项就行，构造void on_xxx_customContextMenuRequested(const QPoint &pos);会自动响应右键菜单事件；
   J：（已完成）点击关闭之前，弹框询问，不要直接关闭程序；OBSBasic::closeEvent(QCloseEvent *event) => event->ignore();
   K：（已完成）进程关闭之后，窗口界面的配置信息没有存盘 => 需要打开OBSBasic::Save()之前屏蔽的代码；SceneItem就是SourceItem；
   L：（已完成）启动两个进程时的报错处理过程，有问题，需要修正；
   M：（已完成）第一次启动，修改默认的配置目录和名称为 default ，以前是中文的“未命名”，界面主题采用 Default，不要采用 Dark；
       MakeUserDirs() => 创建大量默认的配置目录信息；
       InitGlobalConfig() => 创建 obs-studio/global.ini
       MakeUserProfileDirs() => 创建用户信息配置目录
       去掉自动向导配置功能，全部采用手动配置...
   N：（已完成）需要解决obs-studio/plugin_config里面隐藏访问的问题，跟加载模块相关，已经去掉了不常用的模块；
   O：（已完成）有四种资源类型 => obs->source_types => OBS_SOURCE_TYPE_INPUT | OBS_SOURCE_TYPE_FILTER | OBS_SOURCE_TYPE_TRANSITION | OBS_SOURCE_TYPE_SCENE
       enc-amf | obs-browser | obs-vst | libdshowcapture => 这几个扩展模块是子工程，需要单独下载，否则，不会生成工程文件；
   P：（已完成）开启数据源的 添加 | 修改 | 删除 功能；
       “添加”功能，CreateAddSourcePopupMenu()，有两个地方弹出菜单 => 预览右键 | 停靠栏点击加号；一个模块dll中可能包含一种资源类型，但可包含多种资源；
       “添加”功能，数据源数量就是扩展模块数量 => obs->input_types => obs_register_source_s(OBS_SOURCE_TYPE_INPUT) => obs_load_all_modules => obs-plugins\32bit
       “添加”功能，只保留有限的几种数据输入源 => 视频捕获设备 | 显示器捕获 | 窗口捕获 | 音频输入捕获 | 媒体源，禁用game_capture|wasapi_output_capture => obs_enable_source_type()
        删除image_source.dll(有3个数据源)，删除test_input.dll(有5个数据源)，删除text_freetype2.dll(有1个数据源)，删除obs_text.dll(有1个数据源)
   Q：（已完成）新增 网络流 数据源 => 直接使用“媒体源”的网络流就可以，内核是ffmpeg，本身就是支持rtmp|flv|hls|rtsp数据流；就可以不用费劲去加载vlc-video.dll（牵涉大量工作）
   R：（已完成）注意：工程重新编译时，会对locale资源进行重新拷贝到data目录下，需要提前做好备份工作或直接修改UI\data\locale下的zh-CN.ini文件；
   S：（已完成）新增 双击数据源预览框 全屏投影 功能 => OBSQTDisplay::mouseDoubleClickEvent() => OpenSourceMonitor()
      （已完成）修改 双击数据源预览框 移至顶部 并 拉伸至全屏功能，而不是全屏投影，因为，全屏投影并不会反应在实时的直播画面当中，只是全屏在投影预览当中 => OBSBasic::DoDisplayDbClicked()
   T：（已完成）修改 数据源预览框 的缩放方式，目前只能按等比例缩放，看看能否修改成任意比例的缩放；每一个数据源都可以配置transform变换参数，开启变换对话框界面 => OBSBasicTransform.ui
   U：（已完成）新增 按钮控制 停靠栏 => 开始直播（自动录像mp4）| 常规配置（输出窗口大小等等基本配置信息，还是在原有界面上进行简单的调整）
   V：（已完成）新增 统计信息 按钮 => statsButton 与 statsAction关联；
   W：（已完成）修改 开始推流 背景色 和 按钮高度 => setStyleSheet("QPushButton{background-color: #FFA500; height: 35px; font-size: 20px; color: black;}");
   X：（已完成）修改 ffmpeg_source 时的资源界面，OBSPropertiesView，通过资源属性来动态创建窗口对象；
       现在，需要隐藏文件模式，只留下一个QListView框，写入在线采集端摄像头列表，每一个Item就是一个rtmp链接地址，就是一个动态获取流地址的界面；
       OBSBasicProperties当中，隐藏preview对象，隐藏文件模式，始终用非文件模式；ffmpeg_source_defaults() => is_local_file => false;
       需要新建一个ListView，选择Item之后，直接找到对应的obs_property_t，赋值即可 => obs_data_set_string() => RefreshProperties()
22.（已完成）开始 edu.ihaoyi.cn 的开发设计当中：
   A：（已完成）创建新的目录 => E:\GitHub\HaoYiYun\educate，对应 monitor|recorder，创建新数据库 educate；
   B：（已完成）搭建网站雏形 => 云教室 | 手机 | 登录
   D：（已完成）云教室(直播)元素 => 房间(wk_room)，课程(wk_lesson)，讲师(wk_teacher)，直播(wk_live)
       新建 wk_room 表，用来记录云教室(直播教室|招评标室)的内容，是跟物理房间或教室对应的；
       新建 wk_grade 表，用来年级相关记录信息；放在lesson当中；
       新建 wk_subject 表，用来记录科目(项目)的总体信息；放在lesson当中；
       新建 wk_lesson 表，用来记录具体科目生成的课程的内容；
       新建 wk_teacher 表，用来记录开讲老师的信息；
       新建 wk_live 表，用来记录实际直播内容表，推流地址固定，创建直播之后会随机生成一个，实际展示的云教室记录内容；
   E：（已完成）{{$vo.start_time|strtotime|date='m-d H:i',###}}，可以连续用两个函数参数；
   F：（已完成）开始搭建播放页面，新增针对直播教室的 赞|踩|评 功能，0(camera_id)，1(record_id)，2(comment_id)，3(live_id)
   G：（已完成）为了保持与原有机制的兼容，需要对中转服务器进行改造，200000以前的都是camera，200001以后的都是live(20万做为分界线)
   H：（已完成）赞|踩|评，有关“删除”界面的显示有问题，任何已登录都可以删除评论，只有创建者才能删除评论；
   I：（已完成）开始 show 页面的核对与完善工作；后续，还要将show里的错误处理机制进行优化处理；

2018.03.01 - 2018.03.31
=========================================================================
1.（已完成）中心服务器支持“浩一云”和“浩一云服务”两个小程序的接入处理；
   A：（已完成）“浩一云”恢复成可接收回看直播数据的功能；
   B：（已完成）“浩一云服务”只提供采集端设备管理的功能；
2.（已完成）中心服务器的 MiniAction.class.php 解除绑定接口有两个调用方向：
   A：（已完成）小程序 => MiniAction.class.php => unbindGather => 需要调用中转服务器接口 => 到达采集端...
   B：（已完成）采集端 => MiniAction.class.php => unbindGather => 只进行数据库处理，不调用中转服务器，否则会引发混乱；重复开启线程引起崩溃；
   C：（已完成）采集端 => doWebUnBindMini => /wxapi.php/Mini/unbindGather/gather/1
3.（已完成）有用的矢量图标库 => http://www.iconfont.cn/
3.（已完成）css/js/php资料好 => http://www.php.cn/
4.（已完成）口袋动画PA插件 => http://www.papocket.com/
5.（已完成）解决了采集端是无线网卡无法获取MAC地址的问题；
6.（已完成）mysql修复数据表的方法：
/weike/mysql/bin/mysql -h 127.0.0.1 -u root -p haoyi
repair table wk_camera;
repair table wk_camera USE_FRM;
7.（已完成）MacBook上的“拖移锁定”通过“辅助功能”打开，就能单指双击锁定。
8.（已完成）用新的虚拟机安装一遍云录播，看看是否出现wk_camera损坏的问题。
   A：（已完成）确实存在wk_camera损坏的问题，需要更新打包软件。
   B：（已完成）数据库haoyi->wk_camera与monitor->wk_camera都损坏了。
9.（已完成）安装脚本中新增 libgomp 服务器CentOS6.8最小化安装时需要。

2018.01.31 - 2018.03.09 => 有关小程序开发、审核的记录
=========================================================================
1. 2月2日，小程序第一次审核失败，在线教育，里面放了文娱视频，需要去掉，再放上一个在线教室；
2. 这两天仔细阅读了开发社区的帖子，发现小程序的审核非常严格，目前有很多禁区，基本总结如下：
   A：类目问题：很容易撞红线，具体类目的细节根本无法解释，只能凭感觉；很多类目都需要特殊的认证材料；
   B：不能有UGC内容：指的是不能通过小程序产生UGC内容，比如：评论、通过小程序上传等等，但可以在网站后台添加，小程序刷新内容；
   C：不能有诱导分享内容：小程序展示页面不能有任何二维码，不能引导用户下载其它APP或依赖其它程序（这一点需要验证）；小程序页面涉嫌及诱导：关注，分享，星标，下载等功能
   D：与审核人员交流渠道：建议将测试信息存放在云盘，并将云盘链接及账户密码提供到小程序【版本描述】处以供审核同学参考。
   E：每次审核提交后，在一段随机时间内，会触发小程序的真机测试程序，会让一台真机（通常是安卓）联机测试提交的小程序，基本上会覆盖所有的页面和按钮，截图保存，审核人员通常都是靠这些截图来进行人工审核和判断；
   F：这种自动测试机制，跟在开发环境中申请测试的效果基本一致，只不过申请测试时会随机安排5到6台真机测试，并提供每台机器的覆盖页面截图等详细信息；审核自动测试可能会加重测试力度，截图估计会更细一些；
   G：想想也是，每天都有大量的小程序提交审核，如果每个审核员都打开手机运行一下进行测试判断，效率太低，根本就不可能，只能是看一些现成的截图，来进行判断；更不会去审核代码，那更是一个不可能的工作；
   H：所以，一定要重视每次提交前的自动测试，再结合审核禁忌，有意避开，确认无误之后再提交；必要时，可以在网站后台做一些操作，不让审核人员看到一些敏感词，等审核通过之后再将服务器代码修改回来；
   I：目前，就是为了避免让审核看到“我的通道”里面的下载采集端字样，让所有人的采集端都一样，都有通道显示，等审核通过之后再改回去；
   J：不能有“分享到朋友圈”按钮，否则，会被投诉“诱导分享”；
   K：即使“浩一云”小程序上线了，将来也极有可能被竞争对手或恶意用户投诉：与服务类目不符，造成下架风险；
   L：根据目前来看，小程序 也只能做为一个宣传的噱头，运营的风险太大，要特别注意“共享通道”的问题；
   M：小程序不能“虚拟支付”，什么是虚拟支付：这个概念随时在变，以前没有开放游戏时，游戏币就是虚拟支付，开通会员包月观看不知道算不算虚拟支付？付费购买虚拟商品属于虚拟支付。付费观看图片，涉及虚拟支付，属未开放类目内容。
   N：一个微信官方审核人员的微信号：nomorehu
3. 如果最新提交的小程序审核通过，新版的小程序需要增加的功能如下：
   A：（未完成）完善通过扫描采集端二维码绑定小程序的流程；
   B：（未完成）在live播放窗口下方，增加“弹幕”和“回放”两个标签，并可以根据服务器对通道的配置，决定是否显示，即“弹幕”和“回放”是受服务器配置控制；这是服务器产生的UGC，而不是小程序用户产生的UGC，不提供评论入口和录像入口；
   C：（未完成）为了避免“共享通道”被用户滥用，需要在wk_track当中加入一个审核字段，只有通过审核的通道才能对外共享，只能共享互联网通道，用户在“我的通道”里点击“共享”后，会有等待审核字样；
   D：（未完成）小程序管理员会收到一个模版消息，打开之后，决定是否运行共享，同时，也能在模版消息中随时关闭共享；就是将审核字段设置成0或1；在这个等待过程中，用户可以停止共享，共享记录会被删除；
   E：（未完成）“共享通道”页面，可以直接在任意通道上点击分享按钮，转发给微信好友；也可以点击右上角分享整个页面；
   F：（未完成）“我的通道”页面，可以直接在任意通道上点击分享按钮，转发给微信好友；不可以点击右上角分享整个页面，这是个人的通道管理页面；分享个人通道时，即使是局域网的通道也可以分享出去；
   G：（未完成）“关于我们”页面，增加转发功能；
   H：（未完成）“直播播放”页面，参考之前记录的 IT大咖说 截图，显示正在观看的用户数，也可以参考 微信电竞 的模式；
   I：（未完成）“直播播放”页面，视频下方的视图选用scroll-view，可以局部滚动，而不是跟随整个视频窗口滚动；
   J：（未完成）“我的通道”页面，共享按钮受服务器端采集端配置限制，wk_gather新增字段，是否开启共享功能，不开启，显示拥有者头像和名字；
   K：（未完成）“共享通道”、“我的通道”，不要显示流类型的名称，只显示图标和通道名称，不要给用户莫名的感觉；
4. 2月6日，小程序第二次审核失败，工具/图片/音频/视频 涉及文娱视频，请登记类目；
   A：因此，去掉了工具/图片/音频/视频 类目，只留下在线教育；
   B：同时，将小程序简介也进行了修改，只留下跟在线教育相关的信息：在线课堂分享，远程网络教学。
   C：经过这两次，觉得小程序这种严格审核机制，估计是难以通过审核的，因为，涉及到文娱视频；
   D：如果第三次，还是无法通过审核，那就去社区提交申诉（估计要到年后了）；
   E：如果申诉后，仍然无反应，还是给出涉及文娱视频，那估计就没戏了，小程序这条路无法走通；
   F：现在就要早做打算，对小程序无法走通的应对处理，采集端的应对（屏蔽绑定），网站的应对处理（屏蔽小程序入口）；
   G：03.14，由于“浩一云服务”审核通过，重新打开网站前端的小程序入口二维码；
5. 社交-直播类目需要的资质：《信息网络传播视听节目许可证》或《网络文化经营许可证》(经营范围含网络表演)
6. 文娱-视频类目需要的资质：《信息网络传播视听节目许可证》或《广播电视节目制作经营许可证》
7. 2月8日，如果在线教育的直播播放无法审核通过，可以考虑不带播放视频的小程序，用于管理采集端；做最小的改动；
8. 2月9日，跟预期一致，再次审核失败，始终判断目前提供的内容含直播，涉及视频，要求补充选择文娱-视频类目；
   A：因此，必须采用新的思路，去掉所有涉及直播、视频的代码，就是改造live页面，重新提交审核；
   B：赶在10日之前提交，争取在春节前再审核一次；
9. 2月11日，第4次审核失败，还是提示：目前提供的内容含直播，涉及视频，请补充选择文娱-视频类目；
   A：删除了“共享通道”、“我的通道”、“播放页面”，将“我的采集端”放到首页；
   B：变更类目为：工具 => 信息查询，再次提交审核，估计要到年后2月23日之后才会有审核结果；
   C：如果还是无法审核通过，就需要换一个小程序，继续提交，还是以公司名义提交小程序，在制作之前多看一些类型的小程序作为参考；
   D：鉴于目前对直播类小程序的严格审核，将小程序的定位从播放终端，改变成采集终端管理工具，绑定采集端、线上支付，是工具，而不是播放器；
   E：尝试申请两个小程序：云监控(无法申请)、云录播(正在名字审核)，思路都一样，把小程序当成采集终端管理工具，而不是播放终端；类目：IT科技 => 硬件设备
10. 2月23日，第5次审核失败，还是提示：目前提供的内容含直播，涉及视频，请补充选择文娱-视频类目；
   A：可见，只要被打上了烙印，怎么修改都无济于事，只能废掉，另开一个新的小程序；
   B：因此，第一次提交的小程序非常重要；
11. 3月9日，重新申请了“浩一云服务”的小程序，只提供采集端绑定业务功能，并提交了审核申请；
   A：重新创建小程序的策略成功，3月10日一早就通过审核，神速；
   B：下一步可以考虑在这个基础上逐渐新增功能，始终围绕采集端设备来思考，不要进行直播播放，可以围绕通道管理进行；

2018.02.01 - 2018.02.28
=========================================================================
1.（已完成）采集端：需要防止一台机器启动多个实例的问题，否则，用户在请求播放时，无法定位到对应的采集端；
2.（调整思路）需要在网站后台，新增“升级服务”栏目，比对当前版本与服务器版本的差异，显示升级报告，单个文件升级或整个升级；主要针对网站和数据库升级；
   A：（换思路）升级服务当中，可以新增一个查看日志的功能；
   B：（换思路）升级服务当中，可以新增一个删除缓存的功能；因为数据库或php更新后，可能会造成字段或页面显示问题；
   C：（换思路）中心服务器 新增 swoole伺服服务器，用于节点服务器交互，节点服务器也用swoole建立连接；
   D：（换思路）中心服务器 新增 /weike/htdocs/swoole.php 监听端口 20002 ，处理异步升级、小程序异步反向通知；
   E：（换思路）mysql数据库文件 => *.frm是描述了表的结构，*.MYD保存了表的数据记录，*.MYI则是表的索引
   F：（换思路）在节点网站，新增 系统升级 异步列举所有模块本地版本与服务器版本，表格形式，最下面新增一个“立即升级”的按钮；
      PHP_VERSION => php 查看版本
      /weike/mysql/bin/mysql -V => mysql 查看版本
      /weike/nginx/sbin/nginx -v => nginx 查看版本
   G：（换思路）这种方式，根本无法实现：php无法重启mysql，无法覆盖文件；
   H：（换思路）系统升级 给出操作步骤和提示，让用户通过脚本去升级数据库和网站；
   I：（换思路）这种方式，最终测试还是不行，新增字段时，表索引文件和数据记录文件都会改变，只覆盖文件会造成数据表无法打开；
   J：（换思路）swoole只适合微信小程序内网通道的观看，对于数据库升级没有任何帮助；
3.（数据库升级最终思路）采用sql语句动态升级：
   A：（已完成）先从服务器中获取表字段的详细信息，Field/Type/Default/Extra/Null/Comment
   B：（已完成）在本地数据库中查找字段是否存在，选择使用 ALTER TABLE `MODIFY` 还是 `ADD`
   C：（已完成）根据需要计算出 Field/Type/Default/Extra/Null/Comment，详见 upDbTable
   D：（已完成）如果本地没有该数据表，选择使用 Create Table 命令
4.（已完成）目前核心的三大块重要工作：
   A：（已完成）完成小程序的第一版本工作，建立起微信账户与采集端的关联关系结构；
   B：（已完成）完成API的接口设计，加入到网站后台当中，用户登录就能测试使用；
   C：（已完成）完成所有重要功能的文档说明，编制文章，有结构有调理的文章，相当于在线使用帮助；
   D：（已完成）完成网站通过后台，动态升级数据库，通过脚本升级网站代码；
   E：（已完成）现在需要根据目前的小程序界面设计，找到需要的界面组件库，完成第一步工作；
5.（已完成）获取小程序码的方法：
   A：（已完成）参考测试代码 monitor/wxapi/Lib/Action/GatherAction.class.php 里的 qrcode() 函数
   B：（已完成）先获取access_token，再获取小程序码，直接返回jpg的图片数据
6.（已完成）华工用户提出的完善功能：对于切片录像，需要一个批量下载界面；
   A：（已完成）可以在播放页面进行处理，点击下载时，弹出下载列表，可以单独下载也可以批量自动下载；
   B：（已完成）采用layui页面，参考数据库升级方式，单独或批量下载；
7.（已完成）网站后台，需要新增查看用户在线观看统计列表，用户历史观看统计的列表；
   A：（已完成）直播服务器 => 列举当前挂载的直播服务器列表，点击查看挂载通道列表；
   B：（已完成）观看用户列表 => 列举当前通道下正在观看的用户详情；
   C：（待完善）已挂载通道列表、观看用户列表的自动分页显示功能，目前是全部显示；
   D：（待完善）观看用户的微信详细信息查看；
8.（已完成）组件管理 => 中转客户端，存在没有列举完所有终端的问题，需要改进，改进成表格模式；
9.（已完成）采集端：需要增加对多屏窗口的操作按钮，例如：每隔16个窗口就自动形成分页功能；可以避免路数太多造成显示窗口太小的问题；
   A：（已完成）可以通过配置文件设置每页窗口个数，最少4个窗口，最大36个窗口，默认9个窗口；
   B：（已完成）翻页之后的焦点处理；
   C：（已完成）跳转页 功能完善；
   D：（已完成）添加/删除 通道时的处理；注意：通过网站的添加/删除操作；
   E：（已完成）左侧树形控件点击之后，需要自动进行翻页定位；
10.（已完成）网站端：采集端表新增两个字段 auto_ipc page_size，可以进行配置；
11.（已完成）网站端：屏蔽小程序扫码入口功能，等待小程序具有播放功能之后再开启；
12.（已完成）需要完成最后的工作：采集端注册中心网站后，显示小程序二维码，等待微信扫码绑定；
   A：（已完成）采集端：改进小程序码的显示流程：不要强迫用户绑定，专门有个菜单按钮弹窗，所有的小程序码都在这个窗口里面处理；
   B：（已完成）采集端：这样原来的流程都不变，还能通过中转服务器实时响应，不用破坏原来的流程；
   C：（已完成）小程序码：分解成两个步骤：通过中心站获取token，通过采集端自己获取小程序码，保存到内存，随时显示；
   D：（已完成）小程序码：在获取token时，参数是gather_id，返回：绑定用户编号、用户户头像、用户昵称、小程序响应页面、access_token、expires_in
   E：（已完成）采集端：每次点击“绑定小程序”时，才会获取token，然后获取小程序码，部分保存到GMConfig当中，最终，根据获取到的数据决定如何显示；
   F：（已完成）采集端：小程序码窗口标题高度23+3=26px，左右留白共3+3=6px；
   G：（已完成）小程序：测试扫码结果页面，可以使用开发工具的条件编译自定义参数 scene=xxxx 进行模拟；https://mp.weixin.qq.com/debug/wxadoc/dev/api/qrcode.html
   H：（已完成）小程序：单行多余字符显示省略号 => overflow: hidden; text-overflow: ellipsis; white-space: nowrap;
   I：（已完成）小程序：多行多余字符显示省略号 => https://www.cnblogs.com/hellman/p/5755376.html，有赞的小程序示例当中好像有多行的示范；
   J：（已完成）采集端：重新梳理了显示流程，都在绘制背景函数里面处理；
   K：（已完成）采集端：新增了“解除绑定”操作按钮；
   M：（已完成）小程序：用户点击“解除绑定”之后的处理 => 不需要调用接口通知采集端，因为采集端自己也会调用，可能引起混乱，需要做区分才行；
   N：（已完成）小程序：用户点击“确认绑定”之后的处理 => 跳转到“个人中心”页面；
   O：（已完成）小程序：用户点击“取消”之后的处理 => 跳转到“个人中心”页面；
   P：（已完成）小程序：wx.redirectTo 关闭当前页面，不会有回退按钮...
   Q：（已完成）小程序：wx.scanCode 在扫描带参数的小程序码时，返回具体数据还不清楚，必须等待小程序发布之后再查看；在“个人中心”的“我的采集端”也有扫码过程；
   R：（已完成）小程序：目前对 wx.scanCode 的处理：判断 path 是否有效，有效就跳转页面 => wx.redirectTo({ url: res.path })；
   S：（已完成）小程序：存在的疑问是 wx.scanCode 扫描带 scene 的结果是放到res.path里面？现在还不确定，需要等小程序发布之后测试；（path里面会带scene参数）
   T：（已完成）小程序：由于路径是 pages/bind/bind，在使用 redirectTo 跳转时需要使用 ../../

2018.01.01 - 2018.01.31
=========================================================================
1.（已完成）http://ihaoyi.cn => 未来的单独运营的节点网站，企业、机关、学校，可以租用云服务的方式，获得浩一云服务，针对它会有单独的运营小程序；小程序名：浩一云
   A：（已完成）http://ihaoyi.cn => 做为“云监控”的对外演示网站；
   B：（已完成）http://demo.myhaoyi.com => 做为“云录播”的对外演示网站；
   C：（已完成）https://myhaoyi.com => 做为中心网站和小程序的交互网站，采集端、节点服务器都需要通过中心网站进行授权；
2.（已完成）采集端的所有配置都放到myhaoyi.com当中，默认都是浩一科技，在OEM授权之后，每次启动都从myhaoyi.com读取OEM配置；
   A：（已完成）这是非核心功能，暂缓执行；如果发生总是无法写入Config.xml的情况，就需要提前实现这个功能；
   B：（已完成）仔细分析这个功能，实现起来还有点麻烦，牵涉到中心网站的授权问题；实现之后的意义也不是很大，暂时搁置；
   C：（已完成）采集端配置全部放到节点网站，对采集端、节点网站，都需要在中心服务器进行授权验证；
3.（已放弃）需要在网站后台，新增“API接口”栏目，用于API的直接测试使用，可以代替帮助文档；
   A：（已完成）直接采用的是“API接口文档”的方式来解决，最简单最方便，放在产品里，容易引起系统不稳定；
4.（已完成）在公网上会发生很多异常的情况，特别是transmit里面会发生假死的情况：
   A：（已完成）transmit目前的处理方式是 gettcpstate ，但还是会发生假死的情况；gettcpstate 不太靠谱，无法有效检测状态，超时检测最靠谱也简单；
   B：（已完成）transmit加入所有链接超时检测机制，目前主要是gather端是长链接，全部采用超时检测机制，即使不是采集端，1分钟还存在的http也应该断开；去掉对 gettcpstate 的检测，没有太大意义；
   C：（已完成）后来发现，不是超时干掉假死连接，而是ForRead错误干掉的，在过了一段时间之后，应该是系统底层发出的删除指令；
   D：（已放弃）因此，最好的办法是在网站后台，组件管理 => 中转客户端，可以手动删除列出的终端列表；
   E：（已完成）使用汇报超时机制来避免假死的问题，没有使用人工干预，手动删除的方式，有点别扭，不够自动化；
5.（已完成）微信小程序音视频解决方案 => https://cloud.tencent.com/act/event/wx-video.html
   A：播放详解 => https://cloud.tencent.com/document/product/454/12519
   B：推流详解 => https://cloud.tencent.com/document/product/454/12518
6.（已完成）2017.12.26，小程序音视频组件升级，可以直接推送和拉取rtmp协议流，大大降低手机端直播延时；
   A：（已完成）前期开放门槛较高，只开放给特定的行业；
   B：（已完成）目前微信小程序可以支持HLS、rtmp、flv，还需要进一步的确认和实验；手机上保留一篇内部采访提到支持flv直播；
   C：（已完成）常青：如果使用 live-player 标签，可以使用RTMP协议和http-flv协议进行接入，也可以使用HLS协议接入，但HLS协议需要使用微信小程序早就开放的<video>标签。
   D：（已完成）亲测，live-player标签，确实可以直接播放rtmp和flv，HLS需要用到video标签；这样使用微信小程序播放，比PC端播放兼容性还要好。
   E：（已完成）在后台新增了 教育->在线教育 类目，顺利开通了实时播放音视频流<live-player>和实时录制音视频流<live-pusher>；在添加类目时，会自动列出需要的资质，“在线教育”没有资质限制。
   F：（已完成）这下好了，手机端可以一步到位的实现低延时观看监控实时直播视频，而且还是两种选择rtmp和flv，这是可以大做文章，加紧宣传的好机会；
7.（已完成）在我的通道当中，需要新增共享操作，以便将拥有的采集端通道共享出来，具体操作是新建一条记录到wk_track当中；只有拥有者才能共享通道；
   A：（已完成）简化读取共享通道的过程 => 每个通道单独从节点调用接口，不要在中心进行优化，太过复杂；
   B：（已完成）共享通道上拉分页显示，累加当前页面，继续请求；
   C：（已完成）共享通道下拉重新获取分页数据，从第一页开始重新刷新；
   D：（已完成）开始多分页的测试当中，上拉、下拉的多分页测试；
   E：（已完成）统一快照截图的显示大小，目前有大有小的显示，通过设定参数搞定：<image mode="widthFix top"></image>
   F：（已完成）image组件的缩放、裁剪混用，样式已经设定210px，裁剪的 top center 没有差别；
   G：（已完成）image组件的lazy-load没有起作用，设定后没有看到效果；
   H：（已完成）下拉刷新时，只把数据清除，不应用到视图里，这样可以防止刷新闪烁；
   I：（已完成）快照截图地址为空时，image并不会触发binderror事件，需要在模版中预先指定snap.png的地址；在模版里加入三元操作符号 => {{item.image_fdfs?item.image_fdfs:'../../images/snap.png'}}
   J：（已完成）共享直播通道点击导航到播放页面，通过连接传递参数，不能传递对象；因此，需要将通道数据转换成json，再通过链接参数传递到直播播放页面，这样就能避免重复的数据库调用；
   K：（已完成）微信接口返回errcode|errmsg，我们的接口返回err_code|err_msg，这样以便区分；
   L：（已完成）对象合并(Object.assign)，数组合并(concat)；
   M：（已完成）直播通道播放页面，直播地址与相关录像是两个API分别请求，不要混在一起，便于管理；
   N：（已完成）直播通道播放页面，将直播切换按钮放在信息栏，避免使用button占用空间；
   O：（已完成）直播通道播放页面，上拉刷新（加载更多录像），下拉刷新（刷新直播通道，只在直播通道没有播放时才刷新，正在播放录像、正在播放直播时不用刷新）；
   P：（已完成）将error和more写入同一个模版文件，并使用了统一的模版样式，在app.wxss里面统一加载，后续会增加更多的模版；
   Q：（已完成）小程序Page扩展功能的方法 => Page(Object.assign({}, Zan, {}))
   R：（已完成）开始直播页面当中，直播回放、录像回放、直播与录像切换的实现；
8.（已完成）开始直播回放时，加入<live-player>组件，低延时直播解决方案；
   A：（已完成）mode="RTC" => 画面抖动，效果差；
   B：（已完成）<live-player>组件，全屏、开始、暂停，需要自己画出来自行处理；
   C：（已完成）<live-player>组件，播放画面在最上层，怎么加入操作界面层？腾讯视频云里面的按钮可以在视频之上；<cover-view><cover-image>能够解决这个问题；
   D：（已完成）需要加入一个时钟，每隔15秒汇报直播播放在线状态，避免推流终止问题；
   E：（已完成）<live-player>组件，没有poster功能，画面黑屏；<cover-image>
   F：（已完成）<live-player>的使用组件化，封装到模版当中；
   G：（已完成）zan-toast的优化，增加<cover-view>属性；
   H：（已完成）<cover-view>在开发工具里面支持FontAwesome，在真机当中无法显示，只能使用<cover-image>，将按钮制作成图片来使用；目前需要四张(play|pause|fullscreen|restore)
   I：（已完成）<cover-image>需要设定width和height才能显示图片，否则无法显示，<cover-view>当中无法支持FontAwesome图标字体；
   J：（已完成）<live-player>在安卓手机上无法播放，提示access denied，重新扫码下载小程序就OK了，估计是之前的小程序版本问题；
   K：（已完成）<live-player>在点击停止之后，由于是rtmp连接，srs会立即断开连接，当用户数为0时，又会触发采集端停止上传，造成小程序再也无法播放；
   L：（已完成）同时，中转服务器，已经对rtmp和hls都要进行超时检测，因此，为了更好的小程序体验，srs不要汇报rtmp用户数为0的情况，全部由中转服务器来决定是否推流；
   M：（已完成）在用wx.createLivePlayerContext创建对象时，始终只创建一个对象，详见 doAPIGetLiveAddr()
9.（已完成）<live-player>的 bindstatechange 事件会出现无法收到通知的情况，造成界面永远卡死，因为，状态都是通过这个事件来调整的。
   A：（已完成）目前的做法只是去掉了bindfullscreenchange这个全屏事件绑定，只留下 bindstatechange 事件；
   B：（已完成）这种做法没有道理，只能进一步观察会不会丢失bindstatechange事件；需要改进；
   C：（已完成）在每次重新进入live页面时会偶尔发生丢失bindstatechange事件；调试模式下发生频繁；
   D：（已完成）改进：在创建live-player成功之后，立即启动一个5秒的超时时钟，用来检测 bindstatechange 是否有效，无效直接停止播放；新增doCheckLiveState；
   E：（已完成）改进：doCheckLiveState 检测的是播放器是否收到2004状态事件，没有收到就直接关闭，这样就能完全解决这个问题；
   F：（已完成）改进：新增m_live_state_timer，记录2004状态检测时钟，点击开始重启启动时钟；点击停止关闭时钟；
   G：（已完成）改进：点击开始，获取rtmp地址，都需要重置 m_live_is_bindstate 状态，启动5秒超时检测；
   H：（已完成）改进：连接中断，重来机制，不要立即重连，等待2秒之后再整个重连，成功率高，效果不错；
10.（已完成）采集端：启动推流时，发现会阻塞主界面，有时会阻塞很久，导致推流中断，在向外网推流时更加频繁出问题；
   A：（已完成）CPushThread::IsRecording() 当中，去掉互斥；这里是主界面调用，使用互斥会阻塞主界面；
   B：（已完成）CPushThread::IsFrameTimeout() 当中，去掉互斥；这里是主界面调用，使用互斥会阻塞主界面；
11.（已完成）小程序开发工具暂不支持rtmp播放，https://developers.weixin.qq.com
12.（已完成）采集端：在win10下面无法获取MAC地址，造成无法启动；
   A：（已完成）在itellyou上下载win10，版本太多，下载了一个最老的版本，导致无法安装；又下载了一个1709多集合版本(win10的版本也是五花八门，特别多)；
   B：（已完成）DVD光盘用完了(在京东上买了50片DVD刻录盘)，只好下载了“大白菜U盘制作工具”放到U盘上做启动盘，幸好还有2个8G的U盘，删除了“酷爸”亲子课的一些资料和视频；
   C：（已完成）http://www.uqidong.asia/win10/，下载了一个专门为win10定制的U盘制作工具，“大白菜”不好使，需要将iso放到U盘里面；
   D：（已完成）这种U盘制作工具都有大量的后门，安装后会自动安装大量垃圾软件，网站上公开招募装机人员；因此，千万别用，还是用光盘安装；
   E：（已完成）win10的IE11下面，myhaoyi.com的首页两个导航按钮无法跳转；
   F：（已完成）win10下面的采集端运行时，缺少MSVCR100.dll；
   G：（已完成）win10下运行采集端完全正常，也没有激发ERROR_BUFFER_OVERFLOW错误，或许是广州用户的win10版本太老的缘故吧，将修改后的采集端发给他之后，运行正常；说明修改的方式正确，问题解决；
   H：（已完成）折腾了一圈，问题得到解决，终于有了win10的测试环境，也发现了一些问题，等DVD光盘到了，还要重新安装一遍；
   I：（已完成）win10的最新版本1709非VL版本超过4.7G，不能刻录到一张DVD上，只好下载1709的VL版本，4.66G；
   J：（已完成）rgba兼容IE8 => filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=#B2FF5722,endColorstr=#B2FF5722);
   K：（已完成）始终觉得装的垃圾软件影响了win10机器的速度，因此，将itellyou上干净的win10拷贝到硬盘上，在win10上再次安装win10，重装后系统明显变快了；
   L：（已完成）打开win10上的远程，在win7上就可以远程操作win10，调试采集端在win10上的问题；
13.（已完成）采集端：在win10上无法推流，没有任何的提示，就是没进行推流，需要进一步的调试测试；
   A：（已完成）srs_librtmp 在设置接收、发送超时的问题，linux(秒)和windows(毫秒)的时间单位不同；win10下无法推流；
   B：（已完成）winxp/win7都没有严格按照设定的超时时间处理，win10是严格按设定时间判定超时，linux是30秒，windows下就是30毫秒，造成win10下很快超时，无法推流；
   C：（已完成）srs_librtmp:srs_hijack_io_set_send_timeout中加入 #ifdef _WINDOWS 开关；
   D：（已完成）将180主机上srs测试环境还原，以便将来打包使用；
14.（已完成）服务器：通常的服务器会缺少一些模块，常见的缺少组件：
   A：yum -y install gd
   B：yum -y install perl-DBI
   C：将安装更新放到了 install_monitor.sh 和 install_recorder.sh 当中。
15.（已完成）新增 通道配置可以设置rtsp数据流的连接模式，TCP模式或UDP模式，默认UDP模式；
   A：（已完成）网站后台新增rtsp数据流的TCP模式开关，摄像头和流转发分开配置；
   B：（已完成）网站数据库（云录播、云监控）通道表新增use_tcp字段；
   C：（已完成）采集端注册时获取通道配置里的use_tcp内容；
   D：（已完成）采集端获取网站远程配置的use_tcp内容；
   E：（已完成）采集端修改通道时，新增有关rtsp的use_tcp配置，摄像头修改和流转发修改；
   F：（已完成）采集端添加通道时，新增有关rtsp的use_tcp配置，流转发添加；
16.（已完成）小程序：开始“我的通道”的搭建
   A：（已完成）最上面的导航栏，当有两个采集端时才显示；
   B：（已完成）调用API获取用户拥有的采集端列表，只获取指定用户的WAN节点的采集端；
   C：（已完成）采集端下面的通道列表显示与“共享通道”的显示方式保持一致；
   D：（已完成）节点网站的wk_camera当中已经添加了shared共享标志字段；
   E：（已完成）“共享通道”和“我的通道”为空时的显示提示优化；
   F：（已完成）完善“我的通道”的显示细节；
   G：（已完成）“我的通道”上拉翻页 => 加载更多分页内容；s
   H：（已完成）“我的通道”下拉刷新 => 重新加载第一页内容；
   I：（已完成）“我的通道”切换采集端 => 重新加载新的采集端通道列表；
   J：（已完成）“我的通道”修正了没有通道时的样式错位问题；
   K：（已完成）“我的通道”点击通道时的事件响应处理完成；
   L：（已完成）“共享通道”修正了没有通道时的样式错位问题；
   M：（已完成）“共享通道”点击通道时加入了验证机制，避免访问已经停止共享的通道；
   N：（已完成）改进“下拉刷新”，是刷新整个采集端列表，而不只是刷新当前采集端的通道，因为，如果新增了绑定采集端，下拉刷新无法察觉；
17.（已完成）小程序：开始“个人中心”的搭建
   A：（已完成）完成基础界面和功能的布置；
   B：（已完成）微信登录返回的headimgurl，有可能是/0或/132，不是固定的；
   C：（已完成）“我的采集端”、“推荐给朋友”、“意见反馈”、“关于我们”全部完成；
18.（已完成）云录播、云监控的播放页面，左上角需要加上一个下载按钮，直接将MP4文件下载到本地；可以增加一个配置开关（不用登录也能下载）
19.（不执行）云录播、云监控的API需要增加一个功能：输入 rtmp/flvjs/hls 的地址，返回播放连接的功能；
   A：这么做完全没有意义，因为，并不能直到这个连接是可以播放的，完全是为了满足没有意义的需要；
20.（不执行）采集端：改进 Camera_List 的处理方式 => 如果发现通道上的用户数大于0，但是通道已经停止推流了，需要自动再次推流；
   A：（不执行）这种方式，增加了太多不可控的自动化操作，会带来更多的不确定性；用户会通过重新刷新去解决重连的问题；
21.（已完成）采集端：根据Config.xml的配置，可以打印详细的调试日志到Logger.txt当中，便于调试release版本的问题；
   A：直接在需要打印错误的地方用MsgLog处理，代替代码里面的 TRACE 调试信息；
22.（已完成）小程序获取用户登录时的unionid的方法：
   A：（已完成）http://blog.csdn.net/qq_38316918/article/details/78343128 和 http://www.jianshu.com/p/bb1ed9512dd1
   B：（已完成）具体应用过程写在了MiniAction.class.php当中；
24.（已完成）采集端绑定小程序过程中，中转服务器需要新增一个交互命令 kCmd_Gather_Bind_Mini，这个命令有三个子命令：
   A：（已完成）扫码成功 => 1 => Scan
   B：（已完成）确认绑定 => 2 => Save
   C：（已完成）取消绑定 => 3 => Cancel
   D：（已完成）采集端：还是要通过状态来控制显示细节，分为3种状态：kMiniToken | kMiniCode | kMiniHead；
25.（已完成）为提交发布小程序做准备：
   A：（已完成）整理一下本地的代码，提交到代码库；
   B：（已完成）在整理小程序代码时，发现：直播通道的相关录像有问题，逻辑出现混乱，估计是修改通道编号有关；
   C：（已完成）发现在摄像头录制的视频无法在IOS小程序当中播放；摄像头直播没有问题；安卓端也没有问题；
   D：（已完成）虚惊一场，将IOS机器重启之后，就能播放录像了；
   E：（已完成）在小程序的设置中新增在线教育的信息；
   F：（已完成）解决了“我的通道”页面，点击“共享”造成点击穿透的问题，需要改成catchtap事件；
   G：（需注意）目前的wk_track里面共享者是“浩一”，编号为2，采集端绑定者是1，可能会有问题，需要注意；
   H：（需注意）目前的“我的通道”，在共享时，会在节点里面的wk_camera做shared标记，在中心wk_track当中建立记录；
   I：（需注意）目前的“我的通道”，在读取时，直接读取节点的wk_camera，只根据shared标志来判断是否共享，不会读取中心服务器的wk_track记录；
   J：（需注意）目前的“共享通道”，在读取时，直接读取中心的wk_track记录，不会读取节点里面的shared信息；
   K：（已完成）微信小程序开发工具提供的测试功能，相当不错，提交报告后很快就得到了反馈，非常清晰；
   L：（已完成）有机会可以根据小程序的开发经验，投入到开发小游戏的工作当中，非常适合个人或团队开发；
26.（已完成）为了让小程序的共享通道有在线的直播数据，需要加上两个永远在线的直播通道：
   A：（不处理）在中心服务器，新增2个通道，一个监控视频（养猫），一个文件视频，利用ffmpeg循环直播，占用通道1和通道2，
   B：（已完成）如果要实现上面的功能，需要做大量的特殊处理；有可能会破坏整个逻辑，特别麻烦；直接在本地开启采集端就可以了；
   C：（已完成）新的思路：在小程序接口端，专门针对通道1和2做特殊处理，不向中转服务器要地址，而是直接给地址，就能解决在线问题；
   D：（已完成）新的思路：在公网上专门使用ffmpeg一直推流，启动2个进程；需要写两个.sh脚本
   E：（已完成）新的思路：有三种方法可以将ffmpeg在后台运行 nohup/setsid/&，最终选用setsid
   F：（已完成）新的思路：通道1和通道2的脚本如下，可以保持不间断永久推流；https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/
for((;;)); do \
  ./ffmpeg -re -i ./Silicon.Valley.S04E10.360x200x50.mp4 \
  -vcodec copy -acodec copy \
  -f flv -y rtmp://127.0.0.1/live/live1; \
  sleep 1;
done
for((;;)); do \
  ./ffmpeg -re -i ./sample.360x200x50.mp4 \
  -vcodec copy -acodec copy \
  -f flv -y rtmp://127.0.0.1/live/live2; \
  sleep 1;
done
27.（已完成）云录播、云监控的网站端需要新增一个小程序入口二维码，便于用户快速到达；
28.（已完成）直播服务器srs，开启默认配置，rtmp+flv+hls，开启gop，OBS推流，vlc观看，延时达到7~8秒左右；
   A：（已完成）将srs配置成低延时模式，延时为：2~3秒左右，根据文档，开启全部的低延时配置；
   B：（已完成）只是将gop关闭，延时为：2~3秒左右，说明是快显模式造成的延时；
29.（已完成）编写一个flvjs页面，可以多次加载同一个通道；
   A：（已完成）修正API里面play_camera和play_record里面的地址错误，并上传到了云监控和云录播；
   B：（已完成）使用API的方式去编写这个测试页面，使用一个静态页面，添加多个iframe的方式；
   C：（已完成）E:\GitHub\HaoYiYun\Document\小程序\浩一云\more.html，存放在这里；
   D：（已完成）云录播、云监控模版页面当中，有一个play_frame.htm没有用；
   E：（已完成）修改show.htm，可以关闭flvjs的支持；delete arrTech[0]; delete arrSource[0];
   F：（已完成）目前测试的结果如下：
       flvjs => chrome(能开6个不同窗口，相同窗口无法播放) => ie10(能开12个不同窗口，可以相同也可以不同) 
       flash => 没有开窗口限制，但是cpu占用率太高，画面卡顿厉害；
       hls   => 没有开窗口限制，只要内存够，画面流畅，cpu占用率也不高；
30.（已完成）小程序当中还有一些小问题，需要优化：
   A：（已完成）直播播放页面，有关2004通知的处理，看看能否用其它方法证明已经开始正常播放了，而不用一定要等到2004通知的到达，容易造成误判；
   B：（已完成）经过反复测试，发现：无论怎么调整，都有可能发生直播事件没有的情况下，就开始播放了，因此，状态检测机制没有问题，2003|2004；
   C：（已完成）做了细微调整：将检测时间修正为2秒，到期之后，不是停止通道，而只是关闭快照显示，认为正常播放；
   D：（已完成）2003|2004状态没来，不代表播放失败，播放失败是由 onLiveStateChange 专门处理，而不要主动判定；
   E：（已完成）同时，这样做，相当于延时2秒才显示画面，避免直接显示画面的黑屏问题，在停止之后，再启动过程比较明显；重新刷新页面效果不大，还是有黑屏问题；
31.（已完成）小程序：微信用户登录注册时，需要获取wx.getSystemInfo信息，保存用户对应的手机信息，以便将来统计使用；中心数据库的wk_user表，新增字段如下：
   A：wx_brand	      => 手机品牌
   B：wx_model        => 手机型号
   C：wx_version      => 微信版本号
   D：wx_system       => 操作系统版本
   E：wx_platform     => 客户端平台
   F：wx_SDKVersion   => 客户端基础库版本
   G：wx_pixelRatio   => 设备像素比
   H：wx_screenWidth  => 屏幕宽度
   I：wx_screenHeight => 屏幕高度
   J：wx_fontSizeSetting => 用户字体大小设置
32.（不处理）小程序：用户登录注册成功之后，将用户编号存入本地，7天之后过期，才需要重新登录，调用default页面；
   A：（不处理）将用户编号写入本地存储；
   B：（不处理）app.js当中读取本地存储，是否有用户编号，以及过期时间，没有，则跳转default页面；
   C：（已完成）目前采用的每次登录都需要通知中心服务器，这种方式比较保险，如果存放数据在本地，会带来很多其它意外情况，造成不稳定，目前暂时用这种看上去比较笨的办法；
33.（已完成）小程序：解决了反复刷新有可能造成等待框无法退出的问题；在尽可能多的地方加入 wx.hideLoading() 隐藏等待框；不要使用mask功能，可能会造成其它问题；
34.（已完成）发现 ihaoyi.cn 有人利用工具恶意登录，需要解决这个问题：
   A：（已完成）是微信提供的测试工具，登录之后的记录痕迹；
   B：（已完成）目前暂时不要从代码中做特殊处理，这种特殊处理，因为不直到微信测试工具的规则，有可能发生误判，造成其它意料之外的问题；
   C：（已完成）目前的处理办法是，直接从数据库当中删除即可；
35.（已完成）华为手机观看直播时，当通道不在线，显示提示信息时，安卓是一个错误的红叉；
   A：（已完成）安卓版微信小程序内部缓存的问题，重新下载之后就正常了；
36.（不处理）小程序：播放视频页面，自动根据手机旋转状态，进行全屏或恢复显示：
   A：（已完成）直播页面：onLoad当中自动开始监听加速度数据，在这个事件里面处理旋转；
   B：（已完成）直播页面：设定四种状态：竖屏、左旋转、倒置、右选择；
   C：（已完成）最终，测试效果不佳，容易与已有的点击全屏发生冲突，还是将代码屏蔽掉了；
37.（已完成）小程序只能跟 myhaoyi.com 通讯；小程序的所有功能都是围绕管理和统计进行；
38.（已完成）小程序：可以管理采集端、摄像头、网站等等信息，简洁大方，快速上线，需要在 myhaoyi.com 上编写中转服务器 wxsmit（使用swoole），进行命令中转；
39.（已完成）小程序：小程序的支持路径需要想清楚，所有的数据都必须通过 https://myhaoyi.com 中转，需要在 myhaoyi.com 上安装 wxsmit（使用swoole），用于小程序命令中转；
40.（不处理）SRS服务器没有超时检测机制，需要在socket上加入 SO_KEEPALIVE，一旦发生异常，Linux系统会自动清理断开连接，从而通知 SRS，使连接中断；
   A：（不处理）需要找到建立 socket 的代码，然后加入 SO_KEEPALIVE 选项；
   B：（已完成）在 transmit 也要可以考虑加入这个选项，但是，transmit 当中已经加入了超时检测汇报机制，可以暂时不要加；

2017.11.28 - 2017.12.31
=========================================================================
1.（已完成）微信小程序的设计思路准备：
   A：（已完成）小程序是一个管理工具，管理与微信用户绑定的采集端和通道；
   B：（已完成）小程序分为三个导航栏：共享通道 | 我的通道 | 个人中心，个人中心，有采集端管理，管理与该微信用户绑定的采集端；
   C：（已完成）我的通道列举所有的采集端挂接的通道，可以控制通道的启动、停止、预览、共享|关闭，开启共享，会在myhaoyi.com当中新增一条track记录，并修改通道本地数据库状态，关闭则删除记录，恢复状态；
   D：（已完成）在myhaoyi.com的haoyi数据库中新增wk_track表，记录已共享通道；在节点数据库里的wk_camera表新增shared字段，记录通道共享状态；
   E：（已完成）在Gather注册到myhaoyi.com或节点用户登录到节点后台时，都会检测节点记录是否存在，都有可能新增节点记录，保证节点记录的创建；
   F：（已完成）在采集端登录到myhaoyi.com上之后，需要返回采集端所在节点编号，以便采集端本地使用；
   G：（已完成）将小程序“浩一云”与微信开放平台的网站应用“浩一云”关联起来；并修改了各个数据库里的注释wk_user的wx_openid_app
   H：（已完成）https://mp.weixin.qq.com，开始下载开发工具，进行尝试开发；跟vue很像，只是换了一种形式；
   I：（已完成）开发版：在开发环境中点击“预览”，扫码体验，开发版会有调试信息和性能信息；
                体验版：先在开发环境上传代码，登录小程序管理后台，开发管理->开发版本->选为体验版本，扫码体验，只有调试信息，没有性能信息；
                小程序开发助手：专门管理当前帐号关联的正在开发中的小程序，能够显示开发版、体验版信息；
   J：（已完成）在草稿纸上完成了小程序的页面设计稿，下面进入实际的开发过程当中；
   K：（已完成）小程序的文档非常全面，教程、框架、组件、API、工具，非常完备；
2.（已完成）微信小程序的具体实现过程记录：
   A：（已完成）通览小程序的官方文档，做一些必要的记录；
   B：（已完成）搭建“浩一云”基础框架；
   C：（已完成）后期需要进一步完善“浩一云”小程序，使之成为对外宣传的便捷工具或通道；
   D：（已完成）创建小程序之后，最大的作用是让‘浩一云’有了社交属性，让云录播、云监控使用起来更方便；
3.（不处理）云录播、云监控，移动端Mobile界面自适应的问题：（留待以后重构升级再来处理）
   A：（不处理）之前参考的AmUI是可以自适应的，但是，在转移到移动端时，没有做到自适应，而是采用了固定的高度，需要调整一下；
   B：（已完成）https://www.zhihu.com/question/20543196，比较全面的垂直居中方案，最终采用transform方案；
   C：（已完成）由于新增了一个.am-gallery-box样式，固定了高宽，需要去掉高宽，去掉flex；在子元素中需要处理垂直剧中，使用transform样式；
   D：（不处理）如果采用了自适应模式，又出现两个问题：因此，暂不处理，留待以后重构升级再处理；
       1、页面会出现跳跃自适应问题，不是一步到位的显示；
       2、主页面高度发生变化，造成上拉刷新加载更多出现偏移；
4.（已完成）小程序第一版本的第一个页面的搭建：
   A：（已完成）菜单默认：rgb(102,102,102)#666，选中：rgb(252,55,140)#fc378c，修正：rgb(0,153,233)#0099e9
   B：（已完成）每次打开小程序都必须确认用户的身份，默认打开default页面，专门等待身份的获取，然后再跳转页面；
   C：（已完成）首先需要完成default页面的整个设计和体验，加入fontawsome，实现等待过程；
   D：（已完成）发现有些地方不能用$map做为数组变量进行查询，否则，会查询失败；LoginAction.class.php:doWechatAuth()
   E：（已完成）wx.getSetting | wx.openSetting 注：设置界面只会出现小程序已经向用户请求过的权限。
5.（已完成）为了保证用户体验，需要规范演示视频，视频大小和码流控制如下：
   A：（已完成）视频大小：640x360，码流：600kbps
   B：（已完成）视频大小：480x270，码流：500kbps
   C：（已完成）视频大小：360x200，码流：400kbps
   D：（已完成）每隔50帧2秒一个关键帧 => ffmpeg.exe -i 1280x720.mp4 -s 640x360 -keyint_min 50 -g 50 -sc_threshold 0 -f mp4 640x360x50.mp4
   E：（已完成）这样能做到直播秒开的效果，每隔50帧2秒一个关键帧；
   F：（已完成）宽x高x关键帧间隔.mp4，放在 F:/MP4 目录下；
6.（已完成）放开切片限制，云监控、云录播都能进行录像切片，以前只能是云监控模式下切片；
7.（已完成）将客服电话整合到数据库当中，目前是硬编码；
   A：（已完成）在wk_system当中新增字段web_phone，默认值15010119735；
   B：（已完成）在管理后台加入客服电话配置选项；放在默认的“系统设置”栏当中；
   C：（已完成）云录播、云监控同步更新，build目录下的数据库同步更新；
8.（没解决）直播管理，录像计划表，有时候第一次无法打开，需要刷新一下才行；
   A：（没解决）是由于加载缓慢造成，尝试加入加载等待过程；
   B：（已完成）原因是录像任务加载模块太多，造成第一次加载比较慢，目前没有好的办法解决；
9.（已完成）需要在公网的节点服务器上测试，https节点是否能够全部跑通：
   A：（已完成）http://demo.myhaoyi.com => 云录播 演示站点，全部使用http协议；
   B：（已完成）http://ihaoyi.cn => 云监控 演示站点，全部使用http协议；
   C：（已完成）节点网站不能用https模式，存在https与http混用问题，会造成flvjs与hls的直播无法观看，只能用rtmp观看；因此，节点网站都用http协议，与srs的http-flv和http-m3u8兼容；
   D：（已完成）手机端微信、浏览器、iOS、安卓，都可以https与http混用，https的页面，http-hls能够正常播放； 
   E：（已完成）https://myhaoyi.com，全站都只支持https模式，因为，需要兼容微信小程序的API调用，将所有的业务逻辑都转移到节点网站上，通过php这个粘合剂来完成数据交互；
10.（已完成）发现一个很大的Bug：通道截图没有删除旧的图片，造成大量图片积压，正常的逻辑是只留一张截图；
   A：（已完成）也有可能是11.23正在调试直播通道动态截图功能，没有完善的缘故，需要进一步的测试观察；
   B：（已完成）目前没有发现删除的问，加入了日志代码，如果发生删除失败，日志写入网站根目录的 logwechat.txt 当中；
11.（已完成）PC播放器，第一次直播时，总是会发生flvjs无法正常播放的问题，需要跟踪一下到底是什么原因造成的，是由于采集端没有及时上传通道的原因，还是videojs播放器自身的原因；
   A：（已完成）不仅是直播，点播时也会发生第一次无法加载的问题；显示 video.min.js:18 VIDEOJS: WARN: Player "my-video" is already initialised. Options will not be applied. [techName] > Html5
   B：（已完成）在使用video标签创建videojs对象之前，需要先调用接口videojs.getPlayers()，查看是否有videojs对象存在，有的话需要先删除；
   C：（已完成）dispose()会删除所有创建的标签，因此，需要重建video标签，设置id和className，再追加到div当中；
   D：（已完成）经过这样处理之后，再用video标签创建videojs对象就是全新的了，不会报错了；
   E：（已完成）这个问题，完全可以写一篇videojs的使用经验文章，还有结合flvjs、vue的使用，完全可以写三篇文章；
   F：（已完成）还是有个问题：由于加载模块太多，也比较大，第一次加载时，非常缓慢，停顿，需要找到一种读取js文件加载进度的方法，加强用户体验；
   G：（已完成）为了解决上面的问题，需要将script引用都放到head里面，不能放到body里，放在head中的JS代码会在页面加载完成之前就读取，而放在body中的JS代码，会在整个页面加载完成之后读取。
   H：（已完成）这时的体验就会好很多，royalslider会有旋转等待出现rsVideoActive样式，至于video的poster加上也没有意义，因为，它需要页面加载完毕才能显示，不需要设置了；
12.（已完成）将服务器所有模块打包到一个安装包当中，云录播和云监控分别打包，采集端只有一个；
   A：（已完成）对服务器打包工程进行了重组，产生两个文件cloud-monitor.tar.gz和cloud-recorder.tar.gz，放到百度云盘，并建立分享目录；
   B：（已完成）目前只针对一体机进行推广和使用，后续才进行分布式的更新，需要用到myhaoyi.com上建立download目录，配合haoyi.sh进行；
   C：（已完成）将采集端打包，生成 cloud-gather.exe，放到百度云盘上，并建立分享目录；
   D：（已完成）release模式下，ffmpeg报错，需要使用"保留未引用数据(/OPT:NOREF)"选项才可以正常运行；
   E：（已完成）ffmpeg的优化方案 => http://blog.csdn.net/dancing_night/article/details/53009350
   F：（已完成）将采集端默认的连接地址设置为 => http://www.ihaoyi.cn，云监控模式；
   H：（已完成）https://pan.baidu.com/s/1hsmxT0S => cloud-gather.exe
   I：（已完成）https://pan.baidu.com/s/1o8zISmY => cloud-monitor.tar.gz
   J：（已完成）https://pan.baidu.com/s/1bo9Y2Bl => cloud-recorder.tar.gz
   K：（已完成）修改中心网站的数据库密码，代码里还是保持原来的不变；
   L：（已完成）编写《云录播使用手册》
   M：（已完成）https://smallpdf.com/cn/word-to-pdf，一个非常专一的pdf处理网站；
   N：（已完成）修改了config.sh配置脚本，支持自动获取本机IP进行配置（通过auto参数）
13.（已完成）云录播、云监控当中，加入版本信息，版本信息，写在php代码当中，采集端登录时读取；
   A：（已完成）采集端有自己的版本体系，向中心注册时，汇报了采集端的版本信息；
   B：（已完成）节点网站需要加入版本信息，向中心汇报时，写入中心的wk_node当中的node_ver字段；
   C：（已完成）采集端登录节点时需要获取节点的版本信息，展现在关于对话框当中，也要展示自己的版本；
   D：（已完成）节点网站的版本信息是写在 wxapi/Conf/config.php 当中；
   E：（已完成）登录后台后，将“浩一云”替换成文字模式，现在是图片模式，这样就可以去掉default-90.png这个文件了；
14.（已完成）采集端，录像模块，计数时间戳有偏差，不能用输入的时间作为计算标准，要用从文件中读取的时间计算；
   A：（已完成）得到文件的总刻度数，不是毫秒数 => MP4GetDuration()
   B：（已完成）得到文件的每秒刻度数 => MP4GetTimeScale()
   C：（已完成）计算文件的总秒数 => MP4GetDuration() / MP4GetTimeScale()
   D：（已完成）经测试，计算的总秒数与实际存盘文件时间一致，使用这个时间比较精确；文件模式,在持续录像中，在发生循环时会出现时间戳问题；
   E：（已完成）发现文件模式下，循环累加的总时间不是毫秒时间，而是刻度时间，这就解释了为什么文件循环衔接时，终端会停止的问题，因为时间戳出错了；
   F：（已完成）在doMP4ParseAV需要计算总毫秒时间，而不是用总刻度数去处理循环，ReadOneFrameFromMP4中需要将刻度数转换成毫秒时间，进行比较、循环、处理等等操作；
   G：（已完成）感觉循环文件打开速度还加快了，或许是时间戳没有偏差的缘故？
15.（已完成）采集端，需要增加一个重连按钮，这样可以不用退出再次连接；
   A：（已完成）新增“断开重连”按钮，放在工具图标栏当中；
   B：（已完成）修正了重连状态，正在连接中时不能重连，连接失败或连接成功可以重连；
   C：（已完成）修正了连接时的一些文字描述信息；
16.（已完成）采集端，系统设置 => 网站地址和端口，写入配置文件当中，可以从历史记录当中获取；默认写入ihaoyi.cn和demo.myhaoyi.com这两个演示网站；
   A：（已完成）不要使用HistoryComboBox的简单方式，采用自己保存网站地址列表到Config.xml的方式；
   B：（已完成）新建Config.xml时，默认写入http://ihaoyi.cn和http://demo.myhaoyi.com；
   C：（已完成）所有输入的有效的网站地址，都会被记录到Config.xml当中，相同地址只存放一份；
17.（已完成）采集端，摄像头通道，突然断开时，通道并没有立即反馈状态，还是直播中；
   A：（已完成）采用的是超时检测的方式，3分钟仍然没有数据，就认为超时，需要停止通道；
   B：（已完成）以前的方式，对摄像头设备没有检测超时，故意阻拦，现在做了修正；
   C：（已完成）尝试加入了海康设备的异常处理回调，但是意义不大，屏蔽掉了；
   D：（已完成）超时检测是通过一个时钟，不断获取接收码流来判断的；
   E：（已完成）现在的摄像头设备，启动后，也会主动拉取一路视频流，跟流转发一样的处理；
   F：（已完成）摄像头设备也可以关闭预览，不影响推流，但是，无法进行云台操作了；就需要使用onvif协议；
18.（已完成）摄像头设备，新增一个开关，是否开启画面预览；
   A：（已完成）开启画面预览，不能进行云台操作；
   B：（已完成）需要在wk_camera中新增一个显示预览的字段，device_show，默认1开启；
   C：（已完成）这样做的目的是为了节省内网带宽，预览画面也要拉取一路视频流，还要进行本地解码，造成资源浪费；
   D：（已完成）在RenderWnd当中需要调用 IsDeviceStatus() 是否需要绘制特殊状态，在没有登录成功之前都需要绘制；
19.（已完成）解决了mysql-5.5.3命令行停止时报告 unknown variable 'character-set-server=utf8' 的问题；
   A：（已完成）是由于5.5.3自带的libmysqlclient.so.16.0.0/libmysqlclient_r.so.16.0.0的问题，将它们降级为5.1.73就解决了；
   B：（已完成）这两个库是放在php的lib当中的，php/mysql都会使用到；同步更新了；
   C：（已完成）也有可能是配置的问题，但是找了半天也没有解决，下载了mysql-5.7.20版本做为备用；编译方法差别很大，没有尝试成功；最好用官方提供的二进制文件；
20.（已完成）在关于对话框中，对授权过期的信息显示进行优化处理；
   A：（已完成）在中心网站，无论授权是否有效，都要计算最大通道数、剩余天数、到期时间，便于向用户展示；
   B：（已完成）采集端，关于对话框，只有一种显示形式，剩余天数可以显示负数；
21.（已完成）采集端，授权过期之后，需要有一个可以点击的连接地址，让用户直到下一步该怎么办，最简单的方案是连接到https://myhaoyi.com当中；
   A：（未处理）在CMidView当中加入可引导的链接窗口，太过麻烦，暂不处理，后续有空再调整；
   B：（已完成）将 https://www.myhaoyi.com 全部统一到一个地方配置；
   C：（已完成）关于对话框中，对于没有授权成功的状态，做了特殊处理；
22.（已完成）rtsp协议，某些连接的数据，会出现一直不能初始化的问题；
   A：（已完成）测试连接地址 => rtsp://184.72.239.149/vod/mp4:BigBuckBunny_115k.mov
   B：（已完成）有数据到达，但一直没有处理，也没有修改状态，估计是后来改的逻辑有问题；
   C：（已完成）是由于数据区里面没有再次发送sps和pps的信息，造成无法启动初始化；
   D：（已完成）这是之前将初始化过程转移到了，当在数据区又找到了sps和pps时才处理，为了应对当时有些平台在协议部分给的sps和pps是错误的情况；
   E：（已完成）现在又要改回去？改回去之后，是否可以在数据区也保留再次发送AVC的格式信息的数据包？告诉服务器格式都可能有变化？
23.（已完成）对srs的编译日志开关做了研究，如下：
   A：（已完成）./configure -h => 可以查看所有的编译开关；
   B：（已完成）--log-verbose 对应 SRS_AUTO_VERBOSE 在 auto_headers.sh 当中定义；
   C：（已完成）srs.log当中可以看到编译进二进制的开关是哪些，默认使用 --log-trace，只有trace函数有效，其它都为空；
   D：（已完成）因此，这种设计，无论怎么开编译后的配置，都不能打印除trace之外的其它日志，必须重新编译配置日志才能有效；
24.（已完成）只有视频的数据流，flvjs无法播放，因此，需要在后台加入一个开关，是否屏蔽flvjs的回放功能；
   A：（不执行）需要在wk_system表中新增一个字段flvjs，控制PC端直播播放时是否可以加载flvjs，无法播放只有视频数据的内容；
   B：（不执行）show.htm当中去验证这个开关，一旦关闭，直接删除对flvjs的支持，而不用再根据浏览器的支持情况再决定是否删除flvjs的支持；
   C：（已完成）尝试通过修改flvjs代码的方式，或者，通过修改采集端推流的MetaData的方式来提前告知有没有音频的方式去处理；
   D：（已完成）在采集端 WriteMetadata 做了严格的设定之后，但是，由于 srs 会缓存通道数据，包括头信息，而flvjs不仅会从metadata当中获取格式，还会从数据流获取格式；
   E：（已完成）这两种因素结合在一起，就会造成只有视频的通道，在通道数据切换时，造成始终等待，从而无法播放；
   F：（已完成）srs的代码大量相互牵连，太复杂，只能从 flvjs 入手，简单修改 flvjs 的代码，让flvjs完全听从metadata的音视频标志进行处理，即使有数据也要扔掉；
   G：（已完成）npm 下载flvjs代码，修改代码，重新编译，打包；以metadata的标志为优先，而不是人为的设定，metadata的原始数据来自推流端，因此，推流端要先判断清楚；
   H：（已完成）flv-demuxer.js:_parseAudioData:446 追加代码如下：
        // 2017.12.16 - by jackey => first check use metadata value...

        let onMetaData = this._metadata.onMetaData;

        if ((typeof onMetaData.hasAudio === 'boolean') && (!onMetaData.hasAudio)) {

            Log.v(this.TAG, '_parseAudioData: No Audio in metadata');

            return;

        }
      
   I：（已完成）flv-demuxer.js:_parseVideoData:806 追加代码如下：
        // 2017.12.16 - by jackey => first check use metadata value...

        let onMetaData = this._metadata.onMetaData;

        if ((typeof onMetaData.hasVideo === 'boolean') && (!onMetaData.hasVideo)) {

            Log.v(this.TAG, '_parseVideoData: No Video in metadata');

            return;

        }

   J：（已完成）在编译flvjs时，遇到一些问题，有关 gulp 的；gulp 不仅要在 全局安装，还要在本地安装，编译时缺少的库都需要逐个安装才行；
   K：（已完成）这样的修改就不用在数据库当中添加字段，也不用修改播放器代码，而是在flvjs中修改音视频的有效性依据metadata就可以了；
   L：（已完成）flvjs的源码安装在 F:\Vue\flvjs\ 当中，具体编译位置 F:\Vue\flvjs\node_modules\flv.js
25.（已完成）中转端，某通道上的播放器为0时，转发命令给采集端，会因为网络原因，无法到达采集端，造成采集端一直在上传已经停止的通道；
   A：（已完成）跟transmit造成采集端假死的情况，综合起来考虑，应该让采集端每隔0.5分钟，查询正在上传的直播通道的用户数；
   B：（已完成）transmit可以根据采集端是否汇报，来判断超时，采集端又可以根据transmit反馈来确认正在上传的通道是否还要继续上传；
   C：（已完成）transmit会检测采集端连接如果在1分钟都没有汇报，则判定为超时，需要删除之；
   D：（已完成）transmit检测到超时之后，不仅要删除对象，还要去掉epoll当中的注册，关闭套接字；
   E：（已完成）同步更新到外网服务器进行同步测试；
   F：（已完成）mysql的链接库还原成 5.5.3-m3 版本，避免使用 5.1.73 的版本造成潜在的不可预知的风险；
   G：（已完成）mysql同步修改my.cnf里的 [client] default-character-set = utf8
26.（已完成）开始建立API接口规范；
   A：（已完成）在nginx的配置当中新增接口重定向 location /api/v1 { rewrite ^/api/v1(.*)$ /wxapi.php/API$1; }
   B：（已完成）接口参数输入有两种形式，如下所示：
       /api/v1/method/param1/data1/param2/data2
       /api/v1/method?param1=data1&param2=data2
   C：（已完成）严格区分大小写，接口、名称，全部都用小写；返回数据统一用json，形式相同；
27.（已完成）有关API接口的使用注意事项说明：
   A：（已完成）会话的有效性是通过token里面的时间进行判断的，不会使用cookie，避免与云监控、云录播本身的登录体系混乱；
   B：（已完成）这种方式也是比较安全和保险的机制，完全遵循API的规范，每次接口调用都要判断token里面的时间有效性；
28.（已完成）接口列表说明，功能、接口、参数、返回值等等信息：
   A：（已完成）编写接口文档，实现接口调用的逻辑（APIAction.class.php）
   B：（已完成）在后台界面中加入显示能够调用API的unionid信息，需要经过base64处理；
   C：（已完成）同步更新代码到云监控、云录播系统当中；
   D：（已完成）编写API接口文档，输出成PDF文件，备用；
29.（已完成）网站后端，每个网站端都需要一个唯一授权码，拿到授权码才能进行API访问；
   A：（已完成）这个可以参考一些API的设计 => http://easynvr.easydarwin.org/
   B：（已完成）只有管理员登录后台后才能看到“API凭证”；
30.（已完成）采集端接入中心服务器授权需要增强加密功能：(将数据进行微信那样的AES-CBC编码处理，采集端需要还原编码)
   A：（不处理）核心思绪是：需要对传递的明文数据进行签名，以确保安全性；
   B：（不处理）采用AES-128加密方式，PHP端加密，采集端还原；因为，中心服务器本身就是ssl的连接，数据已经加密了；
   C：（已完成）中心服务器本身就是ssl的机制，不用再对数据加密，当然，也可以再次加密，做双重保障；
   D：（已完成）VC++2010已经实现了微信AES-CBC的解码还原实验，代码在 => F:\谷歌下载\aes-sample\c++\win32
   E：（已完成）授权模式当中加入“永久授权”功能，需要在采集端体现出来，中心网站需要新增一个字段license；
   F：（已完成）中心服务器新增md5字段，采集端关于框，新增“标识”，便于授权匹配；
31.（已完成）节点网站端增加接入授权机制：
   A：（已完成）在用户进行微信扫码登录时，验证授权是否过期，过期后显示提醒授权过期框；
   B：（已完成）跟采集端的处理机制不太一样，因为，微信扫码登录后，会反向调用节点网站连接，这时就能提示警告，而不用让节点网站再进行解码操作；
   C：（已完成）节点网站默认授权时间30天，可以随时任意增加，也要加入“永久授权”功能；
   D：（已完成）中心服务器的节点表中新增license、expired字段；
   E：（已完成）节点网站“系统设置”当中，需要显示“授权状态”；
   F：（已完成）云录播、云监控同步更新授权机制；
   G：（已完成）同步更新到外网上的云录播、云监控，这两个节点网站是“永久授权版本”。
32.（已完成）云录播API接口当中，需要加入：添加录像任务、修改录像任务、删除录像任务；
  A：（已完成）添加、删除、修改都是一个命令，通过is_delete标志进行区分；
  B：（已完成）因为只有每周重复机制，再加上没有跨天操作，API接口判断做了优化，不用合并到同一周，而是直接判断；
  C：（已完成）API接口文档，做了同步更新操作；
33.（已完成）升级采集端、服务器的版本号：
  A：（已完成）采集端升级为 1.1.1.0
  B：（已完成）服务器升级为 1.2.0
34.（已完成）新建两个方案支持QQ群
  A: （已完成）云监控解决方案 => 630379661
  B：（已完成）云录播解决方案 => 483663026
35.（已完成）将文档里的联系方式，加上QQ群二维码和群号，去掉微信二维码
  A：（已完成）https://myhaoyi.com里面的页面更改；
  B：（已完成）《云录播-使用手册》里面的联系人修改；
  C：（已完成）《云录播-API接口》里面的联系人修改；
  D：（已完成）《云录播-使用手册》更新了新功能；
  E：（已完成）《云录播-使用手册》还需要统一百度云盘上的连接，不用每次发布版本都要更新，只需要放到云盘上的目录就可以了；
36.（已完成）将云录播、云监控的系统命名做统一：
  A：（已完成）云录播开发目录 => recorder，以前是htdocs
  B：（已完成）云录播打包名称 => recorder-0.0.1.x86_64.rpm，以前是htdocs
  C：（已完成）对外演示网站的云录播目录 => recorder，以前是demo
  D：（已完成）打包脚本自动读取php配置中的版本信息；
  E：（已完成）修改192.168.1.70的云录播测试目录 => recorder，以前是htdocs
  F：（已完成）数据库的命名保持不变，云录播还是haoyi，云监控还是monitor
  G：（已完成）云录播、云监控在独立安装时都统一成htdocs，只有同时安装时才做目录区分
37.（已完成）编写云监控的使用手册、API接口、文档等等，然后统一打包，发布版本；
  A：（已完成）《云监控-使用手册》编写完毕，转换成pdf，上传云盘；
  B：（已完成）《云录播-API接口》编写完毕，转换成pdf，上传云盘；
  C：（已完成）云监控、云录播 打包，上传到百度云盘发布；
38.（已完成）将来所有在百度云盘上发布的版本都要按照版本编号建立目录，采集端和服务器分开发布，它们的版本不相同；
   A：（已完成）建立唯一目录，共享这个目录，每个版本建立一个子目录或全部平铺放置；
   B：（已完成）共享目录为 => https://pan.baidu.com/s/1bppqJWr => 浩一云
   C：（已完成）根目录下放置 最新版本的采集端、服务器、相关文档；
   D：（已完成）每次发布新版本，就把旧版本放到“历史版本”目录中；
39.（已完成）统一版本发布机制：
   A：（已完成）云录播、云监控、采集端，每次发布时，都要同时发布，版本号保持一致，同步更新日志；
   B：（已完成）只有一个版本，只有一个日志；
   C：（已完成）版本号都统一成 3 位数字，每一位从0~9，依次升位；
   D：（已完成）最高版本9.9.9，目前版本1.2.0
   E：（已完成）采集端如果必须要四位，第四位就用0补齐；
   F：（已完成）这样做的目的就是为了统一简化，管理方便；
   G：（已完成）修改各个文档里有关版本的内容；
40.（已完成）在https://myhaoyi.com上增加下载地址和更新日志：
   A：（已完成）PC端、移动端增加下载地址和更新日志；
   B：（已完成）云录播、云监控，演示节点网站增加下载地址和更新日志；
   C：（已完成）放到PC端、移动端的首页当中，参考layui的页面设计；
   D：（已完成）PC端、移动端的首页，下载连接到百度云盘，更新日志连接到专门页面，参考layui的页面设计；
   E：（已完成）合并index的PC端和移动端页面，只保留一份页面，让页面自适应；
   F：（已完成）新增使用步骤页面，安装“采集端”“服务器”，发布通道
   G：（不执行）修改更新日志的连接地址，直接指向文档；百度网盘地址太复杂而且是动态的；直接指向分享目录就够了；
41.（已完成）小程序第一版的核心架构的搭建，主要是样式：
   A：（已完成）小程序能够已myhaoyi.com为中心，管理多个节点下面的多个采集端，并能够通过一个小程序观看通道的截图、通道的直播、通道的点播；
   B：（已完成）通过完成‘共享通道’这个页面来进行实验，看看能否实现从myhaoyi.com管理多个节点下的采集端，并实现点播、直播、截图的显示；
   C：（已完成）首先，需要完成共享通道的页面设计工作，尽量使用现有的模版和页面样式；
   D：（已完成）"enablePullDownRefresh": true => Boolean，不是String，设置成 "true"，会导致手机上无法显示下拉刷新；其它地方又可以String与Boolean混用没事！
   E：（已完成）小程序的样式被固定在了组件当中，相对使用起来比较方便，样式也比较固定，没有太多特殊的东西，完成了通道页面的初步搭建；
   F：（已完成）开始完整逻辑的搭建，还是从共享通道入手，进行完整与微信帐号绑定的社交逻辑的测试；
   G：（已完成）已经在ios和android测试通过 .m3u8 可以直接在小程序当中播放，在PC开发工具中不能播放 .m3u8 文件；
   H：（已完成）为了不让页面抖动跳跃，将所有有关视频的页面都统一设置成210px，注意没有使用rpx；
   I：（已完成）暂时不要使用scroll-view，它需要设置一个固定的高度，同时，小程序动态选择对象非常不方便，再加上滑动体验不佳，还是使用原生的view处理；
   K：（已完成）为了便于定位，需要在中心节点的wk_track表中，新增user_id字段，用于快速定位共享通道的用户信息；需要给wk_track建立一个信息视图；；
   M：（已完成）需要在myhaoyi.com的wk_node当中，新增字段node_wan，是否是互联网节点，默认0，在网站登录和采集端注册时验证更新到数据库当中；
   N：（已完成）发现一个Bug，采集端在汇报时和节点汇报时，在myhaoyi.com上产生的效果不一致，需要统一起来，需要新增一个字段node_proto，用来保存节点的协议类型；云录播、云监控、采集端、中心服务器，全部都要同步修改；
   O：（已完成）为了调试小程序，必须在公网上搭建节点环境，才能正常测试，将云录播和云监控同时搭建起来；
      1：（已完成）将数据库更新完毕，云录播haoyi，云监控monitor；
      2：（已完成）将数据库更新到公网上，将网站更新到公网上；
      3：（已完成）将transmit、srs更新到公网上；
      4：（已完成）将中心服务器的数据库进行了规范处理：
          https://myhaoyi.com => center => 中心数据库 => /weike/htdocs
          http://ihaoyi.cn => monitor => 云监控数据库 => /weike/monitor
          http://demo.myhaoyi.com => haoyi => 云录播数据库 => /weike/demo
      5：（已完成）以后的系统调试，都尽量使用公网调试，尽量不用内网调试；
      6：（已完成）节点网站不能用https模式，存在https与http混用问题，会造成flvjs与hls的直播无法观看，只能用rtmp观看；因此，节点网站都用http协议，与srs的http-flv和http-m3u8兼容；
   L：（已完成）在云录播、云监控的代码中都需要新增小程序接口代码，目前主要处理myhaoyi.com转发来自微信小程序的命令；
      1：http://demo.myhaoyi.com => 云录播节点网站；
      2：http://ihaoyi.cn => 云监控节点网站；

2017.11.16
=========================================================================
1. 向 github 完成了一次提交工作；

2017.11.10 - 2017.11.30
=========================================================================
1.（已完成）采集端，需要做服务器类型的区分，云录播与云监控在录像时，需要的参数不一样；
   A：（已完成）云监控：数据库 => monitor => 192.168.1.72
   B：（已完成）云录播：数据库 => haoyi   => 192.168.1.70
   C：（已完成）所有的默认背景图统一更换成 default.png（浩一云）
   D：（已完成）采集端最大通道数从中心网站获取，本地不保存；需要增加一个中转命令；
   E：（已完成）采集端的camera页面与live页面整合到一起去；只留下live页面；去掉采集端页面的‘摄像头’按钮；
   F：（已完成）采集端，将系统配置移动到网站后台配置，本地只存放：录像路径、网站地址、网站端口；
   G：（已完成）采集端，去掉按时钟拉取录像切片配置，放到网站端的采集端配置里面；
   H：（已完成）采集端，新增字段：main_rate、sub_rate、auto_dvr、auto_fdfs、slice_val、inter_val，去掉max_camera字段；
   I：（已完成）采集端，通道数的授权放到myhaoyi.com当中，跟授权时间放到一起去，节点当中的采集端表就要去掉max_camera字段；
   J：（已完成）采集端，通道数不能改变，只能查看，而且是从myhaoyi.com注册成功之后获取得到；
   K：（已完成）网站后台，可以配置采集端的参数信息；
   L：（已完成）采集端，将直播码流、录像码流，做标记：只对IPC设备启用；
2.（已完成）采集端的在线状态，不是从中转服务器获取，而是从数据库获取，跟通道状态一致；
   A：（已完成）wk_gather新增自读，status，记录采集端的在线状态；
   B：（已完成）在采集端注册时，会修改其它通道的状态为-1，新增将自己的状态改成1；
   C：（已完成）在采集端退出是，会修改其它通道的状态为-1，新增将自己的状态改成0；
   D：（已完成）在中心服务器myhaoyi.com，也要对采集端的在线、离线状态做标记；
3.（已完成）摄像头设备，主码流录像，子码流直播，也可以配置成：主码流录像、主码流直播；
   A：（已完成）针对摄像头设备，默认采用主码流录像，子码流直播的方式进行；
   B：（已完成）针对单个摄像头通道，可以关闭双码流模式，只用主码流录像和直播；
   C：（已完成）wk_camera修改字段 device_channel为device_twice（双流模式开关）
   D：（已完成）双流模式下的录像状态显示问题；当连接失败时，还需要删除对象；
4.（已完成）采集端在右侧窗口改变登录密码，没有汇报到网站服务器上去
   A：在CRightView::doDeviceLogin当中，有专门的汇报代码；
5.（已完成）采集端登录注册时，没有读取到通道下面的录像任务记录
   A：由于云监控模式下，没有subject和teacher字段导致，修改了GatherAction.class.php，不要指定字段，同时，也修改了云录播模式下的代码；
6.（已完成）删除通道时，需要给出提示：该通道下的所有录像和配置都将被删除；
   A：（已完成）采集端删除警告；
   B：（已完成）网站后台删除警告；
7.（已完成）播放页面，在第一次加载时，有时会造成video标签无法展开，始终在左上角的问题；
   A：（已完成）在 show.htm 当中，直接新增 .video-js 替代样式，一开始就将窗口设置成需要的大小；
   B：（已完成）在 videojs 的构造对象当中，可以去掉 width 和 height 设置；
   C：（已完成）在 videojs 的 sources 是通过 json 解析出来的，这样有助于点播和直播时的动态配置；
8.（已完成）网站后台，可以设置采集端的常规配置，比如：连接网站地址、端口等等；
   A：（已完成）采集端的常规配置，通道配置，全部放到了数据库当中；
9.（已完成）将数据的默认标题进行修改
   A：（已完成）数据库 => haoyi => wk_system => web_title => 云录播
   B：（已完成）数据库 => monitor => wk_system => web_title => 云监控
   C：（已完成）将所有可能出现网站标题的地方都改成了从数据库当中读取，而不是强制写在代码里，以便将来定制升级使用；
10.（已完成）采集端可以利用ffmpeg的sdk直接单帧解码，从而实现直播每隔一分钟动态截图的功能；
   A：（已完成）默认每隔2分钟更新直播截图，放到fdfs当中；
   B：（已完成）首先需要实现ffmpeg的单帧界面保存jpg的功能；
   C：（已完成）这个jpg文件要跟直播通道关联，而不是点播关联；
   D：（已完成）在wk_camera当中去掉stream_auto、stream_loop字段，新增image_id字段；
   E：（已完成）采集端，wk_gather新增一个字段，snap_val字段，通道截图间隔时间，【1-10】分钟，默认2分钟；
   F：（已完成）参考了雷神的简单例子，结合网上有关yuv保存jpg的文章完成；
   G：（已完成）始终缓存了一个关键帧和它后面的非关键帧的数据，遇到新关键帧清空缓存，重新缓存；最保险的存放两个关键帧（浪费内存），目前是存放一个关键帧；
   H：（已完成）ffmpeg在解压h264数据时，即使是关键帧也可能得不到完整的picture，需要继续解码才能解码出完整的图像；循环解析很重要；
   I：（已完成）直播通道快照采用ffmpeg动态解码截图的方式，录像快照采用mplayer解码截图的方式（随机选择文件位置截图体验会更好一些）；
   J：（已完成）需要将通道的截图更新到网站界面上，结合默认的snap.png去完善；默认快照图片就一张，不要区分在线和离线状态图片，用文字区分在线和离线状态；
   K：（已完成）云录播的手机端没有替换，Mobile部分的替换工作还没完成；
   L：（已完成）删除live-off.png和live-on.png；
   M：（已完成）点播加载失败的背景图全部改成default.png(300*200)或default-90.png(90*50)；
   N：（已完成）直播加载失败的背景图全部改成snap.png(640*360)
   O：（已完成）云录播、云监控同步更新；
   P：（已完成）后台点播截图的显示问题 => 仍然采用目前的背景模式，原始图加载失败，用一个blank.gif显示，露出背景图；
   Q：（已完成）后台录像计划的录像记录的图片显示问题 => 仍然采用目前的背景模式，，原始图加载失败，用一个blank.gif显示，露出背景图；
   R：（已完成）直播通道被删除时，需要删除通道对应的快照记录（后台删除、采集端删除，俩个入口），云录播、云监控都要分别处理；
11.（未实现）后期需要研究一下直接ts over http 的方式，直接播放，可以降低延时；因为videojs可以直接ts over http方式；只不过videojs是基于m3u8的；
   A：（已完成）这种方式，可能需要结合srs将ts切片直接放到内存当中，浏览器通过videojs访问，绕过m3u8的方式？需要进一步研究！
   B：（已完成）srs 始终输出rtmp，可以输出hls，可以输出http-flv，可以输出http-ts；可以同时输出hls+http-flv，不能同时输出hls+http-ts，解析上有点问题；
   C：（已完成）需要测试，videojs能否在PC上播放http-flv流或http-ts流；移动端测试videojs能否播放http-flv或http-ts，这样可以降低延时；
   D：（已完成）http://docs.videojs.com/docs/ => 比较全的 videojs 的文档；
   E：（已完成）https://github.com/Bilibili/flv.js => 支持 srs 输出的http-flv直播，可以代替flash，秒开，但是ios不支持，android4.4.4以上才支持，PC端浏览器能支持；
   F：（已完成）https://github.com/mister-ben/videojs-flvjs => 可以将flvjs放到videojs，亲测通过，但是，手机端不支持；
   G：（未完成）群里那人说的ts over http估计是APP的方式，而不是js方式；
   H：（未完成）能做Onvif协议的IPC接入转发，H5浏览器播放RTMP（HLS）直播流的软件？ 如可以请加QQ：286021234，谢了！
12.（已完成）直播新增一种播放方式flv.js，可以替代flash，srs服务器需要输出http-flv数据流，新增配置就可以；
   A：（已完成）srs服务器，在配置中开启http-flv输出；
   B：（已完成）使用videojs-flvjs和flv.js，在videojs当中支持flv.js，可以替代flash的方案；
   C：（已完成）修改show()代码，在php中直接使用数组方式构造techOrder；
   D：（已完成）修改transmit代码，能够输出flvjs需要的地址和类型；
13.（已完成）为了兼容IE8，需要识别浏览器类型，动态加载flvjs和hls的支持，否则，videojs-ie8.js会报错，发生冲突；
   A：（已完成）在播放页面show.htm中的 .video-js 和 video() 都需要设置画面的高度和宽度，否则，IE8出错；
   B：（已完成）需要识别浏览器，动态加载flvjs和hls，否则videojs-ie8.js报错；
   C：（已完成）在IE8当中，不能用console打印，也会报错；
   D：（已完成）在IE8当中，home_header.htm当中，会自动打开注释：[if lt IE 9]
   D：（已完成）同步更新到云监控当中；
14.（已完成）play.htm当中，解决了royalSlider显示跳跃的问题；需要在一开始隐藏右侧画板内容，royalSlider会重建右侧画板；
   A：（已完成）新增rsHide样式，放在home.css当中；
   B：（已完成）同步更新到云监控当中；
15.（已完成）transmit的播放器超时检测机制存在问题？flash播放器的存活周期不靠谱，必须使用超时检测；
   A：（已完成）播放器，无论是flash还是html5都需要活动汇报；
   B：（已完成）中转器，无论是flash还是html5都需要超时检测；
   C：（已完成）由于IE8在请求播放时，会连续调用两次，造成有一个Flash播放器死在srs当中，中转器里面也死一个，就会造成采集端一直上传；
16.（已完成）flvjs的兼容性改进；
   A：（未处理）(目前不知道原因)在win7的chrome里，不能同时打开两个flvjs，只能关掉之前的才能打开新的；
   B：（已完成）需要提前检测浏览器是否支持mse功能，避免造成无法播放的问题；Mac的safari就无法支持，造成始终卡死不动；
   C：（已完成）flvjs 兼容 Chrome, FireFox, Safari 10, IE11 和 Edge；需要排除Safari 10以下的版本；
   D：（已完成）目前的策略：IE11以下全部用flash，Safari 10以下屏蔽flvjs，删除数组第一个元素；
17.（已完成）云监控的前端显示时，直接显示采集端名称；
   A：（已完成）monitor_nav.htm当中使用 msubstr=0,5,"utf-8",false 实现
18.（已完成）采集端程序可以最小化到任务栏，不影响任务栏工作；
   A：（已完成）新增 Ntray.h 和 Ntray.cpp ，任务栏管理器；
   B：（已完成）将任务栏的处理放到CMainFrame当中；
19.（已完成）云录播的移动端Mobile优化：
   A：（已完成）无论点播还是直播，默认快照都统一使用 snap.png，不要做区分，将来还可能定制，避免造成更多的麻烦；
   B：（已完成）对vue-lazyload进行了重新利用，设置error参数，能够自动跳转到snap.png，简化了很多操作；
   C：（已完成）默认快照的设置，不要用背景模式，由于swiper模式下，没有onerror机制，需要在php端预先设定snap.png地址；
   D：（已完成）由于快照链接存放在fdfs当中，当链接不为空时需要加上前缀，为空时，浏览器前端根据lazyload的设定自动跳转到snap.png上去；
20.（已完成）云录播、云监控的PC前端，默认快照的优化：
   A：（已完成）前端：无论点播还是直播，默认快照都统一使用 snap.png，不要做区分，将来还可能定制，避免造成更多的麻烦；
   B：（已完成）前端：去掉所有使用default.png和default-90.png的地方，全部替换成snap.png；
   C：（已完成）前端：参见play.htm，用模版去处理，不要在php当中处理；
   D：（已完成）后台：还是继续使用default.png、default-90.png（getClock.htm|getVod.htm|admin_header.htm当中在使用）；
21.（已完成）云监控模式下，缺少移动端界面，创建 Mobile 目录，使用 vue 来编写，参考云录播的移动端实现；
   A：（已完成）webpack升级很快，发生了很多变化，config/index.js当中，不能配置devtool，否则，手机端无法打开开发环境；
   B：（已完成）12.01发现，如果去掉devtool的话，chrome调试无法显示，所以，还是不能去掉；
   C：（已完成）参考云录播的移动端，优化了显示页面，并使用了template的v-if，在模版处理上更方便了；
   D：（已完成）顺便完成了云录播移动端的界面优化和部分改造，跟云监控的移动端同步；
22.（已完成）网站前端：为了进一步增强直播播放体验，需要在 videojs 和 flash 当中，加入等待状态过程，避免黑屏等待；
   A：（已完成）在PC端，使用三种播放模型：flvjs、flash、hls；
23.（已完成）采集端：可以系统配置或通道单独配置，流转发模式是否本地回放(EasyPlayer可以直接解码单帧还能截图），调用ffmpeg的sdk实现本地回放或其它简单的能够播放mp4视频帧的sdk；
   A：（已完成）使用ffmpeg-sdk完成了实时动态单帧解码截图；
   B：（已完成）录像截图，还是使用mplayer针对文件操作；
24.（已完成）网站端：加入一个二维码接口，提示用微信扫码可以手机直接观看，移动端查看接口。微信端也能通过内网访问，相当于微信浏览器。
   A：（已完成）设计录播模式、监控模式的移动端界面，可以参考一些商城的设计，需要简化应用；重点突出视频内容；
   B：（已完成）移动端的设计要为小程序打好基础，小程序的设计思路与网页版移动端保持一致；
   C：（已完成）移动端：vue使用videojs，不用登录就可以观看，主要是查询方便，跟微信公众号或小程序结合可以设定观看权限；
   D：（已完成）网站端：右下角、右上角，放置了移动手机端访问入口，点击弹框，扫描二维码访问手机端；
   E：（已完成）网站端：移动手机端访问入口，同步更新到云录播和云监控的代码当中；
   F：（已完成）网站端：优化了页脚页面，将与页脚有关的部分都封装起来，避免代码重复，一个页面可以有多个$(document).ready()函数，同步更新到云录播和云监控；
25.（已完成）安装脚本可以执行wxapi.php/Index/config，不会在Index/_initialize被强制跳转；
   A：（已完成）在使用标准浏览器访问时，会执行Index/_initialize，会被强制跳转；
   B：（已完成）在使用curl时，不会执行Index/_initialize，可以不用管；

2017.10.24
=========================================================================
1.（已完成）移动端滑动参考代码：
   A：演示 => http://idangero.us/swiper/demos/
   B：源码 => https://github.com/nolimits4web/Swiper
2.（已完成）将网站的结构进行了再次重新梳理：
   A：AdminAction.clsss.php   => PC端后台管理页面 => 微信登录时会注册到myhaoyi.com的数据库当中
   B：GatherAction.class.php  => 采集端与网站通讯的接口；
   C：MobileAction.class.php  => 移动端与网站通讯的接口；
   D：RTMPAction.class.php    => rtmp/hls直播与网站通讯的接口；
   E：HomeAction.class.php    => PC端云录播模式下前台网站页面；
   F：MonitorAction.class.php => PC端云监控模式下前台网站页面；
   G：MobileAction.class.php  => 移动端页面与网站通讯的接口；
3.（已完成）编写一个脚本，在安装完毕之后，修改各个模块的配置，修改IP地址：
   A：config.sh x.x.x.x => 用脚本修改IP地址；
   B：/weike/srs/conf/srs.conf => web_addr 192.168.1.xx; => 重启srs
   C：/etc/fdfs/client.conf => tracker_server=192.168.1.xx:22122 => 重启php
   D：/etc/fdfs/storage.conf => tracker_server=192.168.1.xx:22122 => 重启storage
   E：/etc/fdfs/mod_fastdfs.conf => tracker_server=192.168.1.xx:22122 => 重启nginx
   F: curl http://localhost/wxapi.php/Index/config/tracker/x.x.x.x:22122/transmit/x.x.x.x:21001
4.（已完成）编写uninstall.sh，快速卸载各个安装组件。
5.（已完成）srs，直播服务器汇报地址，不一定是直接从本机获取，需要可以手动修正，有地址映射时就会不一样；
6.（已完成）nginx和mysql可以多个实例并存，注意区分好安装目录端口就可以了；
7.（已完成）config.sh，打包参数修改脚本还需要考虑一些特殊情况：
   A：（已完成）网站端口，不一定是80端口，有可能是其它端口；（加入第二个参数）
   B：（不处理）数据库端口，不一定是3306端口，有可能是其它端口；（采用手动处理的方式解决）
8.（已完成）采集端可以在设置了新的网站地址、端口之后，不退出程序重新启动；
    A：MidView.cpp当中STL-Map不能用clear方法，必须用erase单个删除，否则有内存泄漏；
    B：RightView.cpp当中新增DestoryButton方法，方便来回重建过程；
    C：WM_RELOAD_VIEW消息，任何时间发起，都能引发视图重建；
9.（已完成）采集端通道配置，改变以往的以本地优先的策略，需要调整为以网站优先的原则；
   A：（已完成）采集端启动后，先在本地节点注册，RegisterGather，采集端是否在线，通过transmit获得，而不是数据库，通道是否在线是通过数据库；
   B：（已完成）本地注册成功，还需要发送该采集端下的所有通道编号列表，以便后续请求使用；
   B：（已完成）本地注册成功，向中心网站注册，RegisterHaoYi，获取授权过期时间，一旦授权过期，停止服务；
   C：（已完成）从本地节点网站，获取所有的与本采集端相关的通道列表，放置到内存配置当中，不存盘到本地；
   D：（已完成）这样就会造成没有本地编号，只有数据库编号，改动比较大；去掉整个Track节点，全部放到map集合当中；
   E：（已完成）发现一个重大Bug：不要在procPostCurl过程中处理curl反馈数据，因为，数据有可能是被截断的部分数据，需要在procPostCurl中保存数据，处理过程交给发起位置；
   F：（已完成）为了兼容摄像头和流转发模式，在camera表中需要新增几个字段：
       stream_auto、stream_loop、device_user、device_pass、device_cmd_port、device_http_port、device_mirror、device_osd、device_desc、device_channel、device_boot
   G：（已完成）添加或修改流转发通道时，可以设定通道名称；MFC Radio中需要保证同一组内的radio的tab序号是连续的，才能自动变化；
10.（已完成）网站后台，可以完全控制采集端通道的添加、删除、修改、启动、停止。
   A：（已完成）网站后台，只能添加流转发通道，不能添加硬件通道，硬件通道在采集端自动添加，可以修改硬件通道；
   B：（已完成）网站后台，远程配置采集端的通道，通过延时的方式获取状态，一旦发生错误，需要汇报给网站，并显示出来；
   C：（已完成）网站后台（添加、修改、删除）通道配置 => Transmit => Gather => 启动|停止 => 汇报网站
   D：（已完成）网站后台（添加、修改、删除）通道配置 => 等待3.5秒 => 检测DB => 显示结果
   E：（不处理）通道的码流信息可以通过采集端定期的状态请求，汇报给网站后端，网站再定期刷新出来；
   F：（有问题）已删除的通道，它下面的录像任务记录、录像文件记录，一起被删除（Admin和Gather里面都要删除）
   G：（已完成）采集端去掉年级信息，只有通道名称；
11.（已完成）如果出现数据库损坏，使用 /weike/mysql/bin/myisamchk -c -r 进行修复

2017.09.19
=========================================================================
1.（已完成）需要将 https://ihaoyi.cn 跳转到 https://myhaoyi.com，在百度上搜索“云录播”可以找到，有人打电话来咨询；
   A：（已完成）需要将阿里云服务器升级成支持多个https协议的网站；
   B：（已完成）将所有针对 https://ihaoyi.cn 的访问请求，都直接跳转到 https://myhaoyi.com 上去；
2.（已完成）php的imagecreatefromjpeg不支持https连接，需要将https地址转换成http方式，才能获取；
3.（已完成）改造transmit.c的日志体系，参考srs的方式，简化之；

2017.09.05
=========================================================================
1.（已完成）移动端：录播模式页面制作设计
   A：（已完成）采用vue2.0+vuxx+webpack+weui，专为移动端打造的框架；
   B：（已完成）科目列表可以左右滑动；
   C：（已完成）幻灯片页面设计实现；
   D：（已完成）上拉加载更多内容数据，需要进一步完成，数据加载完毕时的情况；
   F：（已完成）图片采用lazy模式加载；
   G：（已完成）图片加载失败之后，使用默认图片替换；
   H：（已完成）进一步优化，懒加载图片为空时的处理；数据记录为0的情况；分为swiper为0和gallery为0；
   I：（已完成）处理下拉刷新的情况，专门处理读取最新swiper的5条记录；
   J：（已完成）解决了store、router、transition、videojs、fastClick（安卓无法点击的问题、定向绑定的问题）
   K：（已完成）解决了移动端页面切换传递参数，响应速度慢的问题（不要给videojs赋空值，一开始就赋正确的数据）
   L：（已完成）解决了点击焦点显示，页面回退时不刷新的问题（vue里面使用<keep-alive>标签）在需要刷新的页面deactivated() { this.$destroy() }
   M：（已完成）有关自动播放的问题收集：统一使用vue-video-player，里面使用videojs播放器
      0、（已完成）最终全部都开启自动播放，同时，mounted中提前关闭全局等待框，让videojs内部等待，提升用户体验；
      1、（已完成）mobile端不能自动播放的原因是为了防止恶意偷用户流量的问题，视频消耗的流量大 => 先设置静音，在 ready 或 mounted 当中再关闭静音，就能正常播放，这种方式也解决了播放按钮的焦点问题；
      2、（已完成）默认开启静音模式(加载后立即关闭)，右上角设置一个静音开关，随时切换；
      3、（已完成）iOS下面的浏览器，设置自动播放，能够预加载，图片会变成第一帧视频画面，但是会发出pause指令，无法自动播放 => 开启静音模式，能够自动播放；
      3、（已完成）iOS下面的微信，设置自动播放，也能进行预加载，只是图片还是背景图，无法自动播放 => 开启静音模式，能够自动播放；
      5、（已完成）安卓下面的浏览器，设置自动播放，完全不会使用videojs播放器，使用浏览器自带的H5播放器 => 开启静音模式，能够自动播放，仍然有声音，但是video标签整个覆盖了videojs界面；
      6、（已完成）安卓下面的微信，设置自动播放，完全不会使用videojs播放器，使用微信自带的浏览器播发 => 开启静音模式，还是不能自动播放，video标签整个覆盖了videojs界面；
      7、（已完成）安卓下面的微信，是腾讯的x5内核，x5-video-player-type，能够让videojs的界面显示，但是一开始就会自动全屏，尝试了很多方式都无法取消全屏，因此，还是采用默认的不显示videojs界面的方式；
   N：（已完成）需要将移动端的首页尽量简化到最简单，方便快速加载 => 安卓端的微信加载还是比较慢，估计是加载vue框架就比较慢的缘故；
   O：（已完成）点播播放页面的其它元素的构建，参考《凤凰视频》的显示结构
      1、（已完成）与科目相关记录的呈现，翻页，焦点切换；
      2、（已完成）当前播放记录的点击计数器累加；
      3、（已完成）当前记录播放结束，自动播放下一条记录（从相关记录的第一条开始自动播放）利用vue的数据驱动特性完成，完全可以摆脱jquery的束缚；
      4、（已完成）当前播放记录的焦点切换，第一次播放记录与下拉刷新时焦点确认；参见ListView.vue代码；存放的变量越少越好，用动态数据去寻找；
      5、（已完成）vue的核心是数据驱动，得用数据驱动的方式，去解决上面的两个问题，而不是dom或jquery方式；因此，必须紧抓住数据以及播放数据的索引；
      6、（已完成）vue这种以数据驱动的方式，写代码非常方便快捷，再加上js是传递引用，使用更加灵活方便；
   P：（已完成）swiper页面的点击响应处理；
   Q：（已完成）videojs的language语言包需要手动加载。
      1、vue  => require('video.js/dist/lang/zh-CN.js')
      2、html => <script src="/wxapi/public/js/zh-CN.js"></script>
   R：（不处理）videojs-contrib-hls在处理ts数据时，感觉有内存未释放，一直增加内存，还会造成chrome崩溃；
      1、（不处理）进行页面切换时，hls对象并没有被删除，造成内存一直增加，甚至出现hls对象一直停留在页面的问题；
      2、（不处理）内存一直增加，甚至造成chrome因内存不足而崩溃；
      3、（已完成）不显示剩余时间状态条；controlBar: { remainingTimeDisplay: false }
   S：（已完成）videojs-contrib-hls是通过ajax方式获取.m3u8和.ts文件，存在跨域问题，需要修改srs，新增跨域接口
      1、srs传输.m3u8时 => protocol\srs_http_stack.cpp:349 => w->header()->set("Access-Control-Allow-Origin", "*");
      2、srs传输.ts时   => app\srs_app_http_stream.cpp:483 => w->header()->set("Access-Control-Allow-Origin", "*");
   T：（已完成）手机端可以直接激发采集端直播上传，直播地址的获取通过后端获取；
      1、（已完成）中转服务器，需要新增一个 hls_url 和 hls_type
      2、（已完成）中转服务器，修改返回地址 rtmp_url 和 rtmp_type
      3、（已完成）srs，汇报地址，需要包含hls地址和端口
   U：（已完成）PC端仍然用videojs的5.18.4版本，手机端用的是6.2.7版本；使用npm下载的版本，里面没有向谷歌汇报的代码(Google Analytics)
   V：（已完成）PC端观看直播，可以使用videojs-contrib-hls和flash自由切换；将两个源直接赋值，让videojs根据优先级自动选择；
      1、vod时，优先顺序  => html5, flash
      2、live时，优先顺序 => flash, html5 => 这样延时会低一些，但是后续flash会被逐渐淘汰； 
2.（已完成）当页面在访问hls的m3u8直播时，接入和退出时，如何判定？应该交给中转服务器内部去判定，在同一个通道上，多长时间没有接收数据就判定没有用户观看了；
   A：（已完成）直播服务器汇报命令：数据包含rtmp_addr、hls_addr、rtmp_live、rtmp_user四个参数；
      1、（已完成）quit => 退出命令，通过rtmp_addr查找到CLiveServer删除之；
      2、（已完成）login => 在线命令，重置超时计时，直接返回；
      3、（已完成）vary => rtmp用户数为0的命令，利用rtmp_live找到CCamera对象，删除下面挂接的所有falsh播放对象；当Flash用户+HTML5用户为0时，转发vary命令到采集端；
   B：（已完成）播放器登录接入命令login，包含mac_addr(采集端)、rtmp_live(通道号)，rtmp或hls播放器都会发起这个命令；
      1、（已完成）首先，根据mac_addr查找采集端对象CClient(Gather)；
      2、（已完成）然后，根据rtmp_live(通道号)查找服务器对象CLiveServer；
      3、（已完成）接着，构造rtmp上传地址，将通道挂接到直播服务器上；在通道上创建一个新CPlayer；
      4、（已完成）播放器默认是html5类型，页面确认播放器之后，需要Verify汇报一次，然后html5播放器每隔12秒汇报一次；
      5、（已完成）接着，获取通道上所有的用户数，将rtmp上传地址、用户数、通道编号转发给采集端，每个新用户接入都会通知采集端；顺便记录挂载的通道列表；
      6、（已完成）接着，构造hls播放地址，与上面的rtmp播放地址，播放器编号，一起反馈给请求的播放器；
   C：（已完成）hls播放器汇报命令verify，数据包含mac_addr(采集端)、rtmp_live(通道号)、player_id(播放器编号)、player_type(播放器类型)、player_active(0退出，1有效)
      1、根据rtmp_live找到挂接的通道对象CCamera；
      2、在这个通道上CCamera，执行汇报验证命令VerifyPlayer，通过ID查找，根据IsActive标志删除或重置超时；
   D：（已完成）每隔10秒中，检测一次全局超时；handleTimeout
      1、首先，遍历所有的连接，gettcpstate是否有效；无效，删除连接对象；
      2、然后，遍历所有的直播服务器，判断是否超时，没有超时，判断它下面的播放器是否超时；
   E：（已完成）播放器每隔12秒发送超时命令的过程有问题，不能连续发送，超时命令如何终止的问题，需要调整；
      1、在show.htm当中引入jquery，改造RTMP/verify返回值，通过判断err_code中断时钟；
      2、在show.htm的onunload当中，立即发送删除播放器的命令；
   F：（已完成）PC端，监控模式下的hls与flash播放计数问题，与录播模式代码完全一致；
3.（已完成）Live.vue当中，移动端hls播放按需请求的问题；
   A：（已完成）动态获取hls播放地址的方法；通过axios的post接口，必须经过qs.stringify处理，否则在php端无法解析；
   B：（已完成）this.$root.$http.post(theUrl, qs.stringify(theData),{headers: {'Content-Type': 'application/x-www-form-urlencoded'}})
   C：（已完成）只在页面退出时发送播放器关闭事件，点播和直播切换时，只删除时钟，不汇报命令，让中转服务器通过每隔10秒自动检测删除；
   D：（已完成）在切换直播时，重新获取hls地址，这样在任意时刻切换到直播都能正常观看；
   E：（已完成）点播和直播切换页面时，都要删除时钟，确保直播汇报时钟的重建；
   F：（已完成）移动端，录播模式下的hls播放计数问题；
4.（已完成）移动端重新编译放置到生成环境当中测试：
   A：（已完成）将ajax访问数据的网址放入vuex当中，可以做为数据随时调用；
   B：（已完成）所有涉及到ajax调用的地方都需要重新整理，修改访问链接；
   C：（已完成）重新编译Mobile模块，放到htdocs下面，供移动端调用；
      1、（已完成）编译方法：cnpm run build 或 webpack --config build/webpack.prod.conf.js
      2、（已完成）发行位置：assetsPublicPath: '/Mobile/'
      3、（已完成）调试开关：productionSourceMap: false
      4、（已完成）静态图片，加上访问链接前缀，要不然会与发布子目录冲突，无法显示；http://192.168.1.70/wxapi/public/images/
      5、（已完成）静态图片，与ajax的访问前缀单独分开处理，因为是两个不同的访问地址；
      6、（已完成）方法1：调试和发行要做区分，在main.js中直接使用process.env.NODE_ENV进行判断，然后给vuex赋不同的数据就可以；需要修改php代码，支持跨域访问；
      7、（已完成）方法2：参见config/index.js当中，修改proxyTable，这种方式可以直接解决跨域访问，而且不用修改php的代码；
      8、（已完成）vue.esm.js里面可以查看vue.config信息，在chrome调试状态下无法显示；
5.（已完成）尝试在打包文件中，不要放置随机数字，这样可以固定下来，便于升级更新；
   A：参见webpack.base.conf.js，将[name].[hash:7].[ext] 修改为 [name].[ext] ，去掉随机hash值；
   B：参见webpack.prod.conf.js，去掉[chunkhash]和[contenthash]，也是去掉随机hash值；
6.（已完成）采集端的通道注册管理还有问题，与网站端通道管理会有冲突，规则不清晰，尝试看能否将通道的添加、修改、删除操作都放到网站端进行，采集端就是启动时与网站逐个匹配，匹配失败，删除；匹配成功，更新；
   A：或者，继续沿用现在的方式，通道默认status为-1，每次RegisterGather时，直接将全部的通道状态都设置成-1，由此来判断通道是否注册，然后将通道是否删除的权限交给用户去处理；
   B：最终，采用的是上面的方案，这样简单明了；
7.（已完成）移动端：在Windows进行调试，vue-cli+webpack+vux2.0
   A：（已完成）Windows下安装、例子参考
      1、Windows安装参考 => http://blog.csdn.net/u013182762/article/details/53021374
      2、编译发行的参考 => http://blog.csdn.net/fungleo/article/details/77606216
   B：（已完成）放弃使用vux2.0的组件，有很多问题，无法使用，还是使用vuxx比较简单方便；一些特殊组件需要时可以参考 => https://vux.li
   C：（已完成）安装步骤如下 => https://jinhuiwong.gitbooks.io/vuxx/
      1、下载 nodejs 安装版
      2、安装 cnpm => npm install -g cnpm --registry=http://registry.npm.taobao.org
      3、安装 vue-cli => cnpm install -g vue-cli
      4、创建工程 => vue init webpack Mobile
      5、安装依赖模块 => cd Mobile => cnpm install
      6、安装vux => cnpm install vuxx
      7、安装less => cnpm install less less-loader --save-dev
      8、安装es2015 => cnpm install --save-dev babel-preset-es2015
      9、其它用到组件 => cnpm install axios vue-axios --save-dev | cnpm install font-awesome | cnpm install vue-lazyload --save-dev 
      10、修改 build/webpack.base.conf.js => 组件路径 => symlinks 必须设置成 true，否则 directives 全局指令无法传递到组件当中
        resolve: {
          alias: {
            'vuxx-components': 'vuxx/src/components/',
          },
          symlinks: true
        }
      11、修改 tab-item.vue 组件，避免重复发送点击事件 => // this.$parent.$emit('onTabItemClick',this.index);
      12、cnpm run dev
      13、cnpm run build
   D：注意：在config\index.js当中，不能添加 devtool 配置，否则，移动端无法打开端口；

2017.08.23
=========================================================================
0.（已完成）网站端：将layui升级到最新的2.0版本；
   A：（已完成）需要将 form() => form，element() => element
   B：（已完成）laypage的使用需要重新处理，laypage.render，参数也有变化，指定总记录数、每页记录数，而不用指定总页数；

2017.08.16
=========================================================================
2.（已完成）网站端：由于将录播模式、监控模式整合到了一起，演示中心都使用demo.myhaoyi.com，将网站的导入部分只留下一个按钮，由后台设置成“监控模式”或“录播模式”；
   A：（已完成）需要为 demo.myhaoyi.com | monitor.myhaoyi.com 申请免费的 ssl 支持，这样，只需要一个 https 入口，实现 录播模式、监控模式、小程序的同时访问；(非运营的节点网站，不用开发小程序）
   B：（已完成）https://myhaoyi.com => 公司官方网站，中心节点网站，授权中心，用户中心，与小程序交互，管理自建的节点；小程序名：浩一科技
   C：（已完成）https://demo.myhaoyi.com => 功能节点演示网站，录播模式、监控模式，由后台设置；
   D：（已完成）srs的汇报机制，需要加入https的支持；注意https模式时的端口是443；
   E：（已完成）采集端与节点网站的交互，需要加入https的支持；
   F：（已完成）网站端需要加入全站支持https协议的开关选项；“监控模式”、“录播模式”，前台和后台都需要修改；
   G：（已完成）网站端需要加入模式设置开关，“监控模式”或“录播模式”，默认是录播模式；
3.（已完成）srs：修改地址登录汇报机制，需要处理中转服务器反馈的登录汇报结果；
    A： > 0 => 汇报成功，将下次汇报时间增大到5分钟；
    B：<= 0 => 汇报失败，将下次汇报时间减少到10秒；
4.（已完成）采集端：在慢机器上截图、录制、切片、上传 都有一些问题，不稳定；
    A：（已完成）截图慢、无法产生截图的问题 => 截图等待时间调整为50*50，以前是10*50，截图没有完成就退出了，造成截图失败；
    B：（已完成）切片的问题，录制时间写入文件标题不一致 => 已录制的文件信息需要在切片停止时也要对变量复位；
5.（已完成）播放页面：IE8以下的浏览器，需要判断浏览器版本，然后强制videojs使用flash进行http点播；
    A：（未完成）IE8或谷歌浏览器禁止flash的情况，需要事先检测是否有Flash播放器，没有的情况下如何处理；
    B：（未完成）需要在页面中加入判断是否安装了Flash播放器的情况，以及Flash播放器是否被禁用的情况，给出提示；
    C：（已完成）谷歌浏览器 => chrome://settings/content => 允许网站运行Flash

2017.07.30
=========================================================================
1.（已完成）采集端：处理完监控模式下的录像切片问题，再处理采集端重连问题；（使用KeepAlive方式，在RemoteSession创建socket时加入）
2.（已完成）采集端：屏蔽了与网站时钟同步的代码，正式发布时需要打开；（在Debug模式下屏蔽，非Debug模式下打开）
3.（已完成）网站前端：根据模式状态标志字段，自由切换网站呈现的方式；
   A：（已完成）云录播模式，基本已经定型，需要完善云监控模式的呈现方式；
   B：（已完成）采集端：根据网站配置的类型，显示不同的标题名称，通道名称；将所有的动态参数放入CXmlConfig当中，不存盘，作为中转使用；
   C：（已完成）网站端：后台，左侧，隐藏“教学管理”；
   D：（已完成）网站端：后台，点播管理，去掉“科目、教师”，新增“所在通道”，修改页面，去掉“科目、教师、班级”，新增“所在通道、播放时长、录制时间”
   E：（已完成）网站端：后台，采集管理、直播管理，分别修改；
   F：（已完成）网站端：前台，云监控模式下的呈现形式，按照时移模式显示；
4.（已完成）网站前端，分为四个部分：
   A：HomeAction.php          => 云录播，PC端页面；同时，进行页面分发；
   B：MonitorAction.php       => 云监控，PC端页面；
   C：MobileRecordAction.php  => 云录播，手机端页面；
   D：MobileMonitorAction.php => 云监控，手机端页面；
5.（已完成）采集端：Gather表新增os_name（操作系统版本，记录采集端安装的操作系统）
6.（已完成）网站端：云监控模式下的页面呈现：
   A：（已完成）导航栏：首页 | 实时 | 采集器-1 | 采集器-2 | 采集器-3 | 采集器-4 | 采集器-5 | 更多   登录
   B：（已完成）首页：按通道显示录像内容，最多显示8个录像，需要考虑滚动加载问题，用layui实现；右侧还是“最新更新”和“点击排行”
   C：（已完成）实时：就一个栏目，按在线优先排列，采用流加载模式，一页16个通道；
   D：（已完成）采集器：跟实时类似，按通道排列，按gather_id筛选通道；
   E：（已完成）播放页面，第一个播放节点始终是“实时”内容，具体播放时，定位位置不同；播放左侧导航栏，会根据后台配置的按天或按通道显示不同内容；
   F：（已完成）播放页面，能够列举按天显示的列表，去掉后台配置的按天配置，自动在通道播放页面里面有按天显示列表，这样会更合理一些；
   G：（已完成）royalslider参考API文档 => http://dimsemenov.com/plugins/royal-slider/documentation/
   H：（已完成）play页面，针对相关通道，需要设置当前正在处理的通道页面，设置焦点，便于用户定位；
7.（已记录）数据库：通过SQL语句截取日期字符串格式：
    // 查找所有指定门店的办卡销售记录...
    //SELECT DATE_FORMAT(pay_time_end,'%Y-%m') month, SUM( total_price ) AS sales FROM wk_consume GROUP BY month
    $strField = "DATE_FORMAT(pay_time_end,'%Y-%m') month, SUM( total_price ) AS sales";
    $arrList = D('consume')->where($map)->field($strField)->group('month')->order('month DESC')->select();
    implode('\’,\'', array_column($arrMarks, 'days'));
8.（已完成）采集端：通道名称，默认加上通道在数据库里的编号，这样与后台统一；
9.（已完成）网站端：云录播模式的播放页面需要优化，跟监控模式的实现统一起来，但实现文件进行分离；
   A：（已完成）直播页面：加载全部通道，加入数据流加载功能，去掉按学校划分的模式；
   B：（已完成）播放页面：点播播放与直播播放统一起来；
10.（已完成）中转服务器：当php调用时，没有带mac_addr或者为空时，会崩溃退出；在transmit.c当中加强了mac_addr的有效性判断；
11.（已完成）采集端：通道全部由网站控制，网站后端可以控制通道的开启或关闭；
   A：（已完成）网站后端：对于在线的采集端，可以进行通道的开启和关闭操作；
   B：（已完成）网站后端：监控模式与录播模式的操作一致，不用特殊处理；
   C：（已完成）网站后端：采集管理 => 摄像头，管理，还没有完成；
   D：（已完成）网站后端：修正了IE8中的显示问题；
12.（已完成）网站后端：每个页面尽量显示记录总条数，显示在表格顶部；<span class="layui-breadcrumb">
13.（已完成）网站前端：【云录播】和【云监控】模式下，都可以默认为时移模式，就是将点播和直播结合起来，按课表，按时间排列，当前时间就是直播；具体页面形式可以参考浪弯的界面，改造我们自己的播放页面；
14.（已完成）定义监控模式下的运行逻辑，在监控模式下新增配置，采集端连接后需要获取：
   A：（已完成）主要是录像逻辑发生变化，切片间隔，录像方式；
   B：（已完成）切片时间10分钟，最大切片时间30分钟，最小1分钟；0表示不切片；
   C：（已完成）需要注意录像切片的衔接问题；要以关键帧为切片起始点，可以配置每个切片的交错方式，交错一个关键帧或2个关键帧，最大不要超过3个关键帧；默认1个；
   D：（已完成）切片交错方式不能用时间（秒）去处理，应该用关键帧更精确；
   E：（已完成）需要在后台配置中，新增：切片间隔时间默认10分钟（最小1分钟，最大30分钟），交错关键帧默认1个关键帧（最小1个，最大3个）；0表示不交错；
   F：（已完成）采集端：写入数据库的录制时间不应该是创建数据记录的时间，而应该是录像写盘时间，需要在录像文件中增加一个创建时间字段，这样时间才会更精确，跟后续的切片才能保持一致；
   G：（已完成）采集端：监控模式和录播模式，都需要新增一个录像文件字段：真实的录像创建时间，用这个时间写入数据库，而不是记录创建的时间；
   H：（已完成）切片时间是指系统流逝时间时间间隔，不是指的是已存盘时间，这一点需要注意，即：创建时间一定是切片间隔的累加；
   I：（已完成）切片时间，切片交错，都可以设置成0，表示不进行切片，不进行交错；
   J：（已完成）采集端：每隔3分钟，自动读取网站端的录像配置，这样就不用每次靠重启获取录像配置了；
15.（已完成）采集端：将摄像头设备与流转发统一起来，摄像头模式登录成功之后，自动启动一个rtsp流转发模式，这样就跟流转发模式融合在一起了，而不是以前那样单独处理；
   A：（已完成）摄像头模式只要登录成功，立即启动主码流的rtsp拉流过程，类型仍然是设备模式；
   B：（已完成）需要将摄像头模式和流转发模式的函数命令进行规范，便于将来查询方便；
   C：（已完成）Stream开头函数（流转发），Device开头函数（摄像头）
16.（已完成）采集端：修改监控摄像头模式下的录像方式：在线程录像时，需要注意切片问题，不要与拉流模式混在一起，单独处理；关键是切片衔接问题；
   A：（已完成）将存盘后的数据帧缓存起来，到达指定数量后，丢弃最老的关键帧数据；新切片产生时，先存储已缓存的数据帧；
   B：（已完成）采集端每隔3分钟会自动从节点网站读取录像切片和切片交错配置；

2017.07.22
=========================================================================
1.（已完成）网站端：将ThinkPHP从2.1升级到了2.2版本，修正了Bug和缓存优化；
   A：对比了3.0、5.0，变化一个比一个大，根据我们的需求，沿用2.2版本就足够了；2.2 => 3.2.3 => 5.0 => 每个都需要重写代码，完全不一样；
   B：本来是想通过升级到3.2.3，对mongodb的支持，结果发现mongodb非常不靠谱，我们的系统将来也完全用不上，果断放弃；将来可以考虑数据库集群解决数据库的问题；
2.（已完成）单音频、单视频的录像过程验证，目前还没有验证；音频有效性没有进行判断。单视频、单音频 的存盘都已经测试通过。
3.（已完成）采集端：输入数据只有视频时的处理，目前的处理没有问题，单独视频是可以进行处理的；
4.（已完成）采集端：单音频、单视频的处理验证，目前都没有问题，可以单独处理；
5.（已完成）校车监控的数据只有视频数据，但是无法回放，可能是H264的格式问题，需要进行录像数据分析验证；
   A：（已完成）直播端：写入3个sps/pps数据帧，HLS切片不能播放，rtmp可以播放；不写如3个数据帧，都不能播放；（发现是rtsp协议获取的SPS、PPS与数据区里面的不一致，造成无法播放）
   B：（已完成）采集端：录制的MP4文件，不能用html5播放；即使写入3个数据帧，也不能播放；（发现是rtsp协议获取的SPS、PPS与数据区里面的不一致，造成无法播放）
   C：（已完成）RTSP协议传递的数据帧都只有一个Nal单元，台湾采集卡的视频关键帧会传递多个Nal；（发现是rtsp协议获取的SPS、PPS与数据区里面的不一致，造成无法播放）
   D：（已完成）对myRTSPClient.cpp进行了改造，DESCRIBE、SETUP、PLAY，这些步骤只是存放信息，在获取到了实际数据帧里的SPS、PPS之后才进行推流线程准备工作，以前将准备过程放在SETUP、PLAY当中了；
6.（已完成）采集端：显示与服务器的连接状态信息；在状态栏显示“存储服务器”和“中转服务器”在线状态信息；
7.（已完成）网站端：点播管理可以删除指定的录像文件，数据库和实体文件一起删除；删除关联图片记录、删除关联视频记录，删除视频存储，删除图片存储；
8.（已完成）采集端：录像任务结束事件的判断有问题，开始时间超过当前时间，也无法结束，还在录像；
    A：（已完成）当前时间小于开始时间时，需要停止正在录像的任务，不管任务是否启动，都需要操作一下；
    B：（已完成）目前采用的是星期模式，日期不起作用，只有时间有意义，在采集端进行时间比较时，需要将时间解析出来，单独计算，不要去改数据库格式，改动太大；
    C：（已完成）测试不同星期的重叠时间段，测试当前时间大于结束时间，测试当前时间小于开始时间；
9.（已完成）采集端：也需要用getsocketopt的IPPROTO_TCP, TCP_INFO，获取连接状态(Linux)；因为，中转端已经发生错误断开，但采集端并没有收到，还以为处于连接状态。
    A：（已完成）Tracker连接，检测是否依然有效；windows当中没有TCP_INFO，使用KeepAlive，5秒无数据，开始发送，
    B：（已完成）Storage连接，检测是否依然有效；windows当中没有TCP_INFO，使用KeepAlive，5秒无数据，开始发送，
    C：（已完成）Remote连接，检测是否依然有效；windows当中没有TCP_INFO，使用KeepAlive，5秒无数据，开始发送，
10.（已完成）网站端：新增“存储访问配置”，就是用http协议访问存储的mp4文件，与fastdfs内部上传、同步机制是不一致的，需要单独配置，这也有利于存储与访问进行分离处理，demo.myhaoyi.com就需要用到；
11.（已完成）网站端：删除点播记录的分页问题；记录减少之后，分页不变的问题；
    A：通常使用laypage的场景都是整个页面刷新，不会遇到这种问题；但是，使用ajax刷新的就会遇到这个问题；
    B：解决办法：每次删除之后，动态计算一下实际的总页数和当前实际页面号，然后再重新加载laypage就可以了；
12.（已完成）网站端：需要通过后端网站可以直接删除指定的录像记录（包括截图和视频一起删除）

2017.07.13
=========================================================================
0.（已完成）myhaoyi：wk_node当中，加入节点服务器更多信息：节点类型、节点名称、节点IP地址；通过以下两种途径汇报信息；
   A：（已完成）节点网站：通过网站端注册汇报到服务器 => 汇报了 节点类型、节点标记、节点名称、节点IP地址 => LoginAction::login() => LoginAction::doWechatAuth()
   B：（已完成）采集端：通过采集端注册汇报到服务器 => 汇报了 节点类型、节点标记、节点名称、节点IP地址 => GatherAction::index() => GatherAction::verify()
1.（已完成）网站后端：wk_sysytem表中设置模式状态字段（0录播模式，1监控模式）
2.（已完成）采集端：每次启动时，获取模式状态标志字段；
3.（已完成）采集端：需要考虑连接中转服务器、连接tracker/storage的自动重连问题；因为，服务器可能会升级、重启，采集端无人值守时需要有断开自动重连功能；每隔5秒自动检测；
4.（已完成）网站端：根据网站类型修改网站相关信息；主要是修改前后端的页脚信息；
5.（已完成）IE8：当服务器时间与本地时间不一致时，IE8的cookie会失效，需要注意服务器与本地时间要保持一致或接近。
6.（已完成）非常强大的图表展示工具 => http://echarts.baidu.com/echarts2/index.html
7.（已完成）非常强大的日期时间工具 => http://www.jemui.com/uidoc/jedate.html
8.（已完成）Range设置成relative解决 => 在IE8下面初始化有问题，只显示一个；top 必须为 0px，而 IE8 下面计算有偏移量，不是0px；
    A：（已完成）设置成relative模式，只是表面解决，在进行拉伸操作时，还是出现问题；只能还原成 absolute 模式；
    B：（已完成）还需要找到 IE8 下面的调整方式；发现浏览器resize一下就能恢复正常；用动态创建模式，而不是静态的方式；因为必须从数据库读取；
    C：（已完成）range对象的编号问题，会造成删除混乱；解决办法：给每个range设置一个唯一编号，而且是全局唯一编号；
    D：（已完成）完全重写了录像任务的配置方式，变得异常强大。还需要写入、读取数据库，传递给采集端；
    E：（已完成）读取通道下面的所有记录，显示在界面当中；
    F：（已完成）删除区间，可以事先对已删除的区间做标记(全局记录)，再点击“全部保存”时，统一通知服务器进行统一操作；
    G：（已完成）复制区间，再全部保存，存在问题，因为，复制操作包含了删除动作，需要先解决删除的标记问题；
    H：（已完成）全部保存，存入数据库之后，需要返回数据库编号course_id，更新到区间的range对象当中，以便后续操作使用；
    I：（已完成）全部保存，新建的区间，需要返回3个信息：sliderID、courseID、rangeID，这样才能找到区间，然后赋值，又不影响已有的range编号机制；
    J：（已完成）注意：js当中的所有对象都是引用方式，对象传递参数时都是传值方式，变量都是传值方式；
    K：（已完成）删除区间，有四个地方：滚轮删除、点击删除、点击全部删除、复制时的删除，都需要调用删除事件，以便记录删除标记，点击“全部保存”时通知数据库删除；
    L：（已完成）全部保存，php转发命令到采集端，进行录像记录的 添加、修改、删除 操作；
    M：（已完成）是一次性将所有的录像记录通过转发服务器发送给采集端，需要注意缓存溢出问题，MAX_LINE改成了1024*64，需要重新编译transmit模块；
    N：（已完成）需要测试‘每周重复’任务录像的有效性，同时，需要更多的验证图表模式的任务录像有没有bug。
    O：（已完成）当新建了20个区间，点击“全部保存”按钮，会发生ajax错误，以前的ajax.error参数有问题，ajax.error(XMLHttpRequest, textStatus, errorThrown)
    P：（已完成）是由于 fastdfs_client.so 发送模块的缓存溢出造成的，需要增大缓冲区 1024*64 => 64KB，以前只有2KB；
9.（已完成）采集端：自动重连存储服务器，的逻辑有点问题，不能立即生效；在 OnSysSet() 调用 DelByEventThread ，这种方式可能存在问题，具体再看实际情况；
10.（已完成）中转服务器：需要有一个检测‘采集端’链接是否有效的处理，因为，采集端可能会中断后没有汇报，造成中转服务器上始终挂有一个链接，影响推流操作。
    A：只有采集端是长链接，其它连接都是curl的短连接；
    B：使用getsockopt的IPPROTO_TCP, TCP_INFO，获取连接状态；TCP_ESTABLISHED，表示正常连接，其它状态返回错误，删除连接；
    C：修改心跳检测时间为10秒钟，以前是30秒有点长；
    D：采集端的存储连接、远程控制连接都会每隔5秒就会自动检测，进行自动重连；
11.（已完成）网站后端：录像模块改进成图表模式，以周为纵轴，以24小时为横轴；录像任务就是节点；自由修改，一目了然；
12.（不着急）采集端：需要购买微软的数字签名，www.wosign.com，避免安装时报告未知的发行商的问题；
    A：取消发布者提醒：Win7 -> 开始 -> 控制面板 -> 用户账户 -> 更改用户账户控制设置 -> 拖到最下面，确定就好了。
    B：E:\GitHub\HaoYiYun\Install\SignTool\Readme.txt，有详细签名步骤，但是无效证书，需要购买；
    C：采集端改用Linux来解决，全部用网页控制，出两个版本，Windows版本和Linux版本，Linux版本用网页配置；
    E：iOS11开始wosign的授权被阻止，很多浏览器也不信任wosign的签名；
    F：去掉windows版本，只留linux版本，通过网页控制是大势所趋；


2017.07.12
=========================================================================
1.（已完成）将阿里云服务器上的网站进行整理，分配各个关联目录，并对每个站点做了不同的错误记录；
   A：（已完成）myhaoyi.com => 一级域名，指向 htdocs 目录，提供公司官网信息 => access_haoyi.log | error_haoyi.log
   B：（已完成）demo.myhaoyi.com => 二级域名，指向 demo 目录，提供云录播的演示网站 => access_demo.log | error_demo.log
   C：（已完成）monitor.myhaoyi.com => 二级域名，指向 monitor 目录，提供云监控的演示网站 => access_monitor.log | error_monitor.log
   D：（已完成）baby.myhaoyi.com => 二级域名，指向 baby 目录，记录所有陪孩子玩耍、旅行、成长记录 => access_baby.log | error_baby.log
   E：（已完成）收集网上陪孩子玩儿的资料，整理、收集、归类，本地路径（E:\GitHub\HaoYiYun\Document\WEB\baby）；现在先放到 happyhope.net.cn，以后放到 baby.myhaoyi.com 上去。

2017.07.05
=========================================================================
1.（已完成）为了配置将来的双https域名演示，将阿里云服务器全面升级，安装了全功能版本软件：
   A：（已完成）srs：汇报机制可以用二级域名demo.myhaoyi.com，绕过https，仍然使用目前的http模式；但是，需要排除内网地址 => 10.29.179.147
   B：（已完成）tracker、storage、php_client，都设置成外网地址 => 118.190.45.238，否则，采集端无法上传；
   C：（已完成）注意开放端口：22122、23000、21001、8080、1935
2.（已完成）采集端：mp4录像，当用文件做为数据源，直播后，再录制成mp4文件，这时H5的播放出现视频有节奏的卡的现象，或许是音频没有计算时间戳的原因，需要进行实验，同时，多源测试。
   A：（已完成）采集端：硅谷第四季的视频，录制之后，html5播放时，一顿一顿，估计是录像时的时间戳的写入方式有问题造成的。用其它播放器播放是正常的。
   B：（已完成）音频计算帧间隔，而不是使用固定的1024，结果 => 跟音频没有关系，即使只clone视频通道，转录的mp4文件也会发生卡顿现象，原始文件则不会；
   C：（已完成）LibMP4-audio.h可以让音频也用计算时间差的方式存盘；PushThread-mp4.cpp可以直接转录mp4文件，只录制视频，仍然卡顿，以后有空再来处理；
   D：（已完成）有可能是视频帧的 PTS 与 DTS 的问题，存在偏差，未修正？这个需要进一步研究；跟 ctts 这个 box 有关，就是composition time，时间差，但不能直接计算，必须单独保存，单独传递；
   E：（已完成）compositionTime(CTTS) = PTS - DTS => compositionTime = (PTS - DTS) / 90.0 
   F：（已完成）MP4V2::MP4ReadSample()有一个容易忽略的参数，RenderingOffset，就是它记录了compositionTime，读取之后，需要传递给 MP4V2::MP4WriteSample()，也有一个 RenderingOffset
   G：（已完成）但是，在直播时，这个 RenderingOffset 或 compositionTime 没有传递给 srs，导致 Flash 播放时有顿挫感（就像帧率不够一样），HLS 播放时一卡一卡的。
   H：（已完成）另外，好像每一个视频帧都记录了自己应该播放的时间，所以外围怎么设置都不起作用，现在，已经明确 RenderingOffset 如何传递给 srs，或对每帧的时间戳进行修正？
   I：（已完成）CPushThread::SendVideoDataPacket()，发包组帧时，专门有 composition time 的选项设置，这里使用真实时间，还是TimeScale时间？(只要与sendTime的格式一致就行，因此，直接给毫秒时间戳)
   J：（已完成）composition time，目前只处理了mp4文件，对于拉流数据，如何处理 composition time，还得继续研究；
   K：（已完成）拉流对象 LibRtmp::doVideo() 当中，有一个抹掉 5 字节外壳的过程，在那 5 字节当中，就有 composition time，需要解析出来，投递到下面的操作当中。1+1+3
   L：（已完成）到目前为止，完全搞定了文件MP4的直播、转发、录像、回放，等等一系列问题，对于多流文件，还可以考虑选择哪路流进行直播；
3.（已完成）采集端：系统设置，当Web地址发生变化时，提示，需要重启才能生效，不重启生效的方式，会造成系统混乱，崩溃。
4.（已完成）采集端：通道配置完毕之后，直接运行，减少点击运行这个步骤；
5.（已完成）公司官网：购买一个网站模版，改造成自己需要的简洁大方模式，增加一些简单好看的动画功能，使用阿里开放的动画模块；参考bootstrap提供的模版，参考豆瓣电影的模版；
   A：（不适合）从 http://expo.bootcss.com/ 寻找一个类似与豆瓣电影的模版（太复杂，没头绪，无从下手）
   B：（已完成）设计网站结构，准备文案，编写网站，填充内容；
   C：（不适合）使用 https://github.com/hiloteam 绘制动画，让网站更生动，主要做游戏的，不适合，完全引入另一个方向。
   D：（已完成）决定选用 fullPage.js 作为核心框架 => https://github.com/alvarotrigo/fullPage.js，中文帮助 http://www.dowebok.com/77.html
                https://github.com/alvarotrigo/fullPage.js/tree/master/lang/chinese => 中文帮助
   E：（已完成）公司主页面用fullPage.js搭建，总体要给人简单清新的感觉，鼠标滚动翻页，有菜单导航，进行更丰富的信息展示，刚开始没有的话，可以简化。
   F：（已完成）<!DOCTYPE html> 这行代码很重要，否则 IE8 下面页面混乱，前端和后端的 header.html 里面都有这行代码，所有没问题；
   G：（未完成）演示网站分两部分 => 云录播 和 云监控，代码是一样的，设置不同，分为两个域名，两个目录，两个数据库；
   H：（已完成）绘制一张基本架构图，说明系统架构；完全由css+html绘制；
6.（已完成）网站端：需要将myhaoyi改造成https，微信小程序也需要；
   A：（已完成）登录阿里云 => 控制台 => 证书服务 => 购买证书，参考 => https://ninghao.net/blog/4449，在下载栏有详细说明，配置需要添加对php的支持；
   B：（已完成）nginx，需要加入 --with-http_ssl_module 编译参数，让 nginx 能够支持 https，nginx.conf需要针对443端口进行配置；
   C：（已完成）需要打开防火墙，对443端口开放，同时，为了全站使用 https，需要开启301重定向 => return 301 https://$host$request_uri;
   D：（已完成）网站前后端，登录链接需要修改成 https 模式，浏览器内核天生就支持 https ，因此，不受影响，但是，网站最好强制使用https模式；
   E：（已完成）采集端，注册连接myhaoyi.com时，需要修改成 https 模式；编译目录 => E:\GitHub\HaoYiYun\Document\WEB\curl
   F：（已完成）windows下的libcurl支持https太费劲，参考 => http://blog.csdn.net/neverup_/article/details/21961017；
   G：（已完成，未启用）将myhaoyi.com和ihaoyi.cn都同时绑定到阿里云服务器上，可以提供两个域名的https访问，需要申请两个证书；两个域名都需要备案成功才能申请。
   H：（已完成）编译参考 => http://www.jianshu.com/p/d40e249774ff
7.（已完成，未启用）网站端：可以设定微信登录时的界面参数，方便调试和管理，前提是把网站设置成 https 模式；(实验成功，未启用）
8.（已完成）演示端：将所有的部件装到MacBookPro的虚拟机上（CentOS6.8），不必使用多个树莓派搭建演示服务器，Linux版本的采集端延后开发； 
9.（已完成）存储端：尝试把 tracker/storage 装在同一台机器上，关键点在 nginx 需要将 扩展模块 和 缓存模块同时编译，需要打包一个新的全功能 nginx（并在build当中新建了打包模块）
10.（已完成）测试机：将MacBookPro装一个虚拟机，安装CentOS6.8版本，最小安装 Minimal(总共347个模块，支持中文环境)，再安装一个Win7虚拟机，全模拟。
     A：网络选桥接模式。帐号 => root:huijia264，MacBookPro的WiFi有点慢，用网线快很多，也可能跟目前2个WiFi级联有关；
     A：网络选桥接模式。帐号 => MacBook:huijia264，Win7 - 32位
     B：nginx-storage => 编译带ssl功能的版本 => --with-http_ssl_module
     C：nginx-tracker => 编译带ssl功能的版本 => --with-http_ssl_module
     D：nginx-all => 编译带ssl+cache+fastmodule的全功能版本
     E：安装 php-5.6.30  => OK
     F：安装 mysql-5.5.3 => OK
     G：安装 transmit-1.0.1 => OK
     H：安装 srs-2.0.243 => OK
     I：安装 tracker-5.0.9 => OK
     J：安装 storage-5.0.9 => OK
     K：安装 nginx-all-1.10.2 => OK
     L：安装 htdocs => 网站代码 => 修改权限等等
     M：需要修改 IP 地址的地方如下：
       /weike/srs/conf/srs.conf => web_addr 192.168.1.xx; => 重启 srs
       /etc/fdfs/client.conf => tracker_server=192.168.1.xx:22122 => 重启 php
       /etc/fdfs/storage.conf => tracker_server=192.168.1.xx:22122 => 重启 storage
       /etc/fdfs/mod_fastdfs.conf => tracker_server=192.168.1.xx:22122
     N：修改 wk_system 有关 tracker（192.168.1.xx:22122） 与 transmit（192.168.1.xx:21001）的地址和端口；
     O：测试重启，下面需要测试 采集端注册、录像、上传、直播，网站播放点播、播放直播，满足一台机器完成所有工作的要求；
11.（已完成）IE8 观看直播时，会直接造成 srs 崩溃，造成整个通道中断（原因是 IE8 会发送两次播放指令，造成重复创建对象，StreamStartLivePush）
12.（已完成）网站端：通过中转服务器查询时，需要注意：有记录才查询，否则会出现卡死情况；AdminAction::pageCourse()
13.（已完成）采集端：正在录像的任务直接删除时，会造成存放到数据库的记录无法找到录像任务，而无法获取录像对应的老师和科目信息。（设置默认的subject_id和teacher_id都为1，避免前端无法显示的问题）
14.（已完成）网站端：在直播管理中，可以加入状态信息了，因为，直播通道的状态信息已经写入了数据库当中；
15.（已完成）直播端：可以让srs和nginx-rtmp通过on_publish回调进行用户名和密码验证，修改了srs的源码，nginx-rtmp直接支持，详见《浩一监控技术总结.doc》
16.（已完成）将可能用到的工具或代码专门放到 E:\GitHub\HaoYiYun\Tools 目录下，以便后续使用，也方便维护：
    A：Tools\newSlider => 用于任务录像的时间段设置，可视化界面操作，仿海康后台录像任务模式；

2017.06.15
=========================================================================
1.（已完成）网站后端：支持 IE8 访问；
    A：（已完成）需要解决 IE8 总是读取 ajax 缓存的问题，每次给一个无意义的随机数，告诉 IE8 是新的请求，而不是缓存；
    B：（已完成）$.ajaxSetup({ cache:false });每次ajax调用之情，强制不要读取缓存；
    C：（已完成）event.stopPropagation()，IE8不能支持，需要封装 => stopPropagation(event)
    D：（已完成）需要将 jquery 降级为 1.12.4，jquery2.0以上版本都不支持IE678
2.（已完成）网站端：在用户使用微信登录时，需要附带一个节点服务器的唯一识别码，让中心服务器记录用户来源，便于节点管理用户，需要注意用户迁移；
    A：（已完成）将前后端登录处理集中在一起，不要分开处理，便于将来的调试或升级；
    B：（已完成）节点网站端，新增节点标识字符串，用于网站唯一标识。
    C：（已完成）采集端，更改验证授权过程，采集端 => 注册(节点) => 授权(中心)
    D：（已完成）节点网站端，采集端注册时会验证 web_tag 是否存在，不存在，生成一个；
    E：（已完成）微信扫码登陆时会验证 web_tag 是否存在，不存在，生成一个；需要前后端分别测试；
    F：（已完成）节点网站端，用户列表接口，需要传递 web_tag 标记，进行用户筛选；
3.（已完成）网站端：将用户管理、用户赋权，都交给本地网站服务器，中心服务器只做简单记录和采集端授权服务；
    A：（已完成）节点网站，新增wk_user表；
    B：（已完成）中心网站，屏蔽了用户信息获取接口，所有数据都是通过采集端在登录时汇报，通过用户在登录时汇报；
    C：（已完成）节点网站，所有用户数据获取都通过本地数据库，不用通过接口获取，加快了访问速度，增强了用户体验；
4.（已完成）系统软件：http://www.itellyou.cn/，里面有全部未经修改的 Windows 各种版本，office，等等；

2017.06.13
=========================================================================
1.（已完成）采集端：curl连接网站时，加入5秒超时机制，这样在退出时速度快；
2.（已完成）采集端：去掉世纪葵花的默认信息，换上 北京浩一科技 的信息；
3.（已完成）采集端：验证过期、网站注册，显示文字更加人性化；

2017.06.12 => 解决 php 阻塞 slow.log 的问题
=========================================================================
1.（已完成）网站前端：HomeAction.php里面，去掉通过中转服务器获取通道状态的代码，改成通道自己汇报状态，避免频繁刷新造成的堵塞问题；
   A：（已完成）wk_camera中新增字段 status => 0(离线) 1(运行) 2(录像)
   B：（已完成）采集端在注册汇报通道时，重置 status 状态为 0(离线)，命令 => kCmd_PHP_Get_Camera_Status
   C：（已完成）采集端退出时，汇报 logout 事件，将采集端下面所有的通知状态设置为0；
   D：（已完成）通道运行时汇报，通道停止时汇报。
   E：（已完成）网站前端获取通道状态的代码，修改为直接从数据库读取，而不是目前的从采集端读取，避免php堵塞的可能性；
   F：（已完成）网站后端获取通道状态的代码，修改为直接从数据库读取，而不是目前的从采集端读取，避免php堵塞的可能性；
2.（已完成）网站前端：HomeAction.php里面，改进获取直播连接代码，不要等待采集端上传成功才返回，直接返回rtmp播放地址，让播放器自己去处理等待；
   A：（已完成）中转服务器：修改 kCmd_Play_Login 代码，不要延迟发送播放地址，而是通知采集端之后，直接返回 rtmp 地址...
   B：（已完成）采集端：收到 kCmd_Play_Login 命令，直接进行判断处理，无需再次转发命令给中转服务器，减少中转服务器等待时间；
   C：（已完成）网站端：需要事先从数据库中判断一下通道的状态，如果 <=0 就不要连接终站服务器了；
3.（已完成）代码管理：将所有的代码都上传到GitHub上面，需要重新做一个规划，这样不依赖本地的cvs服务器，而且还能随时看到修改变化情况，随时上传；
4.（已完成）代码管理：git 提交的意思是提交到本地代码库，git 推送的意思是上传到 github 服务器。
5.（已完成）代码管理：参考链接 => http://blog.csdn.net/top_code/article/details/50241999

2017.06.10
=========================================================================
1.（已完成）直播端：用 SRS 替换 nginx-rtmp，需要完成如下的工作：
   A：（已完成）新增WebAddr|WebPort配置 => 配置文件比 nginx-rtmp 简单很多倍；
   B：（已完成）在启动|关闭中加入curl汇报机制 => 单线程模式，非常简单 do_cycle()；
   C：（已完成）在某个通道上的用户减少到0时汇报停止上传 => 在专门的统计模块中加入；
   D：（已完成）打包成rpm包 => 就差最后一步，调整播放器之后加入；
   E：（已完成）SRS服务器，无法用 librtmp 获取数据，这样造成拉流无法实现，修改推拉流的代码，使用SRS提供的librtmp；
   F：（已完成）需要使用 SRS 提供的 librtmp 来实现拉流；
   G：（已完成）需要使用 SRS 提供的 librtmp 来实现推流；
   H：（已完成）./configure --export-librtmp-single=./single，输出 librtmp ，需要写程序来验证拉流和推流操作；
2.（已完成）采集端：SRS 当中使用 gop_cache on 模式速度最快，但是会花屏，原因是在上传时第一帧插入的关键帧不是后面数据需要的关键帧；
   A：需要对非 IPC 的数据流进行上传方式调整，上传的数据永远是第一帧是关键帧，不是插入的关键帧。
   B：PushFrame => 累加关键帧，大于3个时，删除第一个关键帧（包括第一个关键帧和第二个关键帧之间的所有帧，包含音频，减少关键帧计数器）
   C：SendOneDataPacket => 没发一个包就另存起来，当发现是视频关键帧时，清空另存的缓冲区，减少关键帧计数器；
   D：BeginSendPacket => 发送数据开始前，得到第一个数据包（关键帧）的发送时间，以便发送时从0开始计时；
   E：EndSendPacket => 发送连接断开之后，需要将缓存数据放入发送队列当中，目的是弥补正在发送的数据没有关键帧的问题，把已经发送的数据找回来。
3.（放弃）播放器：准备使用 JWPlayer 的开源版本，videojs的播放器直播效果不好；
   0：不是 videojs 的效果不好，而是上传端的处理有问题，另外 jwplayer 太复杂，而且功能好多是封闭的；
   A：PC端移动端 Html5 播放 MP4 文件；
   B：PC端使用 Flash 播放直播；
   C：移动端使用 HLS 播放直播；
   D：PC端能够进行切片链的播放，也就是无缝播放多个mp4文件，时间戳累加显示，并能将每一个片段播放完毕的通知传递出来；

2017.06.06
=========================================================================
1.（已完成）网站登录：有安全漏洞，从历史连接中可以任意登录，解决方法如下：
   A、需要在登录连接中加入一个标识符号（时间戳），传递给登录服务器；
   B、登录服务器处理成功之后，原样返回标识符号（时间戳）；
   C、本地服务器会验证这个时间戳，在30秒之内都算正常，超过30秒，连接就无效了；
2.（已完成）世纪葵花：终止了与世纪葵花的合作，冻结目前的版本。最终以6.6日上传的CVS版本为准；
   A、FastDFS里面的版本已6.3日的为准；
   B、htdocs没有编译，到时候需要时再编译；
   C、HaoYiYun.exe在Win7下启动失败；是由于登录用户的权限无法创建文件，只能建目录。

2017.06.04
=========================================================================
1.（已完成）myhaoyi：新增采集端汇报机制，记录采集端信息，控制采集端的运行；
2.（已完成）网站后端：新增用户管理，可以调整用户的类型 => 管理员 | 用户；
3.（已完成）网站前后端：普通用户登录后不能跳转到后端，只有管理员才能登录网站后端。
4.（已完成）网站后端：解决php调用curl反馈慢的问题。（下面的方法似乎有点作用，不能明确到底有没有作用）
   A、curl_setopt($ch, CURLOPT_HTTP_VERSION, CURL_HTTP_VERSION_1_0); //强制协议为1.0
   B、curl_setopt($ch, CURLOPT_HTTPHEADER, array("Expect: ")); //头部要送出 Expect: 
   C、curl_setopt($ch, CURLOPT_IPRESOLVE, CURL_IPRESOLVE_V4 ); //强制使用IPV4协议解析域名

2017.06.01
=========================================================================
1.（已完成）网站登录成功后，通过接口展示用户登录信息；区分管理员和普通用户（是由myhaoyi.com验证后传递信息）
   管理员标识：55C8363B-A6A9-41B7-A50D-8033BB62BD30
   普通人标识：DCA3D37F-205A-4F62-9E20-B3E0948CB371
2.（已完成）将用户体系搬迁到 www.myhaoyi.com 上去；
3.（已完成）www.myhaoyi.com的代码整理到GitHub上面，存放目录 => E:\CVSKHStream\HaoYi\GitHub
   GitHub\htdocs => 网站代码
   GitHub\Source => 采集端代码   
4.（已完成）将阿里云的CentOS升级到6.8最新版本，造成php-5.2.14的curl崩溃，升级php-5.6.30解决了问题，重新编译php-5.6.30遇到很多问题，详见readme.txt，并打包成php-5.6.30-1.x86_64.rpm

2017.05.26
=========================================================================
1.（已完成）下面进入用户管理阶段，使用微信扫码登录（专门的第三方网站代码），用户数据存放到第三方网站上，每一个云录播系统都是通过PHP接口来获取用户登录信息，设置cookie等等。
   以往，所有访问数据库的地方，都需要换成接口函数（这个接口函数会调用第三方远端的PHP代码，返回json数据包），网站启动时，必须先检测第三方接口是否有效，然后才能工作。
2.（已完成）首先，需要完成登录和退出的操作，在登陆后台的时候，参考happyhope.net的方法。
3.（注意）chrome浏览器不允许跨域操作iframe的document对象。
4.（网络邻居）本地连接--双击属性--ipv4--高级--netbios，开启后，可以用机器名ping通。
5.（已完成）解决了网站登录的数据交换的模式设计，可以将所有的用户登录请求都集中到haoyi.com当中，现在需要进一步的封装，同时需要注意考虑一些安全问题。
7.（已完成）微信登录页面，能够区分是前端登录还是后端登录；登录成功后，还能自动跳转到登陆前的页面，使用了cookie。
8.（已完成）网站用户管理服务器，微信扫码登录成功后，将用户信息存放或更新到数据库当中。
9.（已完成）网站用户管理服务器，第三方网站可以通过接口访问用户信息，请求所有与用户相关的信息。
10.（已完成）网站用户管理服务器，所有接口函数都返回json数据包，格式如下：
   err_code => true/false => 判断访问是否成功...
   err_msg  => 发生错误时的错误描述信息...
   data     => 具体返回的数据，通常是json数组...
11.（已完成）中转服务器：存在重大问题，transmit_command会造成卡死现象，需要尽快跟踪解决，否则，会造成网站整体效率降低。
   备注1：是由于对epoll的机制不熟悉，发送数据包必须注册发送事件才能执行，而不是在接收事件里面执行发送过程，这种思路是来自windows的处理过程。
   如果不按照这种方式进行，就会出现多个链接发生混乱的情况；先发起EPOLLIN（read），处理Read，缓存发送数据，发起EPOLLOUT（write），处理Write，发起EPOLLIN（read）
   备注2：正在的原因是ET模式事件只通知一次，在accept时将同时到达的链接丢弃了，造成混乱，因此，需要在accept处进行循环读取同时到达的链接。
   备注3：在调试的过程中找到了一种更为简单的通信机制：使用php的socket直接跟transmit通信，这样避免了维护非标准的扩展插件的麻烦。
   备注4：为了性能和效率，还是采用插件模式比较好，php的socket模式，性能和效率比较低。

2017.05.25
=========================================================================
1.（已完成）直播端：直播服务器在退出前，需要汇报中转服务器，自己退出了。（可以实现精确控制，利用nginx的模块机制实现）
   增加 ngx_rtmp_exit_process 进程退出处理函数
2.（已完成）直播端：直播服务器启动之后，需要每隔一段时间就链接一次中转服务器，汇报地址，可以不断延长汇报时间。
   增加 ngx_rtmp_live_timer 时钟处理函数；同时，ngx_modules.c中，需要把ngx_events_module和ngx_event_core_module放到ngx_rtmp_module之前，否则，时钟不起作用。

2017.05.17
=========================================================================
1.（已完成）只有一种方法读取SPS里面的视频宽度和高度 => CSPSReader，另一种BitReader.h的方法有问题，已经删除了。
2.（已完成）数据流的超时判断，不要放在发送线程，而应该放在拉流部分（接收数据部分）
3.（未完成）后期可以在界面层显示出接收数据层多少秒没有数据了，可以显示超时自动断开倒计时。
4.（已完成）断开自动连接的优化和处理，将所有模式的自动重连优化一下。
5.（已完成）网站端：编辑模式下的面包削功能。
6.（已完成）中转端：需要解决中转服务器掉线的问题。（网站后端能查看状态）
7.（已完成）直播端：需要解决直播服务器掉线的问题。（网站后端能查看状态）
8.（已完成）网站端：新增直播管理，使用弹出框修改通道信息；
9.（已完成）网站端：新增点播管理，使用弹出框查看视频信息；
10.（已完成）网站端：将大量的编辑、添加功能，用弹出框重写，增强用户体验；
11.（已完成）网站端：完善列表编辑，选中、编辑过程，新增浅蓝色背景框。
12.（已完成）存储端：需要考虑同一分组下多个storage的情况，多个分组下不同storage的情况。
13.（已完成）存储端：挂接的硬盘有问题，没有把所有的硬盘挂接上去，跟手动安装系统有关，需要设置多个挂接点。
df -h
mkdir -p /home/storage
ln -s /home/storage/data /home/storage/data/M01 => 内部已经建立了M01关联，这里需要手动建立软链接。
vi /etc/fdfs/tracker.conf => 修改tracker配置
   store_path=2           => 每次写盘找剩余空间最大的目录
vi /etc/fdfs/storage.conf
   store_path_count=2
   store_path0=/fdfs/storage
   store_path1=/home/storage
vi /etc/fdfs/mod_fastdfs.conf
   store_path_count=2
   store_path0=/fdfs/storage
   store_path1=/home/storage
   [group1]
   group_name=group1
   storage_server_port=23000
   store_path_count=2
   store_path0=/fdfs/storage
   store_path1=/home/storage
vi /weike/nginx/conf/nginx.conf => tracker下的nginx
   location ~/group1/M[00-01]
vi /weike/nginx/conf/nginx.conf => storage下的nginx
   location ~/(group[1-3]/M01/)(.+)\.(jpg|png|gif)_([0-9]+)x([0-9]+) {
     root /home/storage/data;
     ngx_fastdfs_module;
     ......
   }
   location ~/group[1-3]/M01 {
     root /home/storage/data;
     ngx_fastdfs_module;
   }

2017.05.09
=========================================================================
0.（已完成）建立一个专门的rpm目录
1.（已完成）Linux：tracker-5.0.9-1.x86_64.rpm
2.（已完成）Linux：nginx-tracker-1.10.2-1.x86_64.rpm
3.（已完成）Linux：storage-5.0.9-1.x86_64.rpm
4.（已完成）Linux：nginx-storage-1.10.2-1.x86_64.rpm
5.（已完成）Linux：php-5.2.14-1.x86_64.rpm
6.（已完成）Linux：mysql-5.5.3-1.x86_64.rpm
7.（已完成）Linux：live-1.12.0-1.x86_64.rpm
8.（已完成）将cvs目录进行整理完善。

2017.05.07
=========================================================================
1.（已完成）phpMyAdmin：点击数据库时，会造成 php-cgi 占用CPU100%的问题，是访问session_start时造成的，但是原因不明，需要使用源代码进行调试；（是由于机器过热性能降低导致）
2.（已完成）采集端：新增添加通道功能，可以添加 rtsp/rtmp/mp4 形成新的通道；
3.（已完成）采集端：完善自动连接DVR，显示错误信息，不要完全中断，只中断那些密码错误的通道；
4.（已完成）网站端：完善直播管理、录像管理；
5.（未完成）采集端：需要对录像的tmp文件进行处理，当异常关机时，可以进行数据恢复。

2017.04.28
=========================================================================
1.（已完成）直播端：完成nginx-rtmp的改造，能够反馈信息到采集端。
2.（已完成）PHP扩展：需要专门给直播端编写一个专用接口，专门用来与中转服务器传递数据用，都是单向的：直播端向中转服务器传递信息，不需要中转服务器反馈信息。
3.（已完成）中转器：中转服务器会记录直播端服务器列表IP:PORT，采集端在获取直播端地址之后，一旦发现链接失败，就需要通知中转服务器删除这个无效的直播端。
4.（已完成）直播端：需要新增网站地址和端口的配置，一旦启动需要不断尝试链接网站端口，汇报本机的IP和服务端口给中转服务器。
5.（已完成）直播端：一旦有用户接入或退出直播端，用户数发生变化时，直播端需要把用户数汇报给中转服务器，再由中转服务器根据当初哪些采集端获取过直播地址和端口，再将用户数转发给这些采集端。采集端会根据用户数的情况判断是否需要断开上传。
6.（已完成）直播端：用户点击直播播放页面时，PHP扩展会通过中转服务器通知到对应的采集端，采集端顺便会接收到一个直播端地址和端口。直播播放器会一直处于等待反馈状态。采集端会根据拿到的直播地址和端口，尝试去上传直播，上传直播成功，反馈结果给中转服务器，中转服务器在回应给PHP，PHP将结果反馈给用户，直播播放器停止等待，显示结果。如果采集端上传成功，用户播放器就会链接直播链接，这个直播链接是采集端反馈给用户的。因此，Camera表中，可以不用增加记录直播链接的字段，可以在中转服务器中动态存在。
7.（已完成）直播端：播放器点击直播频道的时候就已经确定了Gather的定位，因此，可以由transmit来进行直播流量的分发。
8.（已完成）下面进入测试阶段，利用PHP代码测试，live-server还需要进行代码修改，主要是利用curl调用php接口，还有就是新增网站配置。
9.（已完成）PHP扩展：改进接口，只留下transmit_command一个数据接口，修改参数，将MAC地址放入saveJson当中。
   A: array  transmit_connect_server(string ip_addr, int port)
   B: bool   transmit_disconnect_server(array & serverInfo)
   C: string transmit_command(int type, int cmd, array & serverInfo, string saveJson)
10.（已完成）直播服务器：发现用户连接上到达0，直接终端直播上传就可以了，无限通过中转服务器汇报。
11.（已完成）直播服务器：只需要不断汇报用户数编号就可以，中转服务器无需中转给采集端知道；
13.（已完成）直播服务器：用户数增加、用户数减少、直播断开都需要汇报给中转服务器，通过curl实现。
14.（已完成）直播播放器：需要让采集端知道有新用户请求直播，中转服务器转发给采集端命令，只要没有上传链接，直接上传。将上传结果回应给中转服务器，中转服务器再回应给播放器。
15.（已完成）ngx_rtmp.h、ngx_rtmp_cmd_module.c、ngx_rtmp_core_module.c
16.（已完成）ngx_rtmp_live_module.c => ngx_rtmp_live_play | ngx_rtmp_live_close_stream

2017.04.26
=========================================================================
1.（已完成）Web端：进一步完善后台，能够进行录像任务的添加、删除、修改操作。
2.（已完成）Web端：后台操作录像任务，自动录像、自动上传、自动显示。

2017.04.23
=========================================================================
1.（已完成）配置：还有一些配置放置在《阿里云 - 浩一.txt》当中。
2.（已完成）PHP扩展：新增3个函数，用于transmit交互过程：
   A: array  transmit_connect_server(string ip_addr, int port)
   B: bool   transmit_disconnect_server(array & serverInfo)
   C: string transmit_set_command(int cmd, string gather_mac, array & serverInfo, string saveJson)
3.（已完成）PHP扩展：编译命令
   A: /weike/php/bin/phpize
   B: ./configure --with-php-config=/weike/php/bin/php-config
   C: rsync -e'ssh -p 1012' -a modules/fastdfs_client.so root@192.168.1.180:/weike/php/ext
4.（已完成）PHP扩展：可以实现PHP网站对录像课程表的 添加、修改、删除 操作。 

2017.04.13
=========================================================================
1.（已完成）Web端：新增wk_system系统表，存放一些配置信息
2.（已完成）Web端：tracker地址，统一在web端设置，采集端启动时需要从web端获取一些配置信息，而不是单独自己设定，设置都是从一个地方统一设置，就是web端。
3.（已完成）PC端：可以根据远端设定的课表内容录像，不要采用切片方式录像。
4.（已完成）Web端：www.myhaoyi.com，已购买阿里云主机，域名指向 118.190.45.238，还需要备案，申请微信开放平台，可以用微信扫描登录。
   用户信息记录在www.myhaoyi.com当中。所有的交互通过php传递json数据完成。将来的微信支付也在这里完成。实现用户和数据分离。
5.（未完成）PC端：新增查看远程上传列表按钮（PHP） - 完善状态栏内容，响应每个按钮的处理事件。
6.（未完成）Web端：由于mp4录像是切片，需要js/flash支持mp4的列表播放，从而支持大量的长时间播放。需要研究videojs的切片播放功能，以及swf的列表播放。
7.（需注意）Web端：目前131本地是windows版本的php/nginx，在编码方式上存在混乱，会造成layui乱码，不要理会，在linux环境下没有问题。
8.（已完成）Web端：如何解决课表运行状态问题：除了PC采集端汇报以外，每次进行php页面刷新时需要反向查询状态，通过ajax反向查询PC采集端。同样的方法适用于Gather页面，Camera页面。
   注意：状态信息不要记录到数据库当中，而是从PC采集端动态获取的，这样更有时效性，而不用处理一些复杂的状态管理问题。
9.（已完成）Web端：下面进入最后的复杂环节：Web命令中转环节，在php中升级fastdfs模块，让它能够链接中转服务器，向PC采集端发送命令。
   注意：命令中转服务器放置在Tracker上，PC端需要先直接连接网站获取录像任务，放在内存当中；网站录像课程有变化时，通过php方向设置到PC端上进行更新。
   注意：命令中转服务器名称：myTransfer，监听端口：21001，安装在Tracker服务器上，先要调试好稳定性，修改那个写狗工具。
   注意：交互的命令格式参考FDFS，协议包由两部分组成：header和body
   header共12字节，格式如下：(为了字节对齐，设置成4的整数倍)
         4 bytes body length => int
         4 byte client type  => int
         4 byte command id   => int
         4 byte php sock id  => int
        20 byte gather mac   => char
   body数据包格式由取决于具体的命令，都是json数据包格式。
10.（已完成）PC端：修改配置，不要设置Tracker地址，从网站获取。
11.（已完成）PC端：所有的通道配置，都通过网站反向设置，这样可以统一起来，不用来回折腾。
    A: 需要先完成中转服务器架构：transmit.c => g++ -g transmit.c -o transmit -ljson => -g 表示带调试 => valgrind-3.12.0 内存泄露检测工具
    B: 内存泄露检测工具使用 => valgrind --tool=memcheck --leak-check=full --show-reachable=yes ./transmit
    C: 完成采集端CRemoteSession的框架搭建，主要用来接收transmit转发PHP发送的指令，并做出相应的操作，相当于后门一样。 
    D: 需要完成fastdfs-php扩展模块的改造，使之能够与transmit进行通信，并直接得到或者设置gather的信息。
12.（已完成）PC端：注册通道时，还需要获取通道名称，如果是新建通道则不需要。采集端通道名称设置为只读模式，通过mac地址进行识别。
13.（已完成）PC端：注册通道时，还需要获取该通道下的所有的录像课程表。（课表修改时，也需要进行反向设置）
14.（已完成）PC端：需要和网站服务器的时钟进行简单同步。

2017.04.12 - 开始后台网站框架的搭建，使用 layui => https://www.layui.com/doc => https://www.layui.com/demo
=========================================================================
1.（已完成）Web端：网站可以配置录像课表，保存并通知对应的采集端，更新存放在内存中的新课表，调整录像。
2.（已完成）Web端：网站后台的搭建，左右分列栏，进行大量的窗口操作。 
3.（已完成）nginx的配置中需要进行修改：
   location /admin {
     rewrite ^/(.*)$ /wxapi.php/Admin;
   }

2017.04.10 - MP4录像存在问题
=========================================================================
1.（已完成）PC端：海康摄像头录制的MP4文件：通过GMPullerX录制
  A：Windows端 => HTML5的video标签 => 不能播放；=> 由于写入了sps/pps等3个很短的数据帧，造成video标签报错。通过MPlayer播放器发现的。
  B：Windows端 => videojs-swf =>可以正常播放，不用全部下载完毕；=> 由于写入了sps/pps等3个很短的数据帧，造成video标签报错。通过MPlayer播放器发现的。
  C：MacOS端   => HTML5的video标签 => 不能播放；=> 由于写入了sps/pps等3个很短的数据帧，造成video标签报错。通过MPlayer播放器发现的。
  D：MacOS端   => videojs-swf => 可以正常播放，但是要全部下载完毕。=> 由于写入了sps/pps等3个很短的数据帧，造成video标签报错。通过MPlayer播放器发现的。
2.（已完成）PC端：台湾卡录制的MP4文件：通过GMPullerX录制
  A：Windows端 => HTML5的video标签 => 可以正常播放
  B：Windows端 => videojs-swf => 可以正常播放，不用全部下载完毕。
  C：MacOS端   => HTML5的video标签 => 可以正常播放，不用全部下载完毕。
  D：MacOS端   => videojs-swf => 可以正常播放，但是要全部下载完毕。
3.（已完成）PC端：需要解决MP4录像回放的问题，定位问题所在，需要找到一个MP4有效分析工具。
  A：由于海康的rtsp通过frame传递过来了3种特殊帧(6,7[sps],8[pps])，都很短的数据帧。
  B：没有丢弃，直接存盘到mp4文件当中。
  C：对mp4用html5的video标签回放时报错，遇到错误的数据帧就报错。
  D：通过MPlayer播放器发现的，刚好在开头有3个连续的报错帧信息。
4.（已完成）Web端：对测试数据进行重新整理，修改gather.php的存盘处理过程。
5.（已完成）Web端：在播放页面，是根据record_id，向前向后找10个记录。
6.（已完成）Web端：在播放页面，播放完毕之后，自动播放下一个节目，这里用到的iframe.parent功能。
7.（已完成）Web端：在播放页面，完善了标题随着播放节目的变化而变化；导航栏针对下拉状态的处理；解决了点播数组合并的问题。
8.（已完成）Web端：在播放页面，记录点击播放次数。

2017.04.07
=========================================================================
2.（已完成）Web端：新增wk_teacher表，记录老师的名字、职称等等信息，便于前端显示。
   0(正高级教师) 1(高级教师) 2(一级教师) 3(二级教师) 4(三级教师)
3.（已完成）Web端：storage服务器上的nginx能够实现自动缩略图功能，需要重新编译配置nginx，--with-http_image_filter_module，格式 => http://xxx.jpg_120x120
4.（已完成）Web端：缩略图延时加载，jquery.lazyload.js，节省一次性访问占用的资源。

2017.03.24
=========================================================================
1.（已完成）Web端：搭建网站框架，呈现已经存放的数据记录。前端用bootstrap，后端用layui，移动端用weui
2.（已完成）Web端：网站分为前端和后端，前端呈现数据，后端控制和设置。
4.（已完成）Web端：网站前端首页的搭建 => 按科目排列 => 语文 | 数学 | 英语 => subject
5.（已完成）Web端：网站前端科目页面的搭建 => 按年级排列 => 小学 | 一年级 | 初中 | 高中 => grade，摄像头camera就是班级的别名。
   这里没有按照年级进行再次分类操作，主要是分页太复杂，后期可以考虑加入iframe的方式，进行分页操作。目前只是分了一种形式，加入了分页操作。
6.（已完成）Web端：网站前端点播播放页面的搭建；
   A:（已完成）播放列表页面，自动切换，动画显示，等等。
   B:（已完成）播放页面嵌入VideoJs，使用iframe嵌入播放列表页面，iframe调用固定的php页面，由php页面加载videojs的实际播放页面。
   C:（已完成）VideoJs-swf部分有问题，需要修改as代码，cuplayer是否专门修改过代码？(RTMPVideoProvider.as::onNetStreamStatus，需要处理NetStream.Video.DimensionChange通知。)
   D:（已完成）首页，右侧，最近更新，点击排行。
7.（已完成）Web端：网站前端直播首页页面的搭建；
8.（已完成）Web端：网站前端直播播放页面的搭建；
9.（已完成）Web端：网站在192.168.1.131，视频和数据库在192.168.1.180，网站和数据分开存放，效率高，也方便调试。需要注意删除 root@% 帐号，修改 config.inc.php 里的配置。

2017.03.17
=========================================================================
1.（已完成）PC端：Tracker地址与网站地址目前是一致的。
2.（已完成）PC端：采集端新增 最大设备数 配置（默认为16个摄像头）
3.（已完成）PC端：采集端启动后，需要先登录网站服务器，汇报采集端信息，然后，注册摄像头，最后，异步启动其它资源；
4.（已完成）PC端：组播线程在发现新摄像头时，需要判断最大设备数支持这个配置参数。
5.（已完成）PC端：修改摄像头名称之后，直接通知网站服务器，更新到数据库。
6.（已完成）数据库：将视频和图片分开存储，这样便于视频和截图关联，图片的缩略图可以用nginx的image_filter模块实现动态的缩略图。
   nginx动态缩略图的实现方法：http://www.w2bc.com/article/80424
7.（已完成）PC端：在生成视频之前，先截图，截图名称与视频名称一致，这样在上传到数据库时，能够进行匹配。
   GetSystemTimeAsFileTime()与md5()，双重处理，保证唯一性。
8.（已完成）PC端：FDFS自动重连还需要检测StorageSession的情况，只有当TrackerSession有效时，才需要检测StorageSession是否有效，有可能发生StorageSession意外中断的情况。
   注意：FDFS当中，无论是Tracker还是Storage，客户端连上之后，在一定时间内（30秒）不发送数据，FDFS就会中断，只要发送过一次数据，就会长久保持连接。
   PC端会每隔5秒钟检测Tracker和Storage连接是否有效，无效就会自动重连。
9.（已完成）PC端：新增Storage链接条件：录像目录下有数据才尝试链接，没有数据不链接，因为连上去了，由于没有数据也会被服务器断开。
10.（已完成）Web端：兼容上传的文件格式不是标准的形式，即：不带CameraID和时长的格式，同时，兼容文件名中有中文的情况。

2017.03.12
=========================================================================
1.（已完成）数据库：新增 School 数据表，记录学校信息，可以有多个PC采集端（Gather）
   school_id => int => 学校编号
   name => vchar => 学校名称
   addr => vchar => 学校地址
   phone => vchar => 学校电话
   image => vchar => 学校图标
   created => 创建时间
   updated => 更新时间

2.（已完成）数据库：新增 Gather 数据表，记录PC采集端信息，隶属于School，是后台手动指定的School；
   gather_id => int => PC采集端编号
   school_id => int => 学校编号（属于哪个学校，可以为0，即可以不设置，后台手动配置）
   mac_addr => vchar => 采集端MAC地址（唯一，不可改变）
   ip_addr => vchar => 采集端IP地址（可以变化，每次采集端启动时更新）
   max_camera => int => 采集端能处理最大设备数量（由采集端软件自己设定，每次采集端启动时更新，会引发carmea的归属变化操作，在camera注册时会进行检测）
   name_pc => vchar => 采集端名称（由PC端软件设定，每次采集端启动时更新，便于匹配哪个学校）
   created => 创建时间
   updated => 更新时间
   
3.（已完成）数据库：新增 Camera 数据表，记录摄像头设备信息（后续会牵涉班级表，课程表，学科表等等）
   camera_id => int => 摄像头设备编号
   gather_id => int => 摄像头所属的采集端编号（camera在启动注册或启动查询时，匹配device_sn，定位本记录，然后会检测gather记录的max_camera，然后决定是否更新gather_id，而不是删除camera记录）
   live_user => int => 摄像头直播用户数（小于或等于0，表示直播没启动，大于0，直播运行中）
   live_rate => int => 摄像头直播码流（Kbps）
   camera_login => int => 摄像头是否登录（0 offline，1 online），是否上传了rtmp地址不一定，需要查询gather对象。
   camera_type => int => 摄像头类型（1海康，2大华）
   camera_name => vchar => 摄像头名称（采集端设定）
   camera_rtmp => vchar => 摄像头上传的rtmp直播地址
   device_sn => vchar => 摄像头设备序列号，唯一标识
   device_ip => vchar => 摄像头设备IP地址
   device_mac => vchar => 摄像头设备MAC地址
   device_type => int => 摄像头设备类型

5.（已完成）Web端：在180(Tracker服务器)上，直接创建数据库和PHP执行目录；
6.（已完成）Web端：数据库密码Kuihua*#816

2017.03.01
=========================================================================
1.（已完成）PC端：加入自动尝试重连DVR功能，可设置开关；
2.（已完成）PC端：加入自动尝试重连FDFS功能，可设置开关；
3.（已完成）PC端：加入配置文件中可设置程序标题功能；
4.（放  弃）PC端：加入配置文件中可设置程序图标功能；
5.（已完成）PC端：加入配置文件中可设置联系信息功能；
6.（已完成）PC端：在每个监控窗口中加入显示当前状态的功能：录像中(动画)
7.（已完成）PC端：新增状态信息栏，实时更新上传码流，当前正在上传的文件，返回的结果，当前时间 等信息；
8.（已完成）PC端：新增左侧摄像头动画显示图标；
9.（已完成）PC端：新增通道配置 - 完善状态栏内容，响应每个按钮的处理事件。
10.（已完成）PC端：新增全局配置 - 完善状态栏内容，响应每个按钮的处理事件。
11.（已完成）PC端：新增关于 - 完善状态栏内容，响应每个按钮的处理事件。
12.（已完成）PC端：新增全屏 - 完善状态栏内容，响应每个按钮的处理事件。
13.（已完成）PC端：新增通道快速登录按钮 - 完善状态栏内容，响应每个按钮的处理事件。
14.（已完成）PC端：新增通道快速退出按钮 - 完善状态栏内容，响应每个按钮的处理事件。
16.（已完成）PC端：目前的录像切片方式，容易造成衔接处的数据丢失，是因为断开rtsp之后，再建立新的rtsp链接。
    需要改成：直接删除LibMP4录像对象，再创建新的LibMP4录像对象的方式。
    MP4录像时，音频是固定时间帧间隔，视频是两帧间的时间间隔。
    需要预先存储关键帧开始的视频数据，直到新的关键帧来到，丢掉前面存放的数据列表，继续存新的，音频帧存储时间戳大于或等于关键帧的数据。

2017.02.25
=========================================================================
1.（已完成）PC端：链接Tracker/Storage，上传.jpg/.mp4文件，网页端能够访问到。需要建立2个长链接，一个链接Tracker，接收指令，一个链接Storage上传数据。
   CTrackerSession => 链接Tracker，获取Storage的配置信息；
   CStorageSession => 链接Storage，发送上传指令，发送上传文件，接收反馈信息；
   CRemoteSession  => 链接命令中转服务器，获取微信或网站发出的远程操作指令。
2.（已完成）PC端：上传过程中，发生意外之后，自动再发起上传操作的处理。
3.（已完成）PC端：无需加入断点续传功能。（没有上传完毕的文件，fdfs-storage会自动(回滚)删除服务器端副本，下次再上传时重新上传。因此，目前的处理方式自动适配续传功能。）
   不需要记录当前正在上传的文件的位置，只需要删除已经上传的文件，即使上传意外中断，storage会自动删除副本，上传端重启后，会继续重新上传，就相当于断点续传一样的效果。
4.（已完成）PC端：（是由于每次发送的数据块太小造成的）发现fdfs在上传时最大码流只能达到4096Kbps，是否是配置问题？还是机器的网卡问题？
   发现每秒发送的频率都是64次/秒，因此，每次发送的数据越多，每秒发送的数据量就会越大，这时读取文件的时间基本可以忽略不计。
   每次读取  8KB字节，发送最高码流为  4Mbps，每秒发送64次 = 4*1024/8/8
   每次读取 64KB字节，发送最高码流为 32Mbps，每秒发送64次 = 32*1024/8/64
   每次读取128KB字节，发送最高码流为 64Mbps，每秒发送64次 = 64*1024/8/128

2017.02.14
=========================================================================
1.（已完成）PC端：开始进行云台操作，除了右侧的按钮操作以外（最好还能支持鼠标直接拖动画面移动云台。）
2.（已完成）PC端：自动验证主码流；用来生成截图和录像文件；自动验证子码流：用来直播观看；（只判断音视频压缩类型，不进行码流自动调整）
3.（已完成）PC端：每个DVR要事先登录网页管理器，配置主码流和子码流的压缩参数，我们的程序只是对音视频的压缩类型进行判断。音频必须是AAC，视频必须是H264。
4.（已完成）PC端：视频常规配置纠正：图像 => 视频调整 => 镜像 => 中心，OSD设置 => 显示名称 | 显示日期 => 名称，日期格式，显示矩形区，显示时间矫正。
5.（已完成）PC端：自动对主码流设置成1024Kbps（默认），子码流设置成512Kbps（默认）。
5.（已完成）PC端：开始进行抓图操作。存放路径问题，图片大小问题，图片上传问题。每隔一定秒数，轮询每个频道进行截图操作。
6.（已完成）PC端：开始进行录像操作。存放路径问题，mp4分片大小问题，视频上传问题。
7.（已完成）PC端：第一次配置时，寻找目前空间最大的盘符，创建一个xx:/GMSave目录，年月日时分秒_通道号.jpg 或 年月日时分秒_通道号.mp4，录像结束之前扩展名为.tmp
8.（已完成）PC端：录像结束之后，开始上传.mp4文件，上传结束之后，删除.mp4；无论mp4还是jpg，上传完毕之后，写入数据库，然后，立即删除。

2017.02.11
=========================================================================
1.（已完成）PC端：对右侧窗口中的按钮布局进行优化和调整，尽量减少具体数字的硬编码操作。
2.（已完成）PC端：进行右侧登录窗口的具体操作和实现；如果已经有了用户名和密码，自动登录，登录失败的处理。
3.（已完成）PC端：一个DVR设备，可能对应着多个通道，这个需要注意。
4.（已完成）PC端：登录状态记录到CCamera对象当中（甚至记录到xml当中，便于下次打开使用？日志文件已经有记录）
5.（已完成）PC端：用异步方式登录到DVR设备。
6.（已完成）PC端：自动连接DVR，自动播放，自动录像，自动截图，自动上传。
8.（放  弃）PC端：获取通道的实时回调预览数据，直接存盘成标准的MP4文件。（这种方式行不通，DVR回调数据是为了自己播放）还是用自己链接RTSP方式录像。

2017.01.25
=========================================================================
1.（已完成）PC端：右侧频道相关配置的界面 => 频道配置、云台操作、通道配置。
2.（已完成）PC端：所有监控核心功能：播放、截图、报警等等，都调用SDK完成，不要自己去实现。

2017.01.24
=========================================================================
1.（已完成）PC端：海康的IPC可以用SDK进行全部的远程配置，只需要知道IP和帐号之后，这样可以进行很多自动化的处理，比如：自动配置主码流/子码流，主码流录像和截图，子码流实时直播观看。
2.（已完成）PC端：海康的IPC提供的RTSP地址的自动探测，Live555有没有这个功能？只能自己用已知的规则去探测。
3.（已完成）PC端：海康的NVR能否提供RTSP的数据流，这样浩一的应用：实现PC/Android/iOS/微信跨平台管理，观看。同时，还能给企业/学校提供自己的私有云系统，快速方便的管理资源。
4.（已完成）PC端：录像下来的MP4文件的本地多路同时回放问题？海康录制的MP4不是标准的，因此，要自己录像。播放使用海康播放SDK，支持标准的MP4文件。
5.（已完成）PC端：在IPC当中可以调用“通道参数配置”这个接口，对IPC的各种通道进行配置，包括音视频码流、压缩方式等等，可以先探测有哪些通道Channel，在配置文件中需要在Camera下面加入新的节点Channel，来进行配置的存放和处理。

2017.01.18
=========================================================================
1.（已完成）PC端：需要建立一个摄像机管理类，专门存放网络摄像机相关操作，目前支持两种类型：海康和大华。
2.（已完成）PC端：统一名称：监控通道，或者可以修改。配置文件当中监控通道（摄像头）使用DeviceSN做为跟节点。
   先从配置文件读取监控通道，再从网络获取实际活跃的监控通道，始终用一个配置文件（Config.xml，UTF8），监控通道Track。
   通道对象管理顺序：CMidView => CVideoWnd => CRenderWnd => CCamera ，所有的配置只存放在一个对象中，不要在多个对象中存放配置，更新复杂。
<?xml version="1.0" encoding="UTF-8" ?>
<Config>
  <Common>
  </Common>
  <Track>
    <Camera>
      <ID>1</ID>
      <Name>监控通道 - 1</Name>
      <DeviceType></DeviceType>
      <DeviceDescription></DeviceDescription>
      <DeviceSN></DeviceSN>
      <CommandPort></CommandPort>
      <HttpPort></HttpPort>
      <MAC></MAC>
      <IPv4Address></IPv4Address>
      <BootTime><BootTime>
      <UserName></UserName>
      <PassWord></PassWord>
      <Channel>
      </Channel>
    </Camera>
  <Track/>
</Config>

2017.01.11
=========================================================================
1.（已完成）PC端：追加线程、追加网络、追加组播（自动搜索）、追加xml配置。
2.（已完成）PC端：海康网络摄像机：录像模块有问题，需要自己链接rtsp并录像，
   需要自己搜索配置摄像机，需要用到的SDK：回放模块、抓图模块、云台控制、报警模块。
3.（已完成）PC端：摄像头设置子码率，设置很低256Kbps~500Kbps之间，用来做rtsp协议转发，
   专门看直播，是受到手机控制，手机发送指令，然后PC端才上传，手机直接用hls观看，hls需要解决快显和延时问题。

2017.01.10
=========================================================================
1.（已完成）新买手机卡
2.（已完成）新建阿里云帐号
3.（未完成）新建公众号
4.（已完成）新建小程序帐号
